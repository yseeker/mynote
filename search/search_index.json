{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Test \u00b6 test1 \u00b6 test2 \u00b6","title":"AL-DS"},{"location":"#test","text":"","title":"Test"},{"location":"#test1","text":"","title":"test1"},{"location":"#test2","text":"","title":"test2"},{"location":"albumentations/","text":"Image Augumentations \u00b6 \u30b5\u30f3\u30d7\u30eb\u5199\u771f\u306e\u8868\u793a \u00b6 \u30e9\u30a4\u30d6\u30e9\u30ea\u306eimport \u00b6 1 2 3 4 5 import matplotlib.pyplot as plt import albumentations as A import numpy as np import cv2 from PIL import Image Pillow \u3068OpenCV\u305d\u308c\u305e\u308c\u3067\u753b\u50cf\u3092\u8868\u793a \u00b6 \u753b\u50cf\u30c7\u30fc\u30bf\u306fKaggle\u306e Flowers Recognition \u304b\u3089\u53d6\u5f97\u3002Pillow\u3092\u4f7f\u3046\u5834\u5408\u306f\u3001\u8aad\u307f\u8fbc\u3093\u3060\u3068\u304d\u306bJpegImageFile\u306a\u306e\u3067openCV\u306b\u5909\u63db\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002 image_path = '../input/flowers-recognition/flowers/daisy/10140303196_b88d3d6cec.jpg' Pillow\u306f\u5358\u306a\u308b\u753b\u50cf\u51e6\u7406\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u3042\u308a\u3001OpenCV\u306f\u300c\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30d3\u30b8\u30e7\u30f3\u300d\u7528\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u3059\u3002\u78ba\u304b\u306b\u6a5f\u80fd\u304c\u91cd\u8907\u3059\u308b\u90e8\u5206\u306f\u591a\u3044\uff08\u3064\u307e\u308aOpenCV\u306b\u306f\u304b\u306a\u308a\u306e\u753b\u50cf\u51e6\u7406\u6a5f\u80fd\u304c\u542b\u307e\u308c\u3066\u3044\u308b\uff09\u304c\u3001 \u305d\u306e\u6271\u3046\u5185\u5bb9\u306f\u5927\u304d\u304f\u7570\u306a\u308a\u307e\u3059\u3002\u6975\u7aef\u306a\u8a71\u3001\u753b\u50cf\u3092\u30ab\u30c3\u30c8\u3084\u30ea\u30b5\u30a4\u30ba\u3057\u305f\u3044\u6642\u3084\u3001\u5c11\u3057\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3057\u305f\u3044\u5834\u5408\u306f Pillow \u3092\u4f7f\u3044\u3001\u7269\u4e8b\u3092\u300c\u898b\u3088\u3046\u300d\u3068\u601d\u3063\u3066\u3044\u308b\u30ed\u30dc\u30c3\u30c8\u3092\u7d44\u307f\u305f\u3044\u6642\u306b\u306f OpenCV \u3092\u4f7f\u7528\u3057\u307e\u3059\u3002 \u5f15\u7528\u5143\uff1a https://teratail.com/questions/71851 Pillow 1 2 3 4 5 6 img = Image . open ( image_path ) # img: JpegImageFile img = np . asarray ( img ) # \u3082\u3068\u306e\u753b\u50cf\u306b\u623b\u3059\u5834\u5408 # im = Image.fromarray(np.uint8(myarray*255)) plt . imshow ( img ) OpenCV 1 2 3 4 5 6 img = cv2 . imread ( image_path ) # img : ndarray (N-dimensional array, np.array\u306b\u3088\u3063\u3066\u751f\u6210) img = cv2 . cvtColor ( img , cv2 . COLOR_BGR2RGB ) # \u4e0b\u8a18\u3082RGB\u753b\u50cf\u2192BGR\u753b\u50cf\u3078\u306e\u5909\u63db #img = img[:,:,::-1] plt . imshow ( img ) \u53c2\u8003 - https://note.nkmk.me/python-image-processing-pillow-numpy-opencv/ - https://nixeneko.hatenablog.com/entry/2017/09/01/000000 - https://tomomai.com/python-opencv-pillow/ - https://www.codexa.net/opencv_python_introduction/ (open CV\u306b\u95a2\u3057\u3066) Note \u4e0b\u8a18\u306e\u753b\u50cf\u8868\u793a\u30b3\u30fc\u30c9\u306f\u3001 https://github.com/tkuri/albumentations_test/blob/master/albumentations_test.ipynb \u3000\u3092\u53c2\u8003\u306b\u3057\u305f\u3002 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 aug = [] n = 3 param1 = ( 1 , 20 ) param2 = ( 16 , 16 ) aug . append ( A . Compose ([ A . Blur ( p = 1 )])) aug . append ( A . Compose ([ A . MedianBlur ( p = 1 )]) aug . append ( A . Compose ([ A . GaussianBlur ( p = 1 )]) aug_img = [ aug [ i ]( image = img ) for i in range ( n )] fig , ax = plt . subplots ( 1 , 1 + n , figsize = ( 5 + 5 * n , 5 )) plt . subplots_adjust ( wspace = 0 ) plt . rcParams [ \"font.size\" ] = 18 [ ax [ i ] . tick_params ( bottom = False , left = False , right = False , top = False , labelbottom = False , labelleft = False , labelright = False , labeltop = False ) for i in range ( 1 + n )] ax [ 0 ] . set_xlabel ( \"Original\" ) ax [ 1 ] . set_xlabel ( \"Default Augmentation\" ) ax [ 2 ] . set_xlabel ( \"blur_limit= {} \" . format ( param1 )) ax [ 3 ] . set_xlabel ( \"blur_limit= {} \" . format ( param2 )) ax [ 0 ] . imshow ( img ) [ ax [ i + 1 ] . imshow ( aug_img [ i ][ 'image' ]) for i in range ( n )] Albumentations \u00b6 \u53c2\u8003\uff1a https://qiita.com/kurilab/items/b69e1be8d0224ae139ad Flip, Crop, Rotate etc.\uff08\u30d5\u30ea\u30c3\u30d7\u3001\u5207\u308a\u53d6\u308a\u3001\u56de\u8ee2\u306a\u3069\uff09 \u00b6 \u30d5\u30ea\u30c3\u30d7 \u00b6 \u5207\u308a\u53d6\u308a \u00b6 Blur, Noise\uff08\u307c\u304b\u3057\uff09 \u00b6 Blur \u00b6 \u9ad8\u5ea6\u5e7e\u4f55\u5909\u63db\u7cfb (Affine, Distortion) \u00b6","title":"albumentations"},{"location":"albumentations/#image-augumentations","text":"","title":"Image Augumentations"},{"location":"albumentations/#_1","text":"","title":"\u30b5\u30f3\u30d7\u30eb\u5199\u771f\u306e\u8868\u793a"},{"location":"albumentations/#import","text":"1 2 3 4 5 import matplotlib.pyplot as plt import albumentations as A import numpy as np import cv2 from PIL import Image","title":"\u30e9\u30a4\u30d6\u30e9\u30ea\u306eimport"},{"location":"albumentations/#pillow-opencv","text":"\u753b\u50cf\u30c7\u30fc\u30bf\u306fKaggle\u306e Flowers Recognition \u304b\u3089\u53d6\u5f97\u3002Pillow\u3092\u4f7f\u3046\u5834\u5408\u306f\u3001\u8aad\u307f\u8fbc\u3093\u3060\u3068\u304d\u306bJpegImageFile\u306a\u306e\u3067openCV\u306b\u5909\u63db\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002 image_path = '../input/flowers-recognition/flowers/daisy/10140303196_b88d3d6cec.jpg' Pillow\u306f\u5358\u306a\u308b\u753b\u50cf\u51e6\u7406\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u3042\u308a\u3001OpenCV\u306f\u300c\u30b3\u30f3\u30d4\u30e5\u30fc\u30bf\u30d3\u30b8\u30e7\u30f3\u300d\u7528\u306e\u30e9\u30a4\u30d6\u30e9\u30ea\u3067\u3059\u3002\u78ba\u304b\u306b\u6a5f\u80fd\u304c\u91cd\u8907\u3059\u308b\u90e8\u5206\u306f\u591a\u3044\uff08\u3064\u307e\u308aOpenCV\u306b\u306f\u304b\u306a\u308a\u306e\u753b\u50cf\u51e6\u7406\u6a5f\u80fd\u304c\u542b\u307e\u308c\u3066\u3044\u308b\uff09\u304c\u3001 \u305d\u306e\u6271\u3046\u5185\u5bb9\u306f\u5927\u304d\u304f\u7570\u306a\u308a\u307e\u3059\u3002\u6975\u7aef\u306a\u8a71\u3001\u753b\u50cf\u3092\u30ab\u30c3\u30c8\u3084\u30ea\u30b5\u30a4\u30ba\u3057\u305f\u3044\u6642\u3084\u3001\u5c11\u3057\u30d5\u30a3\u30eb\u30bf\u30ea\u30f3\u30b0\u3057\u305f\u3044\u5834\u5408\u306f Pillow \u3092\u4f7f\u3044\u3001\u7269\u4e8b\u3092\u300c\u898b\u3088\u3046\u300d\u3068\u601d\u3063\u3066\u3044\u308b\u30ed\u30dc\u30c3\u30c8\u3092\u7d44\u307f\u305f\u3044\u6642\u306b\u306f OpenCV \u3092\u4f7f\u7528\u3057\u307e\u3059\u3002 \u5f15\u7528\u5143\uff1a https://teratail.com/questions/71851 Pillow 1 2 3 4 5 6 img = Image . open ( image_path ) # img: JpegImageFile img = np . asarray ( img ) # \u3082\u3068\u306e\u753b\u50cf\u306b\u623b\u3059\u5834\u5408 # im = Image.fromarray(np.uint8(myarray*255)) plt . imshow ( img ) OpenCV 1 2 3 4 5 6 img = cv2 . imread ( image_path ) # img : ndarray (N-dimensional array, np.array\u306b\u3088\u3063\u3066\u751f\u6210) img = cv2 . cvtColor ( img , cv2 . COLOR_BGR2RGB ) # \u4e0b\u8a18\u3082RGB\u753b\u50cf\u2192BGR\u753b\u50cf\u3078\u306e\u5909\u63db #img = img[:,:,::-1] plt . imshow ( img ) \u53c2\u8003 - https://note.nkmk.me/python-image-processing-pillow-numpy-opencv/ - https://nixeneko.hatenablog.com/entry/2017/09/01/000000 - https://tomomai.com/python-opencv-pillow/ - https://www.codexa.net/opencv_python_introduction/ (open CV\u306b\u95a2\u3057\u3066) Note \u4e0b\u8a18\u306e\u753b\u50cf\u8868\u793a\u30b3\u30fc\u30c9\u306f\u3001 https://github.com/tkuri/albumentations_test/blob/master/albumentations_test.ipynb \u3000\u3092\u53c2\u8003\u306b\u3057\u305f\u3002 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 aug = [] n = 3 param1 = ( 1 , 20 ) param2 = ( 16 , 16 ) aug . append ( A . Compose ([ A . Blur ( p = 1 )])) aug . append ( A . Compose ([ A . MedianBlur ( p = 1 )]) aug . append ( A . Compose ([ A . GaussianBlur ( p = 1 )]) aug_img = [ aug [ i ]( image = img ) for i in range ( n )] fig , ax = plt . subplots ( 1 , 1 + n , figsize = ( 5 + 5 * n , 5 )) plt . subplots_adjust ( wspace = 0 ) plt . rcParams [ \"font.size\" ] = 18 [ ax [ i ] . tick_params ( bottom = False , left = False , right = False , top = False , labelbottom = False , labelleft = False , labelright = False , labeltop = False ) for i in range ( 1 + n )] ax [ 0 ] . set_xlabel ( \"Original\" ) ax [ 1 ] . set_xlabel ( \"Default Augmentation\" ) ax [ 2 ] . set_xlabel ( \"blur_limit= {} \" . format ( param1 )) ax [ 3 ] . set_xlabel ( \"blur_limit= {} \" . format ( param2 )) ax [ 0 ] . imshow ( img ) [ ax [ i + 1 ] . imshow ( aug_img [ i ][ 'image' ]) for i in range ( n )]","title":"Pillow \u3068OpenCV\u305d\u308c\u305e\u308c\u3067\u753b\u50cf\u3092\u8868\u793a"},{"location":"albumentations/#albumentations","text":"\u53c2\u8003\uff1a https://qiita.com/kurilab/items/b69e1be8d0224ae139ad","title":"Albumentations"},{"location":"albumentations/#flip-crop-rotate-etc","text":"","title":"Flip, Crop, Rotate etc.\uff08\u30d5\u30ea\u30c3\u30d7\u3001\u5207\u308a\u53d6\u308a\u3001\u56de\u8ee2\u306a\u3069\uff09"},{"location":"albumentations/#_2","text":"","title":"\u30d5\u30ea\u30c3\u30d7"},{"location":"albumentations/#_3","text":"","title":"\u5207\u308a\u53d6\u308a"},{"location":"albumentations/#blur-noise","text":"","title":"Blur, Noise\uff08\u307c\u304b\u3057\uff09"},{"location":"albumentations/#blur","text":"","title":"Blur"},{"location":"albumentations/#affine-distortion","text":"","title":"\u9ad8\u5ea6\u5e7e\u4f55\u5909\u63db\u7cfb (Affine, Distortion)"},{"location":"colab/","text":"Google colab \u00b6 Timeout \u00b6 1 2 3 4 5 function KeepClicking (){ console . log ( \"Clicking\" ); document . querySelector ( \"colab-connect-button\" ). click () } setInterval ( KeepClicking , 60000 ) Data\u3092content\u76f4\u4e0b\u306b\u79fb\u52d5\u3057\u3066unzip \u00b6 1 2 3 %%capture !unzip \"/content/drive/MyDrive/kaggle/input/seti-breakthrough-listen/seti-train.zip\" -d \"/content\" print ( 'Downlaod done' ) Kaggle\u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u3046 \u00b6 1 2 3 4 5 6 7 8 import os import json f = open ( \"/content/drive/My Drive/Kaggle/kaggle.json\" , 'r' ) json_data = json . load ( f ) #JSON\u5f62\u5f0f\u3067\u8aad\u307f\u8fbc\u3080 os . environ [ 'KAGGLE_USERNAME' ] = json_data [ 'username' ] os . environ [ 'KAGGLE_KEY' ] = json_data [ 'key' ] ! kaggle competitions submit digit - recognizer - f my_submission . csv - m \"Yeah! I submit my file through the Google Colab!\" Github\u304b\u3089\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb \u00b6 1 !pip install git+https://github.com/yseeker/tez_custom Output\u30bb\u30eb\u3092\u975e\u8868\u793a \u00b6 1 %%capture","title":"Google Colab"},{"location":"colab/#google-colab","text":"","title":"Google colab"},{"location":"colab/#timeout","text":"1 2 3 4 5 function KeepClicking (){ console . log ( \"Clicking\" ); document . querySelector ( \"colab-connect-button\" ). click () } setInterval ( KeepClicking , 60000 )","title":"Timeout"},{"location":"colab/#datacontentunzip","text":"1 2 3 %%capture !unzip \"/content/drive/MyDrive/kaggle/input/seti-breakthrough-listen/seti-train.zip\" -d \"/content\" print ( 'Downlaod done' )","title":"Data\u3092content\u76f4\u4e0b\u306b\u79fb\u52d5\u3057\u3066unzip"},{"location":"colab/#kaggle","text":"1 2 3 4 5 6 7 8 import os import json f = open ( \"/content/drive/My Drive/Kaggle/kaggle.json\" , 'r' ) json_data = json . load ( f ) #JSON\u5f62\u5f0f\u3067\u8aad\u307f\u8fbc\u3080 os . environ [ 'KAGGLE_USERNAME' ] = json_data [ 'username' ] os . environ [ 'KAGGLE_KEY' ] = json_data [ 'key' ] ! kaggle competitions submit digit - recognizer - f my_submission . csv - m \"Yeah! I submit my file through the Google Colab!\"","title":"Kaggle\u30b3\u30de\u30f3\u30c9\u3092\u4f7f\u3046"},{"location":"colab/#github","text":"1 !pip install git+https://github.com/yseeker/tez_custom","title":"Github\u304b\u3089\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb"},{"location":"colab/#output","text":"1 %%capture","title":"Output\u30bb\u30eb\u3092\u975e\u8868\u793a"},{"location":"dcgan/","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 import argparse import os import numpy as np import math import torchvision.transforms as transforms from torchvision.utils import save_image from torch.utils.data import DataLoader from torchvision import datasets from torch.autograd import Variable import torch.nn as nn import torch.nn.functional as F import torch os . makedirs ( \"images\" , exist_ok = True ) parser = argparse . ArgumentParser () parser . add_argument ( \"--n_epochs\" , type = int , default = 200 , help = \"number of epochs of training\" ) parser . add_argument ( \"--batch_size\" , type = int , default = 64 , help = \"size of the batches\" ) parser . add_argument ( \"--lr\" , type = float , default = 0.0002 , help = \"adam: learning rate\" ) parser . add_argument ( \"--b1\" , type = float , default = 0.5 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--b2\" , type = float , default = 0.999 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--n_cpu\" , type = int , default = 8 , help = \"number of cpu threads to use during batch generation\" ) parser . add_argument ( \"--latent_dim\" , type = int , default = 100 , help = \"dimensionality of the latent space\" ) parser . add_argument ( \"--img_size\" , type = int , default = 28 , help = \"size of each image dimension\" ) parser . add_argument ( \"--channels\" , type = int , default = 1 , help = \"number of image channels\" ) parser . add_argument ( \"--sample_interval\" , type = int , default = 400 , help = \"interval betwen image samples\" ) opt = parser . parse_args () print ( opt ) img_shape = ( opt . channels , opt . img_size , opt . img_size ) cuda = True if torch . cuda . is_available () else False class Generator ( nn . Module ): def __init__ ( self ): super ( Generator , self ) . __init__ () def block ( in_feat , out_feat , normalize = True ): layers = [ nn . Linear ( in_feat , out_feat )] if normalize : layers . append ( nn . BatchNorm1d ( out_feat , 0.8 )) layers . append ( nn . LeakyReLU ( 0.2 , inplace = True )) return layers self . model = nn . Sequential ( * block ( opt . latent_dim , 128 , normalize = False ), * block ( 128 , 256 ), * block ( 256 , 512 ), * block ( 512 , 1024 ), nn . Linear ( 1024 , int ( np . prod ( img_shape ))), nn . Tanh () ) def forward ( self , z ): img = self . model ( z ) img = img . view ( img . size ( 0 ), * img_shape ) return img class Discriminator ( nn . Module ): def __init__ ( self ): super ( Discriminator , self ) . __init__ () self . model = nn . Sequential ( nn . Linear ( int ( np . prod ( img_shape )), 512 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 256 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 256 , 1 ), nn . Sigmoid (), ) def forward ( self , img ): img_flat = img . view ( img . size ( 0 ), - 1 ) validity = self . model ( img_flat ) return validity # Loss function adversarial_loss = torch . nn . BCELoss () # Initialize generator and discriminator generator = Generator () discriminator = Discriminator () if cuda : generator . cuda () discriminator . cuda () adversarial_loss . cuda () # Configure data loader os . makedirs ( \"../../data/mnist\" , exist_ok = True ) dataloader = torch . utils . data . DataLoader ( datasets . MNIST ( \"../../data/mnist\" , train = True , download = True , transform = transforms . Compose ( [ transforms . Resize ( opt . img_size ), transforms . ToTensor (), transforms . Normalize ([ 0.5 ], [ 0.5 ])] ), ), batch_size = opt . batch_size , shuffle = True , ) # Optimizers optimizer_G = torch . optim . Adam ( generator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) optimizer_D = torch . optim . Adam ( discriminator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) Tensor = torch . cuda . FloatTensor if cuda else torch . FloatTensor # ---------- # Training # ---------- for epoch in range ( opt . n_epochs ): for i , ( imgs , _ ) in enumerate ( dataloader ): # Adversarial ground truths valid = Variable ( Tensor ( imgs . size ( 0 ), 1 ) . fill_ ( 1.0 ), requires_grad = False ) fake = Variable ( Tensor ( imgs . size ( 0 ), 1 ) . fill_ ( 0.0 ), requires_grad = False ) # Configure input real_imgs = Variable ( imgs . type ( Tensor )) # ----------------- # Train Generator # ----------------- optimizer_G . zero_grad () # Sample noise as generator input z = Variable ( Tensor ( np . random . normal ( 0 , 1 , ( imgs . shape [ 0 ], opt . latent_dim )))) # Generate a batch of images gen_imgs = generator ( z ) # Loss measures generator's ability to fool the discriminator g_loss = adversarial_loss ( discriminator ( gen_imgs ), valid ) g_loss . backward () optimizer_G . step () # --------------------- # Train Discriminator # --------------------- optimizer_D . zero_grad () # Measure discriminator's ability to classify real from generated samples real_loss = adversarial_loss ( discriminator ( real_imgs ), valid ) fake_loss = adversarial_loss ( discriminator ( gen_imgs . detach ()), fake ) d_loss = ( real_loss + fake_loss ) / 2 d_loss . backward () optimizer_D . step () print ( \"[Epoch %d / %d ] [Batch %d / %d ] [D loss: %f ] [G loss: %f ]\" % ( epoch , opt . n_epochs , i , len ( dataloader ), d_loss . item (), g_loss . item ()) ) batches_done = epoch * len ( dataloader ) + i if batches_done % opt . sample_interval == 0 : save_image ( gen_imgs . data [: 25 ], \"images/ %d .png\" % batches_done , nrow = 5 , normalize = True ) DCGAN \u00b6 G\u30e2\u30c7\u30eb\u3068D\u30e2\u30c7\u30eb\u306e\u5185\u90e8\u306b\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u3092\u4f7f\u308f\u306a\u3044\u7573\u307f\u8fbc\u307f\u3084\u8ee2\u79fb\u7573\u307f\u8fbc\u307f\u3092\u5229\u7528 \u5168\u7d50\u5408\u5c64\u306f\u5229\u7528\u3057\u306a\u3044\uff08\u30d7\u30fc\u30ea\u30f3\u30b0\u51e6\u7406\u306b\u3088\u308b\u7d30\u304b\u306a\u60c5\u5831\u304c\u6b20\u843d\u3059\u308b\u306e\u3092\u9632\u3050\u305f\u3081\u3002\uff09 \u30d0\u30c3\u30c1\u6b63\u898f\u5316\u3092\u5229\u7528 G\u30e2\u30c7\u30eb\u306e\u51fa\u529b\u5c64\u3092tanh\u95a2\u6570\u306b\u4ee3\u7528 D\u30e2\u30c7\u30eb\u306e\u6d3b\u6027\u5316\u95a2\u6570\u3092leaky relu\u306b\u4ee3\u7528 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 import argparse import os import numpy as np import math import torchvision.transforms as transforms from torchvision.utils import save_image from torch.utils.data import DataLoader from torchvision import datasets from torch.autograd import Variable import torch.nn as nn import torch.nn.functional as F import torch os . makedirs ( \"images\" , exist_ok = True ) parser = argparse . ArgumentParser () parser . add_argument ( \"--n_epochs\" , type = int , default = 200 , help = \"number of epochs of training\" ) parser . add_argument ( \"--batch_size\" , type = int , default = 64 , help = \"size of the batches\" ) parser . add_argument ( \"--lr\" , type = float , default = 0.0002 , help = \"adam: learning rate\" ) parser . add_argument ( \"--b1\" , type = float , default = 0.5 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--b2\" , type = float , default = 0.999 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--n_cpu\" , type = int , default = 8 , help = \"number of cpu threads to use during batch generation\" ) parser . add_argument ( \"--latent_dim\" , type = int , default = 100 , help = \"dimensionality of the latent space\" ) parser . add_argument ( \"--img_size\" , type = int , default = 32 , help = \"size of each image dimension\" ) parser . add_argument ( \"--channels\" , type = int , default = 1 , help = \"number of image channels\" ) parser . add_argument ( \"--sample_interval\" , type = int , default = 400 , help = \"interval between image sampling\" ) opt = parser . parse_args () print ( opt ) cuda = True if torch . cuda . is_available () else False def weights_init_normal ( m ): classname = m . __class__ . __name__ if classname . find ( \"Conv\" ) != - 1 : torch . nn . init . normal_ ( m . weight . data , 0.0 , 0.02 ) elif classname . find ( \"BatchNorm2d\" ) != - 1 : torch . nn . init . normal_ ( m . weight . data , 1.0 , 0.02 ) torch . nn . init . constant_ ( m . bias . data , 0.0 ) class Generator ( nn . Module ): def __init__ ( self ): super ( Generator , self ) . __init__ () self . init_size = opt . img_size // 4 self . l1 = nn . Sequential ( nn . Linear ( opt . latent_dim , 128 * self . init_size ** 2 )) self . conv_blocks = nn . Sequential ( nn . BatchNorm2d ( 128 ), nn . Upsample ( scale_factor = 2 ), nn . Conv2d ( 128 , 128 , 3 , stride = 1 , padding = 1 ), nn . BatchNorm2d ( 128 , 0.8 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Upsample ( scale_factor = 2 ), nn . Conv2d ( 128 , 64 , 3 , stride = 1 , padding = 1 ), nn . BatchNorm2d ( 64 , 0.8 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Conv2d ( 64 , opt . channels , 3 , stride = 1 , padding = 1 ), nn . Tanh (), ) def forward ( self , z ): out = self . l1 ( z ) out = out . view ( out . shape [ 0 ], 128 , self . init_size , self . init_size ) img = self . conv_blocks ( out ) return img class Discriminator ( nn . Module ): def __init__ ( self ): super ( Discriminator , self ) . __init__ () def discriminator_block ( in_filters , out_filters , bn = True ): block = [ nn . Conv2d ( in_filters , out_filters , 3 , 2 , 1 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Dropout2d ( 0.25 )] if bn : block . append ( nn . BatchNorm2d ( out_filters , 0.8 )) return block self . model = nn . Sequential ( * discriminator_block ( opt . channels , 16 , bn = False ), * discriminator_block ( 16 , 32 ), * discriminator_block ( 32 , 64 ), * discriminator_block ( 64 , 128 ), ) # The height and width of downsampled image ds_size = opt . img_size // 2 ** 4 self . adv_layer = nn . Sequential ( nn . Linear ( 128 * ds_size ** 2 , 1 ), nn . Sigmoid ()) def forward ( self , img ): out = self . model ( img ) out = out . view ( out . shape [ 0 ], - 1 ) validity = self . adv_layer ( out ) return validity # Loss function adversarial_loss = torch . nn . BCELoss () # Initialize generator and discriminator generator = Generator () discriminator = Discriminator () if cuda : generator . cuda () discriminator . cuda () adversarial_loss . cuda () # Initialize weights generator . apply ( weights_init_normal ) discriminator . apply ( weights_init_normal ) # Configure data loader os . makedirs ( \"../../data/mnist\" , exist_ok = True ) dataloader = torch . utils . data . DataLoader ( datasets . MNIST ( \"../../data/mnist\" , train = True , download = True , transform = transforms . Compose ( [ transforms . Resize ( opt . img_size ), transforms . ToTensor (), transforms . Normalize ([ 0.5 ], [ 0.5 ])] ), ), batch_size = opt . batch_size , shuffle = True , ) # Optimizers optimizer_G = torch . optim . Adam ( generator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) optimizer_D = torch . optim . Adam ( discriminator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) Tensor = torch . cuda . FloatTensor if cuda else torch . FloatTensor # ---------- # Training # ---------- for epoch in range ( opt . n_epochs ): for i , ( imgs , _ ) in enumerate ( dataloader ): # Adversarial ground truths valid = Variable ( Tensor ( imgs . shape [ 0 ], 1 ) . fill_ ( 1.0 ), requires_grad = False ) fake = Variable ( Tensor ( imgs . shape [ 0 ], 1 ) . fill_ ( 0.0 ), requires_grad = False ) # Configure input real_imgs = Variable ( imgs . type ( Tensor )) # ----------------- # Train Generator # ----------------- optimizer_G . zero_grad () # Sample noise as generator input z = Variable ( Tensor ( np . random . normal ( 0 , 1 , ( imgs . shape [ 0 ], opt . latent_dim )))) # Generate a batch of images gen_imgs = generator ( z ) # Loss measures generator's ability to fool the discriminator g_loss = adversarial_loss ( discriminator ( gen_imgs ), valid ) g_loss . backward () optimizer_G . step () # --------------------- # Train Discriminator # --------------------- optimizer_D . zero_grad () # Measure discriminator's ability to classify real from generated samples real_loss = adversarial_loss ( discriminator ( real_imgs ), valid ) fake_loss = adversarial_loss ( discriminator ( gen_imgs . detach ()), fake ) d_loss = ( real_loss + fake_loss ) / 2 d_loss . backward () optimizer_D . step () print ( \"[Epoch %d / %d ] [Batch %d / %d ] [D loss: %f ] [G loss: %f ]\" % ( epoch , opt . n_epochs , i , len ( dataloader ), d_loss . item (), g_loss . item ()) ) batches_done = epoch * len ( dataloader ) + i if batches_done % opt . sample_interval == 0 : save_image ( gen_imgs . data [: 25 ], \"images/ %d .png\" % batches_done , nrow = 5 , normalize = True ) Conditional GAN 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 import argparse import os import numpy as np import math import torchvision.transforms as transforms from torchvision.utils import save_image from torch.utils.data import DataLoader from torchvision import datasets from torch.autograd import Variable import torch.nn as nn import torch.nn.functional as F import torch os . makedirs ( \"images\" , exist_ok = True ) parser = argparse . ArgumentParser () parser . add_argument ( \"--n_epochs\" , type = int , default = 200 , help = \"number of epochs of training\" ) parser . add_argument ( \"--batch_size\" , type = int , default = 64 , help = \"size of the batches\" ) parser . add_argument ( \"--lr\" , type = float , default = 0.0002 , help = \"adam: learning rate\" ) parser . add_argument ( \"--b1\" , type = float , default = 0.5 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--b2\" , type = float , default = 0.999 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--n_cpu\" , type = int , default = 8 , help = \"number of cpu threads to use during batch generation\" ) parser . add_argument ( \"--latent_dim\" , type = int , default = 100 , help = \"dimensionality of the latent space\" ) parser . add_argument ( \"--n_classes\" , type = int , default = 10 , help = \"number of classes for dataset\" ) parser . add_argument ( \"--img_size\" , type = int , default = 32 , help = \"size of each image dimension\" ) parser . add_argument ( \"--channels\" , type = int , default = 1 , help = \"number of image channels\" ) parser . add_argument ( \"--sample_interval\" , type = int , default = 400 , help = \"interval between image sampling\" ) opt = parser . parse_args () print ( opt ) img_shape = ( opt . channels , opt . img_size , opt . img_size ) cuda = True if torch . cuda . is_available () else False class Generator ( nn . Module ): def __init__ ( self ): super ( Generator , self ) . __init__ () self . label_emb = nn . Embedding ( opt . n_classes , opt . n_classes ) def block ( in_feat , out_feat , normalize = True ): layers = [ nn . Linear ( in_feat , out_feat )] if normalize : layers . append ( nn . BatchNorm1d ( out_feat , 0.8 )) layers . append ( nn . LeakyReLU ( 0.2 , inplace = True )) return layers self . model = nn . Sequential ( * block ( opt . latent_dim + opt . n_classes , 128 , normalize = False ), * block ( 128 , 256 ), * block ( 256 , 512 ), * block ( 512 , 1024 ), nn . Linear ( 1024 , int ( np . prod ( img_shape ))), nn . Tanh () ) def forward ( self , noise , labels ): # Concatenate label embedding and image to produce input gen_input = torch . cat (( self . label_emb ( labels ), noise ), - 1 ) img = self . model ( gen_input ) img = img . view ( img . size ( 0 ), * img_shape ) return img class Discriminator ( nn . Module ): def __init__ ( self ): super ( Discriminator , self ) . __init__ () self . label_embedding = nn . Embedding ( opt . n_classes , opt . n_classes ) self . model = nn . Sequential ( nn . Linear ( opt . n_classes + int ( np . prod ( img_shape )), 512 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 512 ), nn . Dropout ( 0.4 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 512 ), nn . Dropout ( 0.4 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 1 ), ) def forward ( self , img , labels ): # Concatenate label embedding and image to produce input d_in = torch . cat (( img . view ( img . size ( 0 ), - 1 ), self . label_embedding ( labels )), - 1 ) validity = self . model ( d_in ) return validity # Loss functions adversarial_loss = torch . nn . MSELoss () # Initialize generator and discriminator generator = Generator () discriminator = Discriminator () if cuda : generator . cuda () discriminator . cuda () adversarial_loss . cuda () # Configure data loader os . makedirs ( \"../../data/mnist\" , exist_ok = True ) dataloader = torch . utils . data . DataLoader ( datasets . MNIST ( \"../../data/mnist\" , train = True , download = True , transform = transforms . Compose ( [ transforms . Resize ( opt . img_size ), transforms . ToTensor (), transforms . Normalize ([ 0.5 ], [ 0.5 ])] ), ), batch_size = opt . batch_size , shuffle = True , ) # Optimizers optimizer_G = torch . optim . Adam ( generator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) optimizer_D = torch . optim . Adam ( discriminator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) FloatTensor = torch . cuda . FloatTensor if cuda else torch . FloatTensor LongTensor = torch . cuda . LongTensor if cuda else torch . LongTensor def sample_image ( n_row , batches_done ): \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\" # Sample noise z = Variable ( FloatTensor ( np . random . normal ( 0 , 1 , ( n_row ** 2 , opt . latent_dim )))) # Get labels ranging from 0 to n_classes for n rows labels = np . array ([ num for _ in range ( n_row ) for num in range ( n_row )]) labels = Variable ( LongTensor ( labels )) gen_imgs = generator ( z , labels ) save_image ( gen_imgs . data , \"images/ %d .png\" % batches_done , nrow = n_row , normalize = True ) # ---------- # Training # ---------- for epoch in range ( opt . n_epochs ): for i , ( imgs , labels ) in enumerate ( dataloader ): batch_size = imgs . shape [ 0 ] # Adversarial ground truths valid = Variable ( FloatTensor ( batch_size , 1 ) . fill_ ( 1.0 ), requires_grad = False ) fake = Variable ( FloatTensor ( batch_size , 1 ) . fill_ ( 0.0 ), requires_grad = False ) # Configure input real_imgs = Variable ( imgs . type ( FloatTensor )) labels = Variable ( labels . type ( LongTensor )) # ----------------- # Train Generator # ----------------- optimizer_G . zero_grad () # Sample noise and labels as generator input z = Variable ( FloatTensor ( np . random . normal ( 0 , 1 , ( batch_size , opt . latent_dim )))) gen_labels = Variable ( LongTensor ( np . random . randint ( 0 , opt . n_classes , batch_size ))) # Generate a batch of images gen_imgs = generator ( z , gen_labels ) # Loss measures generator's ability to fool the discriminator validity = discriminator ( gen_imgs , gen_labels ) g_loss = adversarial_loss ( validity , valid ) g_loss . backward () optimizer_G . step () # --------------------- # Train Discriminator # --------------------- optimizer_D . zero_grad () # Loss for real images validity_real = discriminator ( real_imgs , labels ) d_real_loss = adversarial_loss ( validity_real , valid ) # Loss for fake images validity_fake = discriminator ( gen_imgs . detach (), gen_labels ) d_fake_loss = adversarial_loss ( validity_fake , fake ) # Total discriminator loss d_loss = ( d_real_loss + d_fake_loss ) / 2 d_loss . backward () optimizer_D . step () print ( \"[Epoch %d / %d ] [Batch %d / %d ] [D loss: %f ] [G loss: %f ]\" % ( epoch , opt . n_epochs , i , len ( dataloader ), d_loss . item (), g_loss . item ()) ) batches_done = epoch * len ( dataloader ) + i if batches_done % opt . sample_interval == 0 : sample_image ( n_row = 10 , batches_done = batches_done ) WGAN 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 import argparse import os import numpy as np import math import torchvision.transforms as transforms from torchvision.utils import save_image from torch.utils.data import DataLoader from torchvision import datasets from torch.autograd import Variable import torch.nn as nn import torch.nn.functional as F import torch os . makedirs ( \"images\" , exist_ok = True ) parser = argparse . ArgumentParser () parser . add_argument ( \"--n_epochs\" , type = int , default = 200 , help = \"number of epochs of training\" ) parser . add_argument ( \"--batch_size\" , type = int , default = 64 , help = \"size of the batches\" ) parser . add_argument ( \"--lr\" , type = float , default = 0.0002 , help = \"adam: learning rate\" ) parser . add_argument ( \"--b1\" , type = float , default = 0.5 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--b2\" , type = float , default = 0.999 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--n_cpu\" , type = int , default = 8 , help = \"number of cpu threads to use during batch generation\" ) parser . add_argument ( \"--latent_dim\" , type = int , default = 100 , help = \"dimensionality of the latent space\" ) parser . add_argument ( \"--n_classes\" , type = int , default = 10 , help = \"number of classes for dataset\" ) parser . add_argument ( \"--img_size\" , type = int , default = 32 , help = \"size of each image dimension\" ) parser . add_argument ( \"--channels\" , type = int , default = 1 , help = \"number of image channels\" ) parser . add_argument ( \"--sample_interval\" , type = int , default = 400 , help = \"interval between image sampling\" ) opt = parser . parse_args () print ( opt ) img_shape = ( opt . channels , opt . img_size , opt . img_size ) cuda = True if torch . cuda . is_available () else False class Generator ( nn . Module ): def __init__ ( self ): super ( Generator , self ) . __init__ () self . label_emb = nn . Embedding ( opt . n_classes , opt . n_classes ) def block ( in_feat , out_feat , normalize = True ): layers = [ nn . Linear ( in_feat , out_feat )] if normalize : layers . append ( nn . BatchNorm1d ( out_feat , 0.8 )) layers . append ( nn . LeakyReLU ( 0.2 , inplace = True )) return layers self . model = nn . Sequential ( * block ( opt . latent_dim + opt . n_classes , 128 , normalize = False ), * block ( 128 , 256 ), * block ( 256 , 512 ), * block ( 512 , 1024 ), nn . Linear ( 1024 , int ( np . prod ( img_shape ))), nn . Tanh () ) def forward ( self , noise , labels ): # Concatenate label embedding and image to produce input gen_input = torch . cat (( self . label_emb ( labels ), noise ), - 1 ) img = self . model ( gen_input ) img = img . view ( img . size ( 0 ), * img_shape ) return img class Discriminator ( nn . Module ): def __init__ ( self ): super ( Discriminator , self ) . __init__ () self . label_embedding = nn . Embedding ( opt . n_classes , opt . n_classes ) self . model = nn . Sequential ( nn . Linear ( opt . n_classes + int ( np . prod ( img_shape )), 512 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 512 ), nn . Dropout ( 0.4 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 512 ), nn . Dropout ( 0.4 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 1 ), ) def forward ( self , img , labels ): # Concatenate label embedding and image to produce input d_in = torch . cat (( img . view ( img . size ( 0 ), - 1 ), self . label_embedding ( labels )), - 1 ) validity = self . model ( d_in ) return validity # Loss functions adversarial_loss = torch . nn . MSELoss () # Initialize generator and discriminator generator = Generator () discriminator = Discriminator () if cuda : generator . cuda () discriminator . cuda () adversarial_loss . cuda () # Configure data loader os . makedirs ( \"../../data/mnist\" , exist_ok = True ) dataloader = torch . utils . data . DataLoader ( datasets . MNIST ( \"../../data/mnist\" , train = True , download = True , transform = transforms . Compose ( [ transforms . Resize ( opt . img_size ), transforms . ToTensor (), transforms . Normalize ([ 0.5 ], [ 0.5 ])] ), ), batch_size = opt . batch_size , shuffle = True , ) # Optimizers optimizer_G = torch . optim . Adam ( generator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) optimizer_D = torch . optim . Adam ( discriminator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) FloatTensor = torch . cuda . FloatTensor if cuda else torch . FloatTensor LongTensor = torch . cuda . LongTensor if cuda else torch . LongTensor def sample_image ( n_row , batches_done ): \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\" # Sample noise z = Variable ( FloatTensor ( np . random . normal ( 0 , 1 , ( n_row ** 2 , opt . latent_dim )))) # Get labels ranging from 0 to n_classes for n rows labels = np . array ([ num for _ in range ( n_row ) for num in range ( n_row )]) labels = Variable ( LongTensor ( labels )) gen_imgs = generator ( z , labels ) save_image ( gen_imgs . data , \"images/ %d .png\" % batches_done , nrow = n_row , normalize = True ) # ---------- # Training # ---------- for epoch in range ( opt . n_epochs ): for i , ( imgs , labels ) in enumerate ( dataloader ): batch_size = imgs . shape [ 0 ] # Adversarial ground truths valid = Variable ( FloatTensor ( batch_size , 1 ) . fill_ ( 1.0 ), requires_grad = False ) fake = Variable ( FloatTensor ( batch_size , 1 ) . fill_ ( 0.0 ), requires_grad = False ) # Configure input real_imgs = Variable ( imgs . type ( FloatTensor )) labels = Variable ( labels . type ( LongTensor )) # ----------------- # Train Generator # ----------------- optimizer_G . zero_grad () # Sample noise and labels as generator input z = Variable ( FloatTensor ( np . random . normal ( 0 , 1 , ( batch_size , opt . latent_dim )))) gen_labels = Variable ( LongTensor ( np . random . randint ( 0 , opt . n_classes , batch_size ))) # Generate a batch of images gen_imgs = generator ( z , gen_labels ) # Loss measures generator's ability to fool the discriminator validity = discriminator ( gen_imgs , gen_labels ) g_loss = adversarial_loss ( validity , valid ) g_loss . backward () optimizer_G . step () # --------------------- # Train Discriminator # --------------------- optimizer_D . zero_grad () # Loss for real images validity_real = discriminator ( real_imgs , labels ) d_real_loss = adversarial_loss ( validity_real , valid ) # Loss for fake images validity_fake = discriminator ( gen_imgs . detach (), gen_labels ) d_fake_loss = adversarial_loss ( validity_fake , fake ) # Total discriminator loss d_loss = ( d_real_loss + d_fake_loss ) / 2 d_loss . backward () optimizer_D . step () print ( \"[Epoch %d / %d ] [Batch %d / %d ] [D loss: %f ] [G loss: %f ]\" % ( epoch , opt . n_epochs , i , len ( dataloader ), d_loss . item (), g_loss . item ()) ) batches_done = epoch * len ( dataloader ) + i if batches_done % opt . sample_interval == 0 : sample_image ( n_row = 10 , batches_done = batches_done ) Cycle GAN Star GAN Progressive GAN Pix2Pix","title":"other"},{"location":"dcgan/#dcgan","text":"G\u30e2\u30c7\u30eb\u3068D\u30e2\u30c7\u30eb\u306e\u5185\u90e8\u306b\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u3092\u4f7f\u308f\u306a\u3044\u7573\u307f\u8fbc\u307f\u3084\u8ee2\u79fb\u7573\u307f\u8fbc\u307f\u3092\u5229\u7528 \u5168\u7d50\u5408\u5c64\u306f\u5229\u7528\u3057\u306a\u3044\uff08\u30d7\u30fc\u30ea\u30f3\u30b0\u51e6\u7406\u306b\u3088\u308b\u7d30\u304b\u306a\u60c5\u5831\u304c\u6b20\u843d\u3059\u308b\u306e\u3092\u9632\u3050\u305f\u3081\u3002\uff09 \u30d0\u30c3\u30c1\u6b63\u898f\u5316\u3092\u5229\u7528 G\u30e2\u30c7\u30eb\u306e\u51fa\u529b\u5c64\u3092tanh\u95a2\u6570\u306b\u4ee3\u7528 D\u30e2\u30c7\u30eb\u306e\u6d3b\u6027\u5316\u95a2\u6570\u3092leaky relu\u306b\u4ee3\u7528 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 import argparse import os import numpy as np import math import torchvision.transforms as transforms from torchvision.utils import save_image from torch.utils.data import DataLoader from torchvision import datasets from torch.autograd import Variable import torch.nn as nn import torch.nn.functional as F import torch os . makedirs ( \"images\" , exist_ok = True ) parser = argparse . ArgumentParser () parser . add_argument ( \"--n_epochs\" , type = int , default = 200 , help = \"number of epochs of training\" ) parser . add_argument ( \"--batch_size\" , type = int , default = 64 , help = \"size of the batches\" ) parser . add_argument ( \"--lr\" , type = float , default = 0.0002 , help = \"adam: learning rate\" ) parser . add_argument ( \"--b1\" , type = float , default = 0.5 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--b2\" , type = float , default = 0.999 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--n_cpu\" , type = int , default = 8 , help = \"number of cpu threads to use during batch generation\" ) parser . add_argument ( \"--latent_dim\" , type = int , default = 100 , help = \"dimensionality of the latent space\" ) parser . add_argument ( \"--img_size\" , type = int , default = 32 , help = \"size of each image dimension\" ) parser . add_argument ( \"--channels\" , type = int , default = 1 , help = \"number of image channels\" ) parser . add_argument ( \"--sample_interval\" , type = int , default = 400 , help = \"interval between image sampling\" ) opt = parser . parse_args () print ( opt ) cuda = True if torch . cuda . is_available () else False def weights_init_normal ( m ): classname = m . __class__ . __name__ if classname . find ( \"Conv\" ) != - 1 : torch . nn . init . normal_ ( m . weight . data , 0.0 , 0.02 ) elif classname . find ( \"BatchNorm2d\" ) != - 1 : torch . nn . init . normal_ ( m . weight . data , 1.0 , 0.02 ) torch . nn . init . constant_ ( m . bias . data , 0.0 ) class Generator ( nn . Module ): def __init__ ( self ): super ( Generator , self ) . __init__ () self . init_size = opt . img_size // 4 self . l1 = nn . Sequential ( nn . Linear ( opt . latent_dim , 128 * self . init_size ** 2 )) self . conv_blocks = nn . Sequential ( nn . BatchNorm2d ( 128 ), nn . Upsample ( scale_factor = 2 ), nn . Conv2d ( 128 , 128 , 3 , stride = 1 , padding = 1 ), nn . BatchNorm2d ( 128 , 0.8 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Upsample ( scale_factor = 2 ), nn . Conv2d ( 128 , 64 , 3 , stride = 1 , padding = 1 ), nn . BatchNorm2d ( 64 , 0.8 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Conv2d ( 64 , opt . channels , 3 , stride = 1 , padding = 1 ), nn . Tanh (), ) def forward ( self , z ): out = self . l1 ( z ) out = out . view ( out . shape [ 0 ], 128 , self . init_size , self . init_size ) img = self . conv_blocks ( out ) return img class Discriminator ( nn . Module ): def __init__ ( self ): super ( Discriminator , self ) . __init__ () def discriminator_block ( in_filters , out_filters , bn = True ): block = [ nn . Conv2d ( in_filters , out_filters , 3 , 2 , 1 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Dropout2d ( 0.25 )] if bn : block . append ( nn . BatchNorm2d ( out_filters , 0.8 )) return block self . model = nn . Sequential ( * discriminator_block ( opt . channels , 16 , bn = False ), * discriminator_block ( 16 , 32 ), * discriminator_block ( 32 , 64 ), * discriminator_block ( 64 , 128 ), ) # The height and width of downsampled image ds_size = opt . img_size // 2 ** 4 self . adv_layer = nn . Sequential ( nn . Linear ( 128 * ds_size ** 2 , 1 ), nn . Sigmoid ()) def forward ( self , img ): out = self . model ( img ) out = out . view ( out . shape [ 0 ], - 1 ) validity = self . adv_layer ( out ) return validity # Loss function adversarial_loss = torch . nn . BCELoss () # Initialize generator and discriminator generator = Generator () discriminator = Discriminator () if cuda : generator . cuda () discriminator . cuda () adversarial_loss . cuda () # Initialize weights generator . apply ( weights_init_normal ) discriminator . apply ( weights_init_normal ) # Configure data loader os . makedirs ( \"../../data/mnist\" , exist_ok = True ) dataloader = torch . utils . data . DataLoader ( datasets . MNIST ( \"../../data/mnist\" , train = True , download = True , transform = transforms . Compose ( [ transforms . Resize ( opt . img_size ), transforms . ToTensor (), transforms . Normalize ([ 0.5 ], [ 0.5 ])] ), ), batch_size = opt . batch_size , shuffle = True , ) # Optimizers optimizer_G = torch . optim . Adam ( generator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) optimizer_D = torch . optim . Adam ( discriminator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) Tensor = torch . cuda . FloatTensor if cuda else torch . FloatTensor # ---------- # Training # ---------- for epoch in range ( opt . n_epochs ): for i , ( imgs , _ ) in enumerate ( dataloader ): # Adversarial ground truths valid = Variable ( Tensor ( imgs . shape [ 0 ], 1 ) . fill_ ( 1.0 ), requires_grad = False ) fake = Variable ( Tensor ( imgs . shape [ 0 ], 1 ) . fill_ ( 0.0 ), requires_grad = False ) # Configure input real_imgs = Variable ( imgs . type ( Tensor )) # ----------------- # Train Generator # ----------------- optimizer_G . zero_grad () # Sample noise as generator input z = Variable ( Tensor ( np . random . normal ( 0 , 1 , ( imgs . shape [ 0 ], opt . latent_dim )))) # Generate a batch of images gen_imgs = generator ( z ) # Loss measures generator's ability to fool the discriminator g_loss = adversarial_loss ( discriminator ( gen_imgs ), valid ) g_loss . backward () optimizer_G . step () # --------------------- # Train Discriminator # --------------------- optimizer_D . zero_grad () # Measure discriminator's ability to classify real from generated samples real_loss = adversarial_loss ( discriminator ( real_imgs ), valid ) fake_loss = adversarial_loss ( discriminator ( gen_imgs . detach ()), fake ) d_loss = ( real_loss + fake_loss ) / 2 d_loss . backward () optimizer_D . step () print ( \"[Epoch %d / %d ] [Batch %d / %d ] [D loss: %f ] [G loss: %f ]\" % ( epoch , opt . n_epochs , i , len ( dataloader ), d_loss . item (), g_loss . item ()) ) batches_done = epoch * len ( dataloader ) + i if batches_done % opt . sample_interval == 0 : save_image ( gen_imgs . data [: 25 ], \"images/ %d .png\" % batches_done , nrow = 5 , normalize = True ) Conditional GAN 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 import argparse import os import numpy as np import math import torchvision.transforms as transforms from torchvision.utils import save_image from torch.utils.data import DataLoader from torchvision import datasets from torch.autograd import Variable import torch.nn as nn import torch.nn.functional as F import torch os . makedirs ( \"images\" , exist_ok = True ) parser = argparse . ArgumentParser () parser . add_argument ( \"--n_epochs\" , type = int , default = 200 , help = \"number of epochs of training\" ) parser . add_argument ( \"--batch_size\" , type = int , default = 64 , help = \"size of the batches\" ) parser . add_argument ( \"--lr\" , type = float , default = 0.0002 , help = \"adam: learning rate\" ) parser . add_argument ( \"--b1\" , type = float , default = 0.5 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--b2\" , type = float , default = 0.999 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--n_cpu\" , type = int , default = 8 , help = \"number of cpu threads to use during batch generation\" ) parser . add_argument ( \"--latent_dim\" , type = int , default = 100 , help = \"dimensionality of the latent space\" ) parser . add_argument ( \"--n_classes\" , type = int , default = 10 , help = \"number of classes for dataset\" ) parser . add_argument ( \"--img_size\" , type = int , default = 32 , help = \"size of each image dimension\" ) parser . add_argument ( \"--channels\" , type = int , default = 1 , help = \"number of image channels\" ) parser . add_argument ( \"--sample_interval\" , type = int , default = 400 , help = \"interval between image sampling\" ) opt = parser . parse_args () print ( opt ) img_shape = ( opt . channels , opt . img_size , opt . img_size ) cuda = True if torch . cuda . is_available () else False class Generator ( nn . Module ): def __init__ ( self ): super ( Generator , self ) . __init__ () self . label_emb = nn . Embedding ( opt . n_classes , opt . n_classes ) def block ( in_feat , out_feat , normalize = True ): layers = [ nn . Linear ( in_feat , out_feat )] if normalize : layers . append ( nn . BatchNorm1d ( out_feat , 0.8 )) layers . append ( nn . LeakyReLU ( 0.2 , inplace = True )) return layers self . model = nn . Sequential ( * block ( opt . latent_dim + opt . n_classes , 128 , normalize = False ), * block ( 128 , 256 ), * block ( 256 , 512 ), * block ( 512 , 1024 ), nn . Linear ( 1024 , int ( np . prod ( img_shape ))), nn . Tanh () ) def forward ( self , noise , labels ): # Concatenate label embedding and image to produce input gen_input = torch . cat (( self . label_emb ( labels ), noise ), - 1 ) img = self . model ( gen_input ) img = img . view ( img . size ( 0 ), * img_shape ) return img class Discriminator ( nn . Module ): def __init__ ( self ): super ( Discriminator , self ) . __init__ () self . label_embedding = nn . Embedding ( opt . n_classes , opt . n_classes ) self . model = nn . Sequential ( nn . Linear ( opt . n_classes + int ( np . prod ( img_shape )), 512 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 512 ), nn . Dropout ( 0.4 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 512 ), nn . Dropout ( 0.4 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 1 ), ) def forward ( self , img , labels ): # Concatenate label embedding and image to produce input d_in = torch . cat (( img . view ( img . size ( 0 ), - 1 ), self . label_embedding ( labels )), - 1 ) validity = self . model ( d_in ) return validity # Loss functions adversarial_loss = torch . nn . MSELoss () # Initialize generator and discriminator generator = Generator () discriminator = Discriminator () if cuda : generator . cuda () discriminator . cuda () adversarial_loss . cuda () # Configure data loader os . makedirs ( \"../../data/mnist\" , exist_ok = True ) dataloader = torch . utils . data . DataLoader ( datasets . MNIST ( \"../../data/mnist\" , train = True , download = True , transform = transforms . Compose ( [ transforms . Resize ( opt . img_size ), transforms . ToTensor (), transforms . Normalize ([ 0.5 ], [ 0.5 ])] ), ), batch_size = opt . batch_size , shuffle = True , ) # Optimizers optimizer_G = torch . optim . Adam ( generator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) optimizer_D = torch . optim . Adam ( discriminator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) FloatTensor = torch . cuda . FloatTensor if cuda else torch . FloatTensor LongTensor = torch . cuda . LongTensor if cuda else torch . LongTensor def sample_image ( n_row , batches_done ): \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\" # Sample noise z = Variable ( FloatTensor ( np . random . normal ( 0 , 1 , ( n_row ** 2 , opt . latent_dim )))) # Get labels ranging from 0 to n_classes for n rows labels = np . array ([ num for _ in range ( n_row ) for num in range ( n_row )]) labels = Variable ( LongTensor ( labels )) gen_imgs = generator ( z , labels ) save_image ( gen_imgs . data , \"images/ %d .png\" % batches_done , nrow = n_row , normalize = True ) # ---------- # Training # ---------- for epoch in range ( opt . n_epochs ): for i , ( imgs , labels ) in enumerate ( dataloader ): batch_size = imgs . shape [ 0 ] # Adversarial ground truths valid = Variable ( FloatTensor ( batch_size , 1 ) . fill_ ( 1.0 ), requires_grad = False ) fake = Variable ( FloatTensor ( batch_size , 1 ) . fill_ ( 0.0 ), requires_grad = False ) # Configure input real_imgs = Variable ( imgs . type ( FloatTensor )) labels = Variable ( labels . type ( LongTensor )) # ----------------- # Train Generator # ----------------- optimizer_G . zero_grad () # Sample noise and labels as generator input z = Variable ( FloatTensor ( np . random . normal ( 0 , 1 , ( batch_size , opt . latent_dim )))) gen_labels = Variable ( LongTensor ( np . random . randint ( 0 , opt . n_classes , batch_size ))) # Generate a batch of images gen_imgs = generator ( z , gen_labels ) # Loss measures generator's ability to fool the discriminator validity = discriminator ( gen_imgs , gen_labels ) g_loss = adversarial_loss ( validity , valid ) g_loss . backward () optimizer_G . step () # --------------------- # Train Discriminator # --------------------- optimizer_D . zero_grad () # Loss for real images validity_real = discriminator ( real_imgs , labels ) d_real_loss = adversarial_loss ( validity_real , valid ) # Loss for fake images validity_fake = discriminator ( gen_imgs . detach (), gen_labels ) d_fake_loss = adversarial_loss ( validity_fake , fake ) # Total discriminator loss d_loss = ( d_real_loss + d_fake_loss ) / 2 d_loss . backward () optimizer_D . step () print ( \"[Epoch %d / %d ] [Batch %d / %d ] [D loss: %f ] [G loss: %f ]\" % ( epoch , opt . n_epochs , i , len ( dataloader ), d_loss . item (), g_loss . item ()) ) batches_done = epoch * len ( dataloader ) + i if batches_done % opt . sample_interval == 0 : sample_image ( n_row = 10 , batches_done = batches_done ) WGAN 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 import argparse import os import numpy as np import math import torchvision.transforms as transforms from torchvision.utils import save_image from torch.utils.data import DataLoader from torchvision import datasets from torch.autograd import Variable import torch.nn as nn import torch.nn.functional as F import torch os . makedirs ( \"images\" , exist_ok = True ) parser = argparse . ArgumentParser () parser . add_argument ( \"--n_epochs\" , type = int , default = 200 , help = \"number of epochs of training\" ) parser . add_argument ( \"--batch_size\" , type = int , default = 64 , help = \"size of the batches\" ) parser . add_argument ( \"--lr\" , type = float , default = 0.0002 , help = \"adam: learning rate\" ) parser . add_argument ( \"--b1\" , type = float , default = 0.5 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--b2\" , type = float , default = 0.999 , help = \"adam: decay of first order momentum of gradient\" ) parser . add_argument ( \"--n_cpu\" , type = int , default = 8 , help = \"number of cpu threads to use during batch generation\" ) parser . add_argument ( \"--latent_dim\" , type = int , default = 100 , help = \"dimensionality of the latent space\" ) parser . add_argument ( \"--n_classes\" , type = int , default = 10 , help = \"number of classes for dataset\" ) parser . add_argument ( \"--img_size\" , type = int , default = 32 , help = \"size of each image dimension\" ) parser . add_argument ( \"--channels\" , type = int , default = 1 , help = \"number of image channels\" ) parser . add_argument ( \"--sample_interval\" , type = int , default = 400 , help = \"interval between image sampling\" ) opt = parser . parse_args () print ( opt ) img_shape = ( opt . channels , opt . img_size , opt . img_size ) cuda = True if torch . cuda . is_available () else False class Generator ( nn . Module ): def __init__ ( self ): super ( Generator , self ) . __init__ () self . label_emb = nn . Embedding ( opt . n_classes , opt . n_classes ) def block ( in_feat , out_feat , normalize = True ): layers = [ nn . Linear ( in_feat , out_feat )] if normalize : layers . append ( nn . BatchNorm1d ( out_feat , 0.8 )) layers . append ( nn . LeakyReLU ( 0.2 , inplace = True )) return layers self . model = nn . Sequential ( * block ( opt . latent_dim + opt . n_classes , 128 , normalize = False ), * block ( 128 , 256 ), * block ( 256 , 512 ), * block ( 512 , 1024 ), nn . Linear ( 1024 , int ( np . prod ( img_shape ))), nn . Tanh () ) def forward ( self , noise , labels ): # Concatenate label embedding and image to produce input gen_input = torch . cat (( self . label_emb ( labels ), noise ), - 1 ) img = self . model ( gen_input ) img = img . view ( img . size ( 0 ), * img_shape ) return img class Discriminator ( nn . Module ): def __init__ ( self ): super ( Discriminator , self ) . __init__ () self . label_embedding = nn . Embedding ( opt . n_classes , opt . n_classes ) self . model = nn . Sequential ( nn . Linear ( opt . n_classes + int ( np . prod ( img_shape )), 512 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 512 ), nn . Dropout ( 0.4 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 512 ), nn . Dropout ( 0.4 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 1 ), ) def forward ( self , img , labels ): # Concatenate label embedding and image to produce input d_in = torch . cat (( img . view ( img . size ( 0 ), - 1 ), self . label_embedding ( labels )), - 1 ) validity = self . model ( d_in ) return validity # Loss functions adversarial_loss = torch . nn . MSELoss () # Initialize generator and discriminator generator = Generator () discriminator = Discriminator () if cuda : generator . cuda () discriminator . cuda () adversarial_loss . cuda () # Configure data loader os . makedirs ( \"../../data/mnist\" , exist_ok = True ) dataloader = torch . utils . data . DataLoader ( datasets . MNIST ( \"../../data/mnist\" , train = True , download = True , transform = transforms . Compose ( [ transforms . Resize ( opt . img_size ), transforms . ToTensor (), transforms . Normalize ([ 0.5 ], [ 0.5 ])] ), ), batch_size = opt . batch_size , shuffle = True , ) # Optimizers optimizer_G = torch . optim . Adam ( generator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) optimizer_D = torch . optim . Adam ( discriminator . parameters (), lr = opt . lr , betas = ( opt . b1 , opt . b2 )) FloatTensor = torch . cuda . FloatTensor if cuda else torch . FloatTensor LongTensor = torch . cuda . LongTensor if cuda else torch . LongTensor def sample_image ( n_row , batches_done ): \"\"\"Saves a grid of generated digits ranging from 0 to n_classes\"\"\" # Sample noise z = Variable ( FloatTensor ( np . random . normal ( 0 , 1 , ( n_row ** 2 , opt . latent_dim )))) # Get labels ranging from 0 to n_classes for n rows labels = np . array ([ num for _ in range ( n_row ) for num in range ( n_row )]) labels = Variable ( LongTensor ( labels )) gen_imgs = generator ( z , labels ) save_image ( gen_imgs . data , \"images/ %d .png\" % batches_done , nrow = n_row , normalize = True ) # ---------- # Training # ---------- for epoch in range ( opt . n_epochs ): for i , ( imgs , labels ) in enumerate ( dataloader ): batch_size = imgs . shape [ 0 ] # Adversarial ground truths valid = Variable ( FloatTensor ( batch_size , 1 ) . fill_ ( 1.0 ), requires_grad = False ) fake = Variable ( FloatTensor ( batch_size , 1 ) . fill_ ( 0.0 ), requires_grad = False ) # Configure input real_imgs = Variable ( imgs . type ( FloatTensor )) labels = Variable ( labels . type ( LongTensor )) # ----------------- # Train Generator # ----------------- optimizer_G . zero_grad () # Sample noise and labels as generator input z = Variable ( FloatTensor ( np . random . normal ( 0 , 1 , ( batch_size , opt . latent_dim )))) gen_labels = Variable ( LongTensor ( np . random . randint ( 0 , opt . n_classes , batch_size ))) # Generate a batch of images gen_imgs = generator ( z , gen_labels ) # Loss measures generator's ability to fool the discriminator validity = discriminator ( gen_imgs , gen_labels ) g_loss = adversarial_loss ( validity , valid ) g_loss . backward () optimizer_G . step () # --------------------- # Train Discriminator # --------------------- optimizer_D . zero_grad () # Loss for real images validity_real = discriminator ( real_imgs , labels ) d_real_loss = adversarial_loss ( validity_real , valid ) # Loss for fake images validity_fake = discriminator ( gen_imgs . detach (), gen_labels ) d_fake_loss = adversarial_loss ( validity_fake , fake ) # Total discriminator loss d_loss = ( d_real_loss + d_fake_loss ) / 2 d_loss . backward () optimizer_D . step () print ( \"[Epoch %d / %d ] [Batch %d / %d ] [D loss: %f ] [G loss: %f ]\" % ( epoch , opt . n_epochs , i , len ( dataloader ), d_loss . item (), g_loss . item ()) ) batches_done = epoch * len ( dataloader ) + i if batches_done % opt . sample_interval == 0 : sample_image ( n_row = 10 , batches_done = batches_done ) Cycle GAN Star GAN Progressive GAN Pix2Pix","title":"DCGAN"},{"location":"docker/","text":"Dockerhub\u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb Dockerfile\u304b\u3089DockerImage, DockerImage\u304b\u3089\u30b3\u30f3\u30c6\u30ca docker login : dockerhub\u306b\u30ed\u30b0\u30a4\u30f3\u3059\u308b docker pull <image> dockerhub \u304b\u3089\u30a4\u30e1\u30fc\u30b8\u3092\u3068\u3063\u3066\u304f\u308b docker images dockerimage\u306e\u4e00\u89a7\u3092\u8868\u793a docker run <image> create + start, docker\u30a4\u30e1\u30fc\u30b8\u304b\u3089\u30b3\u30f3\u30c6\u30ca\u3092\u4f5c\u6210\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u30b3\u30de\u30f3\u30c9\u304c\u5b9f\u884c\u3055\u308c\u308b\u3002 docker ps -a \u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u306e\u4e00\u89a7\u3092\u8868\u793a docker run -it ubuntu bash :docker \u3067ubuntu\u306ebash\u3092\u8d77\u52d5\uff08bash\u3067\u30c7\u30d5\u30a9\u30eb\u30c8\u30b3\u30de\u30f3\u30c9\u4e0a\u66f8\u304d\uff09, -it \u306fbash\u3092\u8d77\u52d5\u72b6\u614b\uff08up\uff09\u306b\u4fdd\u6301\u3059\u308b\u3002-it\u304c\u306a\u3044\u3068exit\u72b6\u614b\u306b\u5909\u308f\u308b\u3002-i:\u6a19\u6e96\u5165\u529b\u3092\u958b\u304f\u3001-t:\u51fa\u529b\u304c\u304d\u308c\u3044\u306b\u306a\u308b\u3002 ctri + p + q :detach \u7d42\u4e86 docker attach <container> attach\u3067up\u72b6\u614b\u306econtainer\u306b\u5165\u308b\u3002 exit :\u7d42\u4e86 docker restart <container> docker exec -it <container> <command> docker commit <container> <new image> \u30b3\u30f3\u30c6\u30ca\u304b\u3089new image\u3068\u3057\u3066\u4fdd\u5b58 docker commit <container> ubuntu:updated \u30bb\u30df\u30b3\u30ed\u30f3\u3067tag\u540d\u306b\u306a\u308b image\u540d\u306frepostitory\u540d\uff0btag\u540d docker tag <source> <target> docker tag ubuntu:updated <username>/my-repo :\u540d\u524d\u306e\u5909\u66f4 library/ubuntu\u306f, \u6b63\u5f0f\u306b\u306fregistry-1.docker.io/library/ubuntu:latest docker push <image> docker pull <image> docker rmi <image> docker image \u3092\u524a\u9664 docker rm <container> \u30b3\u30f3\u30c6\u30ca\u306e\u524a\u9664 docker stop <container> \u30b3\u30f3\u30c6\u30ca\u3092\u6b62\u3081\u308b docker system prune :\u30b3\u30f3\u30c6\u30ca\u5168\u524a\u9664 docker run --name <name> <image> :\u30b3\u30f3\u30c6\u30ca\u306e\u540d\u524d\u3092\u3064\u3051\u308b\u3002 docker run -d <image> :\u30b3\u30f3\u30c6\u30ca\u3092\u8d77\u52d5\u5f8c\u306bdetach\u3059\u308b\uff08host\u306b\u623b\u308b\uff09 docker run -rm <image> :\u30b3\u30f3\u30c6\u30ca\u3092exit\u5f8c\u306b\u524a\u9664\u3059\u308b\u3002 docker file\u306e\u4f5c\u6210 \u00b6 1 2 3 4 5 6 7 8 9 10 11 FROM ubuntu:latest ADD copressed.tar / COPY something /new_directory/ ENV key1 value RUN apt update && apt install -y \\ aaa \\ bbb \\ ccc WORKDIR /sample_folder RUN touch something CMD [ \"executable\" , \"param1\" , \"param2\" ] docker build <directory> docker build -t <name> <directory> docker build -f <dockerfilename> <build context> \u540d\u524d\u306f\u30c9\u30c3\u30c8\u3067\u3064\u306a\u304c\u308b\u3053\u3068\u304c\u591a\u3044\u3002Dockerfile\u3068\u3044\u3046\u540d\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u30d3\u30eb\u30c9\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u5165\u3063\u3066\u3044\u306a\u3044\u5834\u5408\u3002 FROM :\u30d9\u30fc\u30b9\u3068\u306a\u308b\u30a4\u30e1\u30fc\u30b8\u3092\u6c7a\u5b9a RUN :Linux\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3002RUN\u6bce\u306bLayer\u304c\u4f5c\u3089\u308c\u308b\u3002Layer\u6570\u3092\u6700\u5c0f\u9650\u306b\u3059\u308b\u3002&&\u3067\u3064\u306a\u3052\u308b\u3002(\u30d1\u30c3\u30b1\u30fc\u30b8\u540d\u3092\u30a2\u30eb\u30d5\u30a1\u30d9\u30c3\u30c8\u9806\u3067)\\\u30d0\u30c3\u30af\u30b9\u30e9\u30c3\u30b7\u30e5\u3067\u6539\u884c\u3059\u308b\u3002 \u6700\u521d\u306fLayer\u3092\u7d30\u304b\u304f\u5206\u3051\u3066\u901a\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3002\u6700\u5f8c\u306bLayer\u3092\u6700\u5c0f\u9650\u306b\u3059\u308b\u3002 CMD :\u30b3\u30f3\u30c6\u30ca\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u30b3\u30de\u30f3\u30c9\u3092\u6307\u5b9a\u3002CMD [\"command\", \"param1\", \"paramn2\"] ex. CMD [/bin/bash], CMD\u306f\u30ec\u30a4\u30e4\u30fc\u3092\u4f5c\u3089\u306a\u3044\u3002 Docker\u30b3\u30de\u30f3\u30c9\u3067Docker Daemon\u306b\u547d\u4ee4\u3092\u51fa\u3059 * COPY: \u5358\u7d14\u306b\u30d5\u30a1\u30a4\u30eb\u3084\u30d5\u30a9\u30eb\u30c0\u3092\u30b3\u30d4\u30fc\u3059\u308b\u5834\u5408 * ADD: tar\u306e\u5727\u7e2e\u30d5\u30a1\u30a4\u30eb\u3092\u89e3\u7b54\u3059\u308b ENTRYPOINT \u306f\u4e0a\u66f8\u304d\u3067\u304d\u306a\u3044\uff08CMD\u306f\u4e0a\u66f8\u304d\u3067\u304d\u308b\uff09\u3002ENTRYPOINT\u304c\u3042\u308b\u3068\u304d\u306fCMD\u306fparams\u306e\u307f\u3092\u66f8\u304f\u3002 ENTRYPOINT\u306f\u30b3\u30f3\u30c6\u30ca\u3092\u30b3\u30de\u30f3\u30c9\u306e\u3088\u3046\u306b\u4f7f\u3044\u305f\u3044\u3068\u304d\u3002 ENV :\u74b0\u5883\u5909\u6570\u3092\u8a2d\u5b9a\u3059\u308b\u3002 WORKDIR \u5b9f\u884c\u74b0\u5883\u3092\u5909\u66f4\u3059\u308b\u3002 \u30db\u30b9\u30c8\u3068\u30b3\u30f3\u30c6\u30ca\u3092\u3064\u306a\u3050 \u00b6 docker run -it -v <host>:<container> <image bash> docker run -it -u $(id -u):$(id -g) -v ~/mouted_folder:/new_dir <image> bash -u <uder id>:<group id>: \u30e6\u30fc\u30b6ID\u3068\u30b0\u30eb\u30fc\u30d7ID\u3092\u6307\u5b9a\u3059\u308b -p <host_port>:<container_port> docker run -it -p 8888:8888 --rm jupyter/datascience-notebook bash docker run -it --rm --cpus 4 --memory 2g ubuntu bash docker inspect <container> | grep -i cpu \u30ed\u30fc\u30ab\u30eb\u3067\u74b0\u5883\u69cb\u7bc9 \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 FROM ubuntu:latest RUN apt-get update && apt-get install -y \\ sudo \\ wget \\ vim WORKDIR /opt RUN wget https://repo.continuum.io/archive/Anaconda3-2019.10-Linux-x86_64.sh && \\ sh /opt/Anaconda3-2019.10-Linux-x86_64.sh -b -p /opt/anaconda3 \\ rm -f Anaconda3-2019.10-Linux-x86_64.sh ENV PATH /opt/anaconda3/bin: $PATH RUN pip install --upgrade pip WORKDIR / CMD [ \"jupyter\" , \"lab\" , \"--ip=0.0.0.0\" , \"--allow-root\" , \"--LabAPP.token=''\" ] docker run -p 8888:8888 -v ~/Desktop/ds-pyhton:/work --name my-lab <container> GPU\u74b0\u5883\u4f8b \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04 RUN apt-get update && apt-get install -y \\ sudo \\ wget \\ vim WORKDIR /opt RUN wget https://repo.continuum.io/archive/Anaconda3-2019.10-Linux-x86_64.sh && \\ sh /opt/Anaconda3-2019.10-Linux-x86_64.sh -b -p /opt/anaconda3 \\ rm -f Anaconda3-2019.10-Linux-x86_64.sh ENV PATH /opt/anaconda3/bin: $PATH RUN pip install --upgrade pip && pip install \\ keras == 2 .3 \\ scipy == 1 .4.1 \\ tensorflow-gpu == 2 .1 WORKDIR / CMD [ \"jupyter\" , \"lab\" , \"--ip=0.0.0.0\" , \"--allow-root\" , \"--LabAPP.token=''\" ]","title":"Docker"},{"location":"docker/#docker-file","text":"1 2 3 4 5 6 7 8 9 10 11 FROM ubuntu:latest ADD copressed.tar / COPY something /new_directory/ ENV key1 value RUN apt update && apt install -y \\ aaa \\ bbb \\ ccc WORKDIR /sample_folder RUN touch something CMD [ \"executable\" , \"param1\" , \"param2\" ] docker build <directory> docker build -t <name> <directory> docker build -f <dockerfilename> <build context> \u540d\u524d\u306f\u30c9\u30c3\u30c8\u3067\u3064\u306a\u304c\u308b\u3053\u3068\u304c\u591a\u3044\u3002Dockerfile\u3068\u3044\u3046\u540d\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u30d3\u30eb\u30c9\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u5165\u3063\u3066\u3044\u306a\u3044\u5834\u5408\u3002 FROM :\u30d9\u30fc\u30b9\u3068\u306a\u308b\u30a4\u30e1\u30fc\u30b8\u3092\u6c7a\u5b9a RUN :Linux\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3002RUN\u6bce\u306bLayer\u304c\u4f5c\u3089\u308c\u308b\u3002Layer\u6570\u3092\u6700\u5c0f\u9650\u306b\u3059\u308b\u3002&&\u3067\u3064\u306a\u3052\u308b\u3002(\u30d1\u30c3\u30b1\u30fc\u30b8\u540d\u3092\u30a2\u30eb\u30d5\u30a1\u30d9\u30c3\u30c8\u9806\u3067)\\\u30d0\u30c3\u30af\u30b9\u30e9\u30c3\u30b7\u30e5\u3067\u6539\u884c\u3059\u308b\u3002 \u6700\u521d\u306fLayer\u3092\u7d30\u304b\u304f\u5206\u3051\u3066\u901a\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3002\u6700\u5f8c\u306bLayer\u3092\u6700\u5c0f\u9650\u306b\u3059\u308b\u3002 CMD :\u30b3\u30f3\u30c6\u30ca\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u30b3\u30de\u30f3\u30c9\u3092\u6307\u5b9a\u3002CMD [\"command\", \"param1\", \"paramn2\"] ex. CMD [/bin/bash], CMD\u306f\u30ec\u30a4\u30e4\u30fc\u3092\u4f5c\u3089\u306a\u3044\u3002 Docker\u30b3\u30de\u30f3\u30c9\u3067Docker Daemon\u306b\u547d\u4ee4\u3092\u51fa\u3059 * COPY: \u5358\u7d14\u306b\u30d5\u30a1\u30a4\u30eb\u3084\u30d5\u30a9\u30eb\u30c0\u3092\u30b3\u30d4\u30fc\u3059\u308b\u5834\u5408 * ADD: tar\u306e\u5727\u7e2e\u30d5\u30a1\u30a4\u30eb\u3092\u89e3\u7b54\u3059\u308b ENTRYPOINT \u306f\u4e0a\u66f8\u304d\u3067\u304d\u306a\u3044\uff08CMD\u306f\u4e0a\u66f8\u304d\u3067\u304d\u308b\uff09\u3002ENTRYPOINT\u304c\u3042\u308b\u3068\u304d\u306fCMD\u306fparams\u306e\u307f\u3092\u66f8\u304f\u3002 ENTRYPOINT\u306f\u30b3\u30f3\u30c6\u30ca\u3092\u30b3\u30de\u30f3\u30c9\u306e\u3088\u3046\u306b\u4f7f\u3044\u305f\u3044\u3068\u304d\u3002 ENV :\u74b0\u5883\u5909\u6570\u3092\u8a2d\u5b9a\u3059\u308b\u3002 WORKDIR \u5b9f\u884c\u74b0\u5883\u3092\u5909\u66f4\u3059\u308b\u3002","title":"docker file\u306e\u4f5c\u6210"},{"location":"docker/#_1","text":"docker run -it -v <host>:<container> <image bash> docker run -it -u $(id -u):$(id -g) -v ~/mouted_folder:/new_dir <image> bash -u <uder id>:<group id>: \u30e6\u30fc\u30b6ID\u3068\u30b0\u30eb\u30fc\u30d7ID\u3092\u6307\u5b9a\u3059\u308b -p <host_port>:<container_port> docker run -it -p 8888:8888 --rm jupyter/datascience-notebook bash docker run -it --rm --cpus 4 --memory 2g ubuntu bash docker inspect <container> | grep -i cpu","title":"\u30db\u30b9\u30c8\u3068\u30b3\u30f3\u30c6\u30ca\u3092\u3064\u306a\u3050"},{"location":"docker/#_2","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 FROM ubuntu:latest RUN apt-get update && apt-get install -y \\ sudo \\ wget \\ vim WORKDIR /opt RUN wget https://repo.continuum.io/archive/Anaconda3-2019.10-Linux-x86_64.sh && \\ sh /opt/Anaconda3-2019.10-Linux-x86_64.sh -b -p /opt/anaconda3 \\ rm -f Anaconda3-2019.10-Linux-x86_64.sh ENV PATH /opt/anaconda3/bin: $PATH RUN pip install --upgrade pip WORKDIR / CMD [ \"jupyter\" , \"lab\" , \"--ip=0.0.0.0\" , \"--allow-root\" , \"--LabAPP.token=''\" ] docker run -p 8888:8888 -v ~/Desktop/ds-pyhton:/work --name my-lab <container>","title":"\u30ed\u30fc\u30ab\u30eb\u3067\u74b0\u5883\u69cb\u7bc9"},{"location":"docker/#gpu","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04 RUN apt-get update && apt-get install -y \\ sudo \\ wget \\ vim WORKDIR /opt RUN wget https://repo.continuum.io/archive/Anaconda3-2019.10-Linux-x86_64.sh && \\ sh /opt/Anaconda3-2019.10-Linux-x86_64.sh -b -p /opt/anaconda3 \\ rm -f Anaconda3-2019.10-Linux-x86_64.sh ENV PATH /opt/anaconda3/bin: $PATH RUN pip install --upgrade pip && pip install \\ keras == 2 .3 \\ scipy == 1 .4.1 \\ tensorflow-gpu == 2 .1 WORKDIR / CMD [ \"jupyter\" , \"lab\" , \"--ip=0.0.0.0\" , \"--allow-root\" , \"--LabAPP.token=''\" ]","title":"GPU\u74b0\u5883\u4f8b"},{"location":"gan/","text":"\u751f\u6210\u30e2\u30c7\u30eb \u00b6 \u751f\u6210\u30e2\u30c7\u30eb\u3068\u306f\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u3069\u306e\u3088\u3046\u306b\u751f\u6210\u3055\u308c\u308b\u304b\u78ba\u7387\u30e2\u30c7\u30eb\u306e\u89b3\u70b9\u304b\u3089\u8a18\u8ff0\u3059\u308b\u3002\u6f5c\u5728\u7a7a\u9593\u304b\u3089\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b\u3053\u3068\u3067\u65b0\u3057\u3044\u30c7\u30fc\u30bf\u3092\u751f\u6210\u3002 Note \u8b58\u5225\u30e2\u30c7\u30ea\u30f3\u30b0 \uff1a \\(p(y|\\textbf{x})\\) \uff08\u89b3\u6e2c \\(\\textbf{x}\\) \u304c\u4e0e\u3048\u3089\u308c\u305f\u3068\u304d\u306e\u30e9\u30d9\u30eb \\(y\\) \u306e\u78ba\u7387\uff09\u3092\u63a8\u5b9a\u3059\u308b\u3002\uff08\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\uff09 \u751f\u6210\u30e2\u30c7\u30ea\u30f3\u30b0 \uff1a \\(p(\\textbf{x})\\) \uff08\u89b3\u6e2c \\(\\textbf{x}\\) \u304c\u89b3\u6e2c\u3055\u308c\u308b\u78ba\u7387\uff09\u3092\u63a8\u5b9a\u3059\u308b\u3002\uff08\u6559\u5e2b\u306a\u3057\u5b66\u7fd2\uff09 \u6f5c\u5728\u5909\u6570\u3068\u306f\u751f\u6210\u753b\u50cf\u306e\u5143\u306b\u306a\u308b\u6b21\u5143\u524a\u6e1b\u3055\u308c\u305f\u7279\u5fb4\u91cf VAE\u306f\u6f5c\u5728\u5909\u6570\u3092\u6b63\u898f\u5206\u5e03\u3068\u4eee\u5b9a \u5909\u5206\u30aa\u30fc\u30c8\u30a8\u30f3\u30b3\u30fc\u30c0\u30fc \u00b6 \u6f5c\u5728\u7a7a\u9593\u304c\u6b63\u898f\u5206\u5e03 GAN \u00b6 \u8b58\u5225\u5668\u306e\u8a13\u7df4 \u00b6 \u8a13\u7df4\u30c7\u30fc\u30bf\u304b\u3089\u30e9\u30f3\u30c0\u30e0\u306b\u672c\u7269\u306e\u30b5\u30f3\u30d7\u30ebx\u3092\u53d6\u308a\u51fa\u3059 \u65b0\u3057\u3044\u4e71\u6570\u304b\u3089\u751f\u6210\u5668\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u507d\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u751f\u6210 \u8b58\u5225\u5668\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f7f\u3063\u3066x\u3068x*\u3092\u5206\u985e\u3057\u3001\u8aa4\u5dee\u9006\u4f1d\u642c\u3057\u3066\u5206\u985e\u8aa4\u5dee\u3092\u6700\u5927\u5316 \\(p_G(x_i|\\textbf{z})\\) \u3092 \\(p_{r}(x)\\) \u306b\u8fd1\u3065\u3051\u3066\u3044\u304f\u305f\u3081\u306e\u6307\u6a19\u3068\u3057\u3066Kullback\u2013Leibler divergence\uff08\u78ba\u7387\u5bc6\u5ea6\u95a2\u6570\u306e\u8ddd\u96e2\u306e\u5c3a\u5ea6\uff09\u3068Jensen\u2013Shannon (JS)divergence\u304c\u3042\u308b\u3002GAN\u306e\u640d\u5931\u95a2\u6570\u306f\u751f\u6210\u5668\u306eJS divergence\u306e\u6700\u5c0f\u5316\uff08\u8b58\u5225\u5668\u304b\u3089\u898b\u3066\u6700\u5927\u5316\uff09\u304b\u3089\u5c0e\u304b\u308c\u308b\u3002 GAN\u306e\u640d\u5931\u95a2\u6570 \u00b6 \\[\\min_{G}\\max_{D} E_{x\\sim p_r} [\\log D(z)] + E_{x\\sim p_z} [\\log (1-D(G(z)))]\\] \u751f\u6210\u5668\u306e\u8a13\u7df4 \u00b6 \u65b0\u3057\u3044\u4e71\u6570\u304b\u3089\u751f\u6210\u5668\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u507d\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u751f\u6210\uff08- \u30c7\u30fc\u30bf\u304c\u5f93\u3046\u78ba\u7387\u5206\u5e03 \\(p_{r}(x)\\) \u305d\u306e\u3082\u306e\u306f\u308f\u304b\u3089\u306a\u3044\u306e\u3067\u751f\u6210\u5668\u306e\u78ba\u7387 \\(p_G(x_i|\\textbf{z})\\) \u3067\u8fd1\u4f3c\u3059\u308b\u3002\uff09 \u8b58\u5225\u5668\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7528\u3044\u3066x*\u304c\u672c\u7269\u304b\u63a8\u5b9a \u8b58\u5225\u5668\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f7f\u3063\u3066x\u3068x*\u3092\u5206\u985e\u3057\u3001\u8aa4\u5dee\u9006\u4f1d\u642c\u3057\u3066\u5206\u985e\u8aa4\u5dee\u3092\u6700\u5c0f\u5316 https://www.iangoodfellow.com/slides/2019-05-07.pdf GAN\u306e\u53ce\u675f\u6761\u4ef6 \u00b6 \u30ca\u30c3\u30b7\u30e5\u5747\u8861 -\u3000\u751f\u6210\u5668\u304c\u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u4e2d\u306b\u3042\u308b\u672c\u7269\u306e\u30b5\u30f3\u30d7\u30eb\u3068\u898b\u5206\u3051\u304c\u3064\u304b\u306a\u3044\u507d\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u751f\u6210\u3059\u308b \u8b58\u5225\u6a5f\u306e\u6b63\u7b54\u7387\u304c50%\uff08\u30e9\u30f3\u30c0\u30e0\u306b\u3057\u304b\u751f\u6210\u3067\u304d\u306a\u3044\uff09 GAN\u306e\u6b20\u70b9 \u00b6 \u5b66\u7fd2\u6642\u9593\u306e\u9577\u3055 \u30e2\u30fc\u30c9\u5d29\u58ca\uff1a\u3044\u304f\u3064\u304b\u306e\u30e2\u30fc\u30c9\u304c\u751f\u6210\u3055\u308c\u308b\u30b5\u30f3\u30d7\u30eb\u306b\u542b\u307e\u308c\u306a\u304f\u306a\u308b \u751f\u6210\u5668\u3068\u8b58\u5225\u5668\u306e\u30d0\u30e9\u30f3\u30b9\uff1a\u8b58\u5225\u5668\u304c\u5f37\u3059\u304e\u308b\uff1d\uff1e\u52fe\u914d\u6d88\u5931\u3001\u8b58\u5225\u5668\u304c\u5b66\u7fd2\u3057\u306a\u3044\uff1d\uff1e\u753b\u50cf\u306e\u30af\u30aa\u30ea\u30c6\u30a3\u304c\u4e0a\u304c\u3089\u306a\u3044 \u751f\u6210\u753b\u50cf\u306b\u7d30\u304b\u306a\u30ce\u30a4\u30ba\u304c\u5165\u308b \u6bd4\u8f03\u53ef\u80fd\u306a\u578b\u306e\u30c7\u30fc\u30bf\u3067\u306a\u3044\u3068\u5b66\u7fd2\u3067\u304d\u306a\u3044 \u640d\u5931\u95a2\u6570\u306e\u5024\u3068\u753b\u50cf\u306e\u30af\u30aa\u30ea\u30c6\u30a3\u304c\u5fc5\u305a\u3057\u3082\u76f8\u95a2\u3057\u306a\u3044\u3002 \u6539\u5584\u6cd5 \u00b6 \u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u6df1\u304f\u3059\u308b\u3002\uff08Progressive GAN\uff09 \u30b2\u30fc\u30e0\u306e\u8a2d\u5b9a\u3092\u5909\u3048\u308b\u3002 Min-Max\u65b9\u5f0f\u3068\u505c\u6b62\u57fa\u6e96 \u975e\u98fd\u548c\u65b9\u5f0f\u3068\u505c\u6b62\u57fa\u6e96 WassertsteinGAN \u30cf\u30c3\u30af \u00b6 \u5165\u529b\u306e\u6b63\u898f\u5316 \u52fe\u914d\u306e\u5236\u7d04 \u8b58\u5225\u5668\u3092\u3088\u308a\u591a\u304f\u8a13\u7df4\u3059\u308b \u758e\u306a\u52fe\u914d\u3092\u907f\u3051\u308b \u30bd\u30d5\u30c8\u306a\u3042\u308b\u3044\u306f\u30ce\u30a4\u30ba\u4ed8\u304d\u306e\u30e9\u30d9\u30eb\u306b\u5207\u308a\u66ff\u3048\u308b \u8b58\u5225\u5668\u30af\u30e9\u30b9\u306e\u5b9f\u88c5 \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Generator ( nn . Module ): def __init__ ( self ): super ( Generator , self ) . __init__ () def block ( in_feat , out_feat , normalize = True ): layers = [ nn . Linear ( in_feat , out_feat )] if normalize : layers . append ( nn . BatchNorm1d ( out_feat , 0.8 )) layers . append ( nn . LeakyReLU ( 0.2 , inplace = True )) return layers self . model = nn . Sequential ( * block ( opt . latent_dim , 128 , normalize = False ), * block ( 128 , 256 ), * block ( 256 , 512 ), * block ( 512 , 1024 ), nn . Linear ( 1024 , int ( np . prod ( img_shape ))), nn . Tanh () ) def forward ( self , z ): img = self . model ( z ) img = img . view ( img . size ( 0 ), * img_shape ) return img \u751f\u6210\u5668\u30af\u30e9\u30b9\u306e\u5b9f\u88c5 \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class Discriminator ( nn . Module ): def __init__ ( self ): super ( Discriminator , self ) . __init__ () self . model = nn . Sequential ( nn . Linear ( int ( np . prod ( img_shape )), 512 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 256 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 256 , 1 ), nn . Sigmoid (), ) def forward ( self , img ): img_flat = img . view ( img . size ( 0 ), - 1 ) validity = self . model ( img_flat ) return validity GAN\u306e\u5b66\u7fd2\u306e1 step \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 optimizer_G = optim . Adam ( netG . parameters (), lr = opt . lr , betas = ( opt . beta1 , 0.999 ), weight_decay = 1e-5 ) optimizer_D = optim . Adam ( netD . parameters (), lr = opt . lr , betas = ( opt . beta1 , 0.999 ), weight_decay = 1e-5 ) shape = ( batch_size , 1 , 1 , 1 ) labels_real = torch . ones ( shape ) . to ( device ) labels_fake = torch . zeros ( shape ) . to ( device ) def train_one_step ( real_imgs , labels_valid , labels_fake ): # Sample noise as generator input noise = torch . randn ( batch_size , opt . z_dim , 1 , 1 ) . to ( device ) \"\"\"Train Discriminator\"\"\" optimizer_D . zero_grad () # Generate a batch of images gen_imgs = generator ( noise ) # Measure discriminator's ability to classify real from generated samples out_real = discriminator ( real_imgs ) out_fake = discriminator ( gen_imgs . detach ()) real_loss = BCELoss ()( out_real , labels_valid ) fake_loss = BCELoss ()( out_fake , labels_fake ) d_loss = real_loss + fake_loss d_loss . backward () optimizer_D . step () \"\"\"Train Generator\"\"\" optimizer_G . zero_grad () # Loss measures generator's ability to fool the discriminator g_loss = BCELoss ()( discriminator ( gen_imgs ), labels_valid ) g_loss . backward () optimizer_G . step () return g_loss , d_loss DCGAN (Deep Convolutional GAN) \u00b6 \u30ce\u30a4\u30ba\u30d9\u30af\u30c8\u30eb\u3092\u5165\u529b\u3057\u3066\u3001\u5e45\u3068\u9ad8\u3055\u3092\u62e1\u5927\u3057\u3064\u3064\u3001\u30c1\u30e3\u30cd\u30eb\u6570\u3092\u6e1b\u3089\u3057\u3066\u3044\u304f\u3001\u6700\u7d42\u7684\u306b\uff08H x W x C\uff09\u3092\u51fa\u529b\u3002 G\u30e2\u30c7\u30eb\u3068D\u30e2\u30c7\u30eb\u306e\u5185\u90e8\u306b\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u3092\u4f7f\u308f\u306a\u3044\u7573\u307f\u8fbc\u307f\u3084 \u8ee2\u7f6e\u7573\u307f\u8fbc\u307f \u3092\u5229\u7528 \u5168\u7d50\u5408\u5c64\u306f\u5229\u7528\u3057\u306a\u3044\uff08\u30d7\u30fc\u30ea\u30f3\u30b0\u51e6\u7406\u306b\u3088\u308b\u7d30\u304b\u306a\u60c5\u5831\u304c\u6b20\u843d\u3059\u308b\u306e\u3092\u9632\u3050\u305f\u3081\u3002\uff09 \u30d0\u30c3\u30c1\u6b63\u898f\u5316 \u3092\u5229\u7528 G\u30e2\u30c7\u30eb\u306e\u51fa\u529b\u5c64\u3092\u7279\u306b\u8b58\u5225\u5668\u306e\u640d\u5931\u95a2\u6570\u306f Earth Mover's distance \u3068\u547c\u3070\u308c\u308b\u3002\u306b\u4ee3\u7528 D\u30e2\u30c7\u30eb\u306e\u6d3b\u6027\u5316\u95a2\u6570\u3092\u7279\u306b\u8b58\u5225\u5668\u306e\u640d\u5931\u95a2\u6570\u306f Earth Mover's distance \u3068\u547c\u3070\u308c\u308b\u3002\u306b\u4ee3\u7528 \u8b58\u5225\u5668\u30af\u30e9\u30b9\u306e\u5b9f\u88c5 \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class Generator ( nn . Module ): def __init__ ( self , z_dim = 100 , ngf = 128 , nc = 1 ): super () . __init__ () self . convt1 = self . conv_trans_layers ( z_dim , 4 * ngf , 3 , 1 , 0 ) self . convt2 = self . conv_trans_layers ( 4 * ngf , 2 * ngf , 3 , 2 , 0 ) self . convt3 = self . conv_trans_layers ( 2 * ngf , ngf , 4 , 2 , 1 ) self . convt4 = nn . Sequential ( nn . ConvTranspose2d ( ngf , nc , 4 , 2 , 1 ), nn . Tanh () ) @staticmethod def conv_trans_layers ( in_channels , out_channels , kernel_size , stride , padding ): net = nn . Sequential ( nn . ConvTranspose2d ( in_channels , out_channels , kernel_size , stride , padding , bias = False ), nn . BatchNorm2d ( out_channels ), nn . ReLU ( inplace = True ) ) return net def forward ( self , x ): out = self . convt1 ( x ) out = self . convt2 ( out ) out = self . convt3 ( out ) out = self . convt4 ( out ) return out \u751f\u6210\u5668\u30af\u30e9\u30b9\u306e\u5b9f\u88c5 \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Discrimnator ( nn . Module ): def __init__ ( self , nc = 1 , ndf = 128 ): super () . __init__ () self . conv1 = self . conv_layers ( nc , ndf , has_batch_norm = False ) self . conv2 = self . conv_layers ( ndf , 2 * ndf ) self . conv3 = self . conv_layers ( 2 * ndf , 4 * ndf , 3 , 2 , 0 ) self . conv4 = nn . Sequential ( nn . Conv2d ( 4 * ndf , 1 , 3 , 1 , 0 ), nn . Sigmoid () ) @staticmethod def conv_layers ( in_channels , out_channels , kernel_size = 4 , stride = 2 , padding = 1 , has_batch_norm = True ): layers = [ nn . Conv2d ( in_channels , out_channels , kernel_size , stride , padding , bias = False ) ] if has_batch_norm : layers . append ( nn . BatchNorm2d ( out_channels )) layers . append ( nn . LeakyReLU ( 0.2 , inplace = True )) net = nn . Sequential ( * layers ) return net def forward ( self , x ): out = self . conv1 ( x ) out = self . conv2 ( out ) out = self . conv3 ( out ) out = self . conv4 ( out ) return out Conditional GAN \u00b6 \u30ce\u30a4\u30ba\u3084\u753b\u50cf\u306b\u30e9\u30d9\u30eb\u3092\u4ed8\u4e0e\u3059\u308b\u3053\u3068\u3067\u7279\u5b9a\u306e\u753b\u50cf\u3092\u751f\u6210 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def get_noise_with_label ( noise , labels , device , n_class = 10 ): one_hot_vec = torch . nn . functional . one_hot ( labels , num_classes = n_class ) . view ( - 1 , n_class , 1 , 1 ) . to ( device ) concat_noise = torch . cat (( noise , one_hot_vec ), dim = 1 ) return concat_noise def get_img_with_label ( imgs , labels , device , n_class = 10 ): B , _ , H , W = imgs . size () one_hot_vec = torch . nn . functional . one_hot ( labels , num_classes = n_class ) . view ( - 1 , n_class , 1 , 1 ) one_hot_vec = one_hot_vec . expand ( B , n_class , H , W ) . to ( device ) concat_img = torch . cat (( imgs , one_hot_vec ), dim = 1 ) return concat_img def train_one_step ( real_imgs , labels_valid , labels_fake ): # Sample noise as generator input noise = torch . randn ( batch_size , opt . z_dim , 1 , 1 ) . to ( device ) # Get the noise with label noise_with_label = get_noise_with_label ( noise , labels , device ) # Get the real images with label real_imgs_with_label = get_img_with_label ( real_imgs , labels , device ) \"\"\"Train Discriminator\"\"\" optimizer_D . zero_grad () # Generate a batch of images gen_imgs = generator ( noise ) # Measure discriminator's ability to classify real from generated samples out_real = discriminator ( real_imgs ) out_fake = discriminator ( gen_imgs . detach ()) real_loss = BCELoss ()( out_real , labels_valid ) fake_loss = BCELoss ()( out_fake , labels_fake ) d_loss = real_loss + fake_loss d_loss . backward () optimizer_D . step () \"\"\"Train Generator\"\"\" optimizer_G . zero_grad () # Loss measures generator's ability to fool the discriminator g_loss = BCELoss ()( discriminator ( gen_imgs ), labels_valid ) g_loss . backward () optimizer_G . step () return g_loss , d_loss Wassersteing GAN \u00b6 \u8a13\u7df4\u306e\u5b89\u5b9a\u5316\u3068\u5224\u65ad\u3092\u89e3\u6c7a\u3059\u308b\u305f\u3081\u306b\u3001\u640d\u5931\u95a2\u6570\u306b Wasserstein\u640d\u5931 \u3092\u5c0e\u5165\u3002\u7279\u306b\u8b58\u5225\u5668\u306e\u640d\u5931\u95a2\u6570\u306f Earth Mover's distance \u3068\u547c\u3070\u308c\u308b\u3002 \u8b58\u5225\u5668\u306b 1-Lipschitz\u9023\u7d9a \u3092\u8ab2\u3057\u305f\u3002 1-Lipschitz\u9023\u7d9a \u3092\u8ab2\u3059\u305f\u3081\u306bWeight\u3092\u3042\u308b\u7bc4\u56f2\u3067\u30af\u30ea\u30c3\u30d7\u3057\u3001\u52fe\u914d\u304c1\u306b\u306a\u308b\u3088\u3046\u306b\u6b63\u5247\u5316\u9805\u3092\u5897\u3084\u3059\u3002 \u8b58\u5225\u5668\u3092\u591a\u304f\u8a13\u7df4\u3059\u308b\u3002 optimizer\u306b RMSProp \u3092\u4f7f\u3046\u3002 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 optimizerG = optim . RMSprop ( netG . parameters (), lr = opt . lr ) optimizerD = optim . RMSprop ( netD . parameters (), lr = opt . lr ) def train_one_step ( real_imgs , labels_valid , labels_fake ): # Sample noise as generator input noise = torch . randn ( batch_size , opt . z_dim , 1 , 1 ) . to ( device ) for p in netD . parameters (): p . data . clamp_ ( opt . c_lower , opt . c_upper ) \"\"\"Train Discriminator\"\"\" optimizer_D . zero_grad () # Generate a batch of images gen_imgs = generator ( noise ) # Measure discriminator's ability to classify real from generated samples out_real = discriminator ( real_imgs ) out_fake = discriminator ( gen_imgs . detach ()) real_loss = - torch . mean ( output ) fake_loss = torch . mean ( output ) d_loss = real_loss + fake_loss d_loss . backward () optimizer_D . step () \"\"\"Train Generator\"\"\" if i % opt . n_critic == 0 : optimizer_G . zero_grad () # Loss measures generator's ability to fool the discriminator g_loss = BCELoss ()( discriminator ( gen_imgs ), labels_valid ) g_loss . backward () optimizer_G . step () return g_loss , d_loss Wassersteing GAN (Gradient penalty) \u00b6 -\u30d0\u30c3\u30c1\u6b63\u898f\u5316\u3092False\u306b\u3059\u308b\u3002 -RMSprop\u306bweight_decay = 1e-4\u3092\u5165\u308c\u308b. 1 2 3 4 5 6 7 8 9 10 11 def gradient_penalty ( real_imgs , fake_img , gp_weight , netD , device ): batch_size = real_imgs . size ()[ 0 ] alpha = torch . randn ( batch_size , 1 , 1 , 1 ) alpha = alpha . expand_as ( real_imgs ) . to ( device ) interpolated_imgs = ( alpha * real_imgs . data + ( 1 - alpha ) * fake_img . data ) . requires_grad_ () grad_outputs = torch . autograd . grad ( inyerpolated_out , interpolated_imgs , grad_outputs = grad_outputs , retain_graph = True )[ 0 ] gradients = gradients . view ( batch_size , - 1 ) gradients_nrom = torch . sqrt ( torch . sum ( gradients ** 2 , dim = 1 ) + eps ) gp = gp_weight * (( gradients_norm - 1 ) ** 2 ) . mean () 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 optimizerG = optim . RMSprop ( netG . parameters (), lr = opt . lr , weight_decay = 1e-4 ) optimizerD = optim . RMSprop ( netD . parameters (), lr = opt . lr , weight_decay = 1e-4 ) def train_one_step ( real_imgs , labels_valid , labels_fake ): # Sample noise as generator input noise = torch . randn ( batch_size , opt . z_dim , 1 , 1 ) . to ( device ) # for p in netD.parameters(): # p.data.clamp_(opt.c_lower, opt.c_upper) \"\"\"Train Discriminator\"\"\" optimizer_D . zero_grad () # Generate a batch of images gen_imgs = generator ( noise ) # Measure discriminator's ability to classify real from generated samples out_real = discriminator ( real_imgs ) out_fake = discriminator ( gen_imgs . detach ()) real_loss = - torch . mean ( output ) fake_loss = torch . mean ( output ) gp_loss = gradient_penalty ( real_imgs , fake_imgs , opt . gp_weight , netD , device ) d_loss = real_loss + fake_loss + gp_loss d_loss . backward () optimizer_D . step () \"\"\"Train Generator\"\"\" if i % opt . n_critic == 0 : optimizer_G . zero_grad () # Loss measures generator's ability to fool the discriminator g_loss = BCELoss ()( discriminator ( gen_imgs ), labels_valid ) g_loss . backward () optimizer_G . step () return g_loss , d_loss Cycke GAN \u00b6 \u57fa\u672c\u7684\u306bEncoder-Decoder\u69cb\u9020 Instance Normalization : \u30d0\u30c3\u30c1\u6b63\u898f\u5316\u3067\u306f\u753b\u50cf\u5168\u4f53\u306e\u307f\u3067\u6b63\u898f\u5316\u3092\u884c\u3046\u3002\u30df\u30cb\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba = 1\u306eBN\u3068\u540c\u3058 \u30ea\u30d5\u30ec\u30af\u30b7\u30e7\u30f3\u30d1\u30c3\u30c9\uff1a\u30bc\u30ed\u30d1\u30c7\u30a3\u30f3\u30b0\u3068\u306f\u7570\u306a\u308a\u30a8\u30c3\u30b8\u90e8\u5206\u3092\u7af6\u6cf3\u9762\u3068\u3057\u3066\u53cd\u5c04\u3055\u305b\u305f\u30d1\u30c7\u30a3\u30f3\u30b0\u65b9\u6cd5\u3002\u6298\u308a\u8fd4\u3057\u3066\u3064\u306a\u3052\u308b\u3053\u3068\u3067\u753b\u50cf\u306e\u4e2d\u306e\u30d1\u30bf\u30fc\u30f3\u3092\u30a8\u30c3\u30b8\u5468\u8fba\u3067\u4fdd\u3064\u3002 \u30b5\u30a4\u30af\u30eb\u4e00\u8cab\u6027\u640d\u5931 \u540c\u4e00\u6027\u640d\u5931 Replay Buffer","title":"GAN basis"},{"location":"gan/#_1","text":"\u751f\u6210\u30e2\u30c7\u30eb\u3068\u306f\u3001\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u304c\u3069\u306e\u3088\u3046\u306b\u751f\u6210\u3055\u308c\u308b\u304b\u78ba\u7387\u30e2\u30c7\u30eb\u306e\u89b3\u70b9\u304b\u3089\u8a18\u8ff0\u3059\u308b\u3002\u6f5c\u5728\u7a7a\u9593\u304b\u3089\u30b5\u30f3\u30d7\u30ea\u30f3\u30b0\u3059\u308b\u3053\u3068\u3067\u65b0\u3057\u3044\u30c7\u30fc\u30bf\u3092\u751f\u6210\u3002 Note \u8b58\u5225\u30e2\u30c7\u30ea\u30f3\u30b0 \uff1a \\(p(y|\\textbf{x})\\) \uff08\u89b3\u6e2c \\(\\textbf{x}\\) \u304c\u4e0e\u3048\u3089\u308c\u305f\u3068\u304d\u306e\u30e9\u30d9\u30eb \\(y\\) \u306e\u78ba\u7387\uff09\u3092\u63a8\u5b9a\u3059\u308b\u3002\uff08\u6559\u5e2b\u3042\u308a\u5b66\u7fd2\uff09 \u751f\u6210\u30e2\u30c7\u30ea\u30f3\u30b0 \uff1a \\(p(\\textbf{x})\\) \uff08\u89b3\u6e2c \\(\\textbf{x}\\) \u304c\u89b3\u6e2c\u3055\u308c\u308b\u78ba\u7387\uff09\u3092\u63a8\u5b9a\u3059\u308b\u3002\uff08\u6559\u5e2b\u306a\u3057\u5b66\u7fd2\uff09 \u6f5c\u5728\u5909\u6570\u3068\u306f\u751f\u6210\u753b\u50cf\u306e\u5143\u306b\u306a\u308b\u6b21\u5143\u524a\u6e1b\u3055\u308c\u305f\u7279\u5fb4\u91cf VAE\u306f\u6f5c\u5728\u5909\u6570\u3092\u6b63\u898f\u5206\u5e03\u3068\u4eee\u5b9a","title":"\u751f\u6210\u30e2\u30c7\u30eb"},{"location":"gan/#_2","text":"\u6f5c\u5728\u7a7a\u9593\u304c\u6b63\u898f\u5206\u5e03","title":"\u5909\u5206\u30aa\u30fc\u30c8\u30a8\u30f3\u30b3\u30fc\u30c0\u30fc"},{"location":"gan/#gan","text":"","title":"GAN"},{"location":"gan/#_3","text":"\u8a13\u7df4\u30c7\u30fc\u30bf\u304b\u3089\u30e9\u30f3\u30c0\u30e0\u306b\u672c\u7269\u306e\u30b5\u30f3\u30d7\u30ebx\u3092\u53d6\u308a\u51fa\u3059 \u65b0\u3057\u3044\u4e71\u6570\u304b\u3089\u751f\u6210\u5668\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u507d\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u751f\u6210 \u8b58\u5225\u5668\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f7f\u3063\u3066x\u3068x*\u3092\u5206\u985e\u3057\u3001\u8aa4\u5dee\u9006\u4f1d\u642c\u3057\u3066\u5206\u985e\u8aa4\u5dee\u3092\u6700\u5927\u5316 \\(p_G(x_i|\\textbf{z})\\) \u3092 \\(p_{r}(x)\\) \u306b\u8fd1\u3065\u3051\u3066\u3044\u304f\u305f\u3081\u306e\u6307\u6a19\u3068\u3057\u3066Kullback\u2013Leibler divergence\uff08\u78ba\u7387\u5bc6\u5ea6\u95a2\u6570\u306e\u8ddd\u96e2\u306e\u5c3a\u5ea6\uff09\u3068Jensen\u2013Shannon (JS)divergence\u304c\u3042\u308b\u3002GAN\u306e\u640d\u5931\u95a2\u6570\u306f\u751f\u6210\u5668\u306eJS divergence\u306e\u6700\u5c0f\u5316\uff08\u8b58\u5225\u5668\u304b\u3089\u898b\u3066\u6700\u5927\u5316\uff09\u304b\u3089\u5c0e\u304b\u308c\u308b\u3002","title":"\u8b58\u5225\u5668\u306e\u8a13\u7df4"},{"location":"gan/#gan_1","text":"\\[\\min_{G}\\max_{D} E_{x\\sim p_r} [\\log D(z)] + E_{x\\sim p_z} [\\log (1-D(G(z)))]\\]","title":"GAN\u306e\u640d\u5931\u95a2\u6570"},{"location":"gan/#_4","text":"\u65b0\u3057\u3044\u4e71\u6570\u304b\u3089\u751f\u6210\u5668\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3067\u507d\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u751f\u6210\uff08- \u30c7\u30fc\u30bf\u304c\u5f93\u3046\u78ba\u7387\u5206\u5e03 \\(p_{r}(x)\\) \u305d\u306e\u3082\u306e\u306f\u308f\u304b\u3089\u306a\u3044\u306e\u3067\u751f\u6210\u5668\u306e\u78ba\u7387 \\(p_G(x_i|\\textbf{z})\\) \u3067\u8fd1\u4f3c\u3059\u308b\u3002\uff09 \u8b58\u5225\u5668\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u7528\u3044\u3066x*\u304c\u672c\u7269\u304b\u63a8\u5b9a \u8b58\u5225\u5668\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u4f7f\u3063\u3066x\u3068x*\u3092\u5206\u985e\u3057\u3001\u8aa4\u5dee\u9006\u4f1d\u642c\u3057\u3066\u5206\u985e\u8aa4\u5dee\u3092\u6700\u5c0f\u5316 https://www.iangoodfellow.com/slides/2019-05-07.pdf","title":"\u751f\u6210\u5668\u306e\u8a13\u7df4"},{"location":"gan/#gan_2","text":"\u30ca\u30c3\u30b7\u30e5\u5747\u8861 -\u3000\u751f\u6210\u5668\u304c\u8a13\u7df4\u30c7\u30fc\u30bf\u306e\u4e2d\u306b\u3042\u308b\u672c\u7269\u306e\u30b5\u30f3\u30d7\u30eb\u3068\u898b\u5206\u3051\u304c\u3064\u304b\u306a\u3044\u507d\u306e\u30b5\u30f3\u30d7\u30eb\u3092\u751f\u6210\u3059\u308b \u8b58\u5225\u6a5f\u306e\u6b63\u7b54\u7387\u304c50%\uff08\u30e9\u30f3\u30c0\u30e0\u306b\u3057\u304b\u751f\u6210\u3067\u304d\u306a\u3044\uff09","title":"GAN\u306e\u53ce\u675f\u6761\u4ef6"},{"location":"gan/#gan_3","text":"\u5b66\u7fd2\u6642\u9593\u306e\u9577\u3055 \u30e2\u30fc\u30c9\u5d29\u58ca\uff1a\u3044\u304f\u3064\u304b\u306e\u30e2\u30fc\u30c9\u304c\u751f\u6210\u3055\u308c\u308b\u30b5\u30f3\u30d7\u30eb\u306b\u542b\u307e\u308c\u306a\u304f\u306a\u308b \u751f\u6210\u5668\u3068\u8b58\u5225\u5668\u306e\u30d0\u30e9\u30f3\u30b9\uff1a\u8b58\u5225\u5668\u304c\u5f37\u3059\u304e\u308b\uff1d\uff1e\u52fe\u914d\u6d88\u5931\u3001\u8b58\u5225\u5668\u304c\u5b66\u7fd2\u3057\u306a\u3044\uff1d\uff1e\u753b\u50cf\u306e\u30af\u30aa\u30ea\u30c6\u30a3\u304c\u4e0a\u304c\u3089\u306a\u3044 \u751f\u6210\u753b\u50cf\u306b\u7d30\u304b\u306a\u30ce\u30a4\u30ba\u304c\u5165\u308b \u6bd4\u8f03\u53ef\u80fd\u306a\u578b\u306e\u30c7\u30fc\u30bf\u3067\u306a\u3044\u3068\u5b66\u7fd2\u3067\u304d\u306a\u3044 \u640d\u5931\u95a2\u6570\u306e\u5024\u3068\u753b\u50cf\u306e\u30af\u30aa\u30ea\u30c6\u30a3\u304c\u5fc5\u305a\u3057\u3082\u76f8\u95a2\u3057\u306a\u3044\u3002","title":"GAN\u306e\u6b20\u70b9"},{"location":"gan/#_5","text":"\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u6df1\u304f\u3059\u308b\u3002\uff08Progressive GAN\uff09 \u30b2\u30fc\u30e0\u306e\u8a2d\u5b9a\u3092\u5909\u3048\u308b\u3002 Min-Max\u65b9\u5f0f\u3068\u505c\u6b62\u57fa\u6e96 \u975e\u98fd\u548c\u65b9\u5f0f\u3068\u505c\u6b62\u57fa\u6e96 WassertsteinGAN","title":"\u6539\u5584\u6cd5"},{"location":"gan/#_6","text":"\u5165\u529b\u306e\u6b63\u898f\u5316 \u52fe\u914d\u306e\u5236\u7d04 \u8b58\u5225\u5668\u3092\u3088\u308a\u591a\u304f\u8a13\u7df4\u3059\u308b \u758e\u306a\u52fe\u914d\u3092\u907f\u3051\u308b \u30bd\u30d5\u30c8\u306a\u3042\u308b\u3044\u306f\u30ce\u30a4\u30ba\u4ed8\u304d\u306e\u30e9\u30d9\u30eb\u306b\u5207\u308a\u66ff\u3048\u308b","title":"\u30cf\u30c3\u30af"},{"location":"gan/#_7","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Generator ( nn . Module ): def __init__ ( self ): super ( Generator , self ) . __init__ () def block ( in_feat , out_feat , normalize = True ): layers = [ nn . Linear ( in_feat , out_feat )] if normalize : layers . append ( nn . BatchNorm1d ( out_feat , 0.8 )) layers . append ( nn . LeakyReLU ( 0.2 , inplace = True )) return layers self . model = nn . Sequential ( * block ( opt . latent_dim , 128 , normalize = False ), * block ( 128 , 256 ), * block ( 256 , 512 ), * block ( 512 , 1024 ), nn . Linear ( 1024 , int ( np . prod ( img_shape ))), nn . Tanh () ) def forward ( self , z ): img = self . model ( z ) img = img . view ( img . size ( 0 ), * img_shape ) return img","title":"\u8b58\u5225\u5668\u30af\u30e9\u30b9\u306e\u5b9f\u88c5"},{"location":"gan/#_8","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class Discriminator ( nn . Module ): def __init__ ( self ): super ( Discriminator , self ) . __init__ () self . model = nn . Sequential ( nn . Linear ( int ( np . prod ( img_shape )), 512 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 512 , 256 ), nn . LeakyReLU ( 0.2 , inplace = True ), nn . Linear ( 256 , 1 ), nn . Sigmoid (), ) def forward ( self , img ): img_flat = img . view ( img . size ( 0 ), - 1 ) validity = self . model ( img_flat ) return validity","title":"\u751f\u6210\u5668\u30af\u30e9\u30b9\u306e\u5b9f\u88c5"},{"location":"gan/#gan1-step","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 optimizer_G = optim . Adam ( netG . parameters (), lr = opt . lr , betas = ( opt . beta1 , 0.999 ), weight_decay = 1e-5 ) optimizer_D = optim . Adam ( netD . parameters (), lr = opt . lr , betas = ( opt . beta1 , 0.999 ), weight_decay = 1e-5 ) shape = ( batch_size , 1 , 1 , 1 ) labels_real = torch . ones ( shape ) . to ( device ) labels_fake = torch . zeros ( shape ) . to ( device ) def train_one_step ( real_imgs , labels_valid , labels_fake ): # Sample noise as generator input noise = torch . randn ( batch_size , opt . z_dim , 1 , 1 ) . to ( device ) \"\"\"Train Discriminator\"\"\" optimizer_D . zero_grad () # Generate a batch of images gen_imgs = generator ( noise ) # Measure discriminator's ability to classify real from generated samples out_real = discriminator ( real_imgs ) out_fake = discriminator ( gen_imgs . detach ()) real_loss = BCELoss ()( out_real , labels_valid ) fake_loss = BCELoss ()( out_fake , labels_fake ) d_loss = real_loss + fake_loss d_loss . backward () optimizer_D . step () \"\"\"Train Generator\"\"\" optimizer_G . zero_grad () # Loss measures generator's ability to fool the discriminator g_loss = BCELoss ()( discriminator ( gen_imgs ), labels_valid ) g_loss . backward () optimizer_G . step () return g_loss , d_loss","title":"GAN\u306e\u5b66\u7fd2\u306e1 step"},{"location":"gan/#dcgan-deep-convolutional-gan","text":"\u30ce\u30a4\u30ba\u30d9\u30af\u30c8\u30eb\u3092\u5165\u529b\u3057\u3066\u3001\u5e45\u3068\u9ad8\u3055\u3092\u62e1\u5927\u3057\u3064\u3064\u3001\u30c1\u30e3\u30cd\u30eb\u6570\u3092\u6e1b\u3089\u3057\u3066\u3044\u304f\u3001\u6700\u7d42\u7684\u306b\uff08H x W x C\uff09\u3092\u51fa\u529b\u3002 G\u30e2\u30c7\u30eb\u3068D\u30e2\u30c7\u30eb\u306e\u5185\u90e8\u306b\u30d7\u30fc\u30ea\u30f3\u30b0\u5c64\u3092\u4f7f\u308f\u306a\u3044\u7573\u307f\u8fbc\u307f\u3084 \u8ee2\u7f6e\u7573\u307f\u8fbc\u307f \u3092\u5229\u7528 \u5168\u7d50\u5408\u5c64\u306f\u5229\u7528\u3057\u306a\u3044\uff08\u30d7\u30fc\u30ea\u30f3\u30b0\u51e6\u7406\u306b\u3088\u308b\u7d30\u304b\u306a\u60c5\u5831\u304c\u6b20\u843d\u3059\u308b\u306e\u3092\u9632\u3050\u305f\u3081\u3002\uff09 \u30d0\u30c3\u30c1\u6b63\u898f\u5316 \u3092\u5229\u7528 G\u30e2\u30c7\u30eb\u306e\u51fa\u529b\u5c64\u3092\u7279\u306b\u8b58\u5225\u5668\u306e\u640d\u5931\u95a2\u6570\u306f Earth Mover's distance \u3068\u547c\u3070\u308c\u308b\u3002\u306b\u4ee3\u7528 D\u30e2\u30c7\u30eb\u306e\u6d3b\u6027\u5316\u95a2\u6570\u3092\u7279\u306b\u8b58\u5225\u5668\u306e\u640d\u5931\u95a2\u6570\u306f Earth Mover's distance \u3068\u547c\u3070\u308c\u308b\u3002\u306b\u4ee3\u7528","title":"DCGAN (Deep Convolutional GAN)"},{"location":"gan/#_9","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class Generator ( nn . Module ): def __init__ ( self , z_dim = 100 , ngf = 128 , nc = 1 ): super () . __init__ () self . convt1 = self . conv_trans_layers ( z_dim , 4 * ngf , 3 , 1 , 0 ) self . convt2 = self . conv_trans_layers ( 4 * ngf , 2 * ngf , 3 , 2 , 0 ) self . convt3 = self . conv_trans_layers ( 2 * ngf , ngf , 4 , 2 , 1 ) self . convt4 = nn . Sequential ( nn . ConvTranspose2d ( ngf , nc , 4 , 2 , 1 ), nn . Tanh () ) @staticmethod def conv_trans_layers ( in_channels , out_channels , kernel_size , stride , padding ): net = nn . Sequential ( nn . ConvTranspose2d ( in_channels , out_channels , kernel_size , stride , padding , bias = False ), nn . BatchNorm2d ( out_channels ), nn . ReLU ( inplace = True ) ) return net def forward ( self , x ): out = self . convt1 ( x ) out = self . convt2 ( out ) out = self . convt3 ( out ) out = self . convt4 ( out ) return out","title":"\u8b58\u5225\u5668\u30af\u30e9\u30b9\u306e\u5b9f\u88c5"},{"location":"gan/#_10","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 class Discrimnator ( nn . Module ): def __init__ ( self , nc = 1 , ndf = 128 ): super () . __init__ () self . conv1 = self . conv_layers ( nc , ndf , has_batch_norm = False ) self . conv2 = self . conv_layers ( ndf , 2 * ndf ) self . conv3 = self . conv_layers ( 2 * ndf , 4 * ndf , 3 , 2 , 0 ) self . conv4 = nn . Sequential ( nn . Conv2d ( 4 * ndf , 1 , 3 , 1 , 0 ), nn . Sigmoid () ) @staticmethod def conv_layers ( in_channels , out_channels , kernel_size = 4 , stride = 2 , padding = 1 , has_batch_norm = True ): layers = [ nn . Conv2d ( in_channels , out_channels , kernel_size , stride , padding , bias = False ) ] if has_batch_norm : layers . append ( nn . BatchNorm2d ( out_channels )) layers . append ( nn . LeakyReLU ( 0.2 , inplace = True )) net = nn . Sequential ( * layers ) return net def forward ( self , x ): out = self . conv1 ( x ) out = self . conv2 ( out ) out = self . conv3 ( out ) out = self . conv4 ( out ) return out","title":"\u751f\u6210\u5668\u30af\u30e9\u30b9\u306e\u5b9f\u88c5"},{"location":"gan/#conditional-gan","text":"\u30ce\u30a4\u30ba\u3084\u753b\u50cf\u306b\u30e9\u30d9\u30eb\u3092\u4ed8\u4e0e\u3059\u308b\u3053\u3068\u3067\u7279\u5b9a\u306e\u753b\u50cf\u3092\u751f\u6210 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def get_noise_with_label ( noise , labels , device , n_class = 10 ): one_hot_vec = torch . nn . functional . one_hot ( labels , num_classes = n_class ) . view ( - 1 , n_class , 1 , 1 ) . to ( device ) concat_noise = torch . cat (( noise , one_hot_vec ), dim = 1 ) return concat_noise def get_img_with_label ( imgs , labels , device , n_class = 10 ): B , _ , H , W = imgs . size () one_hot_vec = torch . nn . functional . one_hot ( labels , num_classes = n_class ) . view ( - 1 , n_class , 1 , 1 ) one_hot_vec = one_hot_vec . expand ( B , n_class , H , W ) . to ( device ) concat_img = torch . cat (( imgs , one_hot_vec ), dim = 1 ) return concat_img def train_one_step ( real_imgs , labels_valid , labels_fake ): # Sample noise as generator input noise = torch . randn ( batch_size , opt . z_dim , 1 , 1 ) . to ( device ) # Get the noise with label noise_with_label = get_noise_with_label ( noise , labels , device ) # Get the real images with label real_imgs_with_label = get_img_with_label ( real_imgs , labels , device ) \"\"\"Train Discriminator\"\"\" optimizer_D . zero_grad () # Generate a batch of images gen_imgs = generator ( noise ) # Measure discriminator's ability to classify real from generated samples out_real = discriminator ( real_imgs ) out_fake = discriminator ( gen_imgs . detach ()) real_loss = BCELoss ()( out_real , labels_valid ) fake_loss = BCELoss ()( out_fake , labels_fake ) d_loss = real_loss + fake_loss d_loss . backward () optimizer_D . step () \"\"\"Train Generator\"\"\" optimizer_G . zero_grad () # Loss measures generator's ability to fool the discriminator g_loss = BCELoss ()( discriminator ( gen_imgs ), labels_valid ) g_loss . backward () optimizer_G . step () return g_loss , d_loss","title":"Conditional GAN"},{"location":"gan/#wassersteing-gan","text":"\u8a13\u7df4\u306e\u5b89\u5b9a\u5316\u3068\u5224\u65ad\u3092\u89e3\u6c7a\u3059\u308b\u305f\u3081\u306b\u3001\u640d\u5931\u95a2\u6570\u306b Wasserstein\u640d\u5931 \u3092\u5c0e\u5165\u3002\u7279\u306b\u8b58\u5225\u5668\u306e\u640d\u5931\u95a2\u6570\u306f Earth Mover's distance \u3068\u547c\u3070\u308c\u308b\u3002 \u8b58\u5225\u5668\u306b 1-Lipschitz\u9023\u7d9a \u3092\u8ab2\u3057\u305f\u3002 1-Lipschitz\u9023\u7d9a \u3092\u8ab2\u3059\u305f\u3081\u306bWeight\u3092\u3042\u308b\u7bc4\u56f2\u3067\u30af\u30ea\u30c3\u30d7\u3057\u3001\u52fe\u914d\u304c1\u306b\u306a\u308b\u3088\u3046\u306b\u6b63\u5247\u5316\u9805\u3092\u5897\u3084\u3059\u3002 \u8b58\u5225\u5668\u3092\u591a\u304f\u8a13\u7df4\u3059\u308b\u3002 optimizer\u306b RMSProp \u3092\u4f7f\u3046\u3002 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 optimizerG = optim . RMSprop ( netG . parameters (), lr = opt . lr ) optimizerD = optim . RMSprop ( netD . parameters (), lr = opt . lr ) def train_one_step ( real_imgs , labels_valid , labels_fake ): # Sample noise as generator input noise = torch . randn ( batch_size , opt . z_dim , 1 , 1 ) . to ( device ) for p in netD . parameters (): p . data . clamp_ ( opt . c_lower , opt . c_upper ) \"\"\"Train Discriminator\"\"\" optimizer_D . zero_grad () # Generate a batch of images gen_imgs = generator ( noise ) # Measure discriminator's ability to classify real from generated samples out_real = discriminator ( real_imgs ) out_fake = discriminator ( gen_imgs . detach ()) real_loss = - torch . mean ( output ) fake_loss = torch . mean ( output ) d_loss = real_loss + fake_loss d_loss . backward () optimizer_D . step () \"\"\"Train Generator\"\"\" if i % opt . n_critic == 0 : optimizer_G . zero_grad () # Loss measures generator's ability to fool the discriminator g_loss = BCELoss ()( discriminator ( gen_imgs ), labels_valid ) g_loss . backward () optimizer_G . step () return g_loss , d_loss","title":"Wassersteing GAN"},{"location":"gan/#wassersteing-gan-gradient-penalty","text":"-\u30d0\u30c3\u30c1\u6b63\u898f\u5316\u3092False\u306b\u3059\u308b\u3002 -RMSprop\u306bweight_decay = 1e-4\u3092\u5165\u308c\u308b. 1 2 3 4 5 6 7 8 9 10 11 def gradient_penalty ( real_imgs , fake_img , gp_weight , netD , device ): batch_size = real_imgs . size ()[ 0 ] alpha = torch . randn ( batch_size , 1 , 1 , 1 ) alpha = alpha . expand_as ( real_imgs ) . to ( device ) interpolated_imgs = ( alpha * real_imgs . data + ( 1 - alpha ) * fake_img . data ) . requires_grad_ () grad_outputs = torch . autograd . grad ( inyerpolated_out , interpolated_imgs , grad_outputs = grad_outputs , retain_graph = True )[ 0 ] gradients = gradients . view ( batch_size , - 1 ) gradients_nrom = torch . sqrt ( torch . sum ( gradients ** 2 , dim = 1 ) + eps ) gp = gp_weight * (( gradients_norm - 1 ) ** 2 ) . mean () 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 optimizerG = optim . RMSprop ( netG . parameters (), lr = opt . lr , weight_decay = 1e-4 ) optimizerD = optim . RMSprop ( netD . parameters (), lr = opt . lr , weight_decay = 1e-4 ) def train_one_step ( real_imgs , labels_valid , labels_fake ): # Sample noise as generator input noise = torch . randn ( batch_size , opt . z_dim , 1 , 1 ) . to ( device ) # for p in netD.parameters(): # p.data.clamp_(opt.c_lower, opt.c_upper) \"\"\"Train Discriminator\"\"\" optimizer_D . zero_grad () # Generate a batch of images gen_imgs = generator ( noise ) # Measure discriminator's ability to classify real from generated samples out_real = discriminator ( real_imgs ) out_fake = discriminator ( gen_imgs . detach ()) real_loss = - torch . mean ( output ) fake_loss = torch . mean ( output ) gp_loss = gradient_penalty ( real_imgs , fake_imgs , opt . gp_weight , netD , device ) d_loss = real_loss + fake_loss + gp_loss d_loss . backward () optimizer_D . step () \"\"\"Train Generator\"\"\" if i % opt . n_critic == 0 : optimizer_G . zero_grad () # Loss measures generator's ability to fool the discriminator g_loss = BCELoss ()( discriminator ( gen_imgs ), labels_valid ) g_loss . backward () optimizer_G . step () return g_loss , d_loss","title":"Wassersteing GAN (Gradient penalty)"},{"location":"gan/#cycke-gan","text":"\u57fa\u672c\u7684\u306bEncoder-Decoder\u69cb\u9020 Instance Normalization : \u30d0\u30c3\u30c1\u6b63\u898f\u5316\u3067\u306f\u753b\u50cf\u5168\u4f53\u306e\u307f\u3067\u6b63\u898f\u5316\u3092\u884c\u3046\u3002\u30df\u30cb\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba = 1\u306eBN\u3068\u540c\u3058 \u30ea\u30d5\u30ec\u30af\u30b7\u30e7\u30f3\u30d1\u30c3\u30c9\uff1a\u30bc\u30ed\u30d1\u30c7\u30a3\u30f3\u30b0\u3068\u306f\u7570\u306a\u308a\u30a8\u30c3\u30b8\u90e8\u5206\u3092\u7af6\u6cf3\u9762\u3068\u3057\u3066\u53cd\u5c04\u3055\u305b\u305f\u30d1\u30c7\u30a3\u30f3\u30b0\u65b9\u6cd5\u3002\u6298\u308a\u8fd4\u3057\u3066\u3064\u306a\u3052\u308b\u3053\u3068\u3067\u753b\u50cf\u306e\u4e2d\u306e\u30d1\u30bf\u30fc\u30f3\u3092\u30a8\u30c3\u30b8\u5468\u8fba\u3067\u4fdd\u3064\u3002 \u30b5\u30a4\u30af\u30eb\u4e00\u8cab\u6027\u640d\u5931 \u540c\u4e00\u6027\u640d\u5931 Replay Buffer","title":"Cycke GAN"},{"location":"git/","text":"Git \u00b6 Git\u3068\u306f \u00b6 Git\u306f\u30d0\u30fc\u30b8\u30e7\u30f3\u7ba1\u7406\u30b7\u30b9\u30c6\u30e0\u306e1\u3064\uff08\u5206\u6563\u7ba1\u7406\u65b9\u5f0f\uff09\u3002\u7279\u5b9a\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306e\u5dee\u5206\u3092\u78ba\u8a8d\u3057\u305f\u308a\u3001\u524d\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u78ba\u8a8d\u3057\u305f\u308a\u3059\u308b\u3002 \u7528\u8a9e \u00b6 \u30ea\u30dd\u30b8\u30c8\u30ea\uff1a\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u5168\u3066\u306e\u30d5\u30a1\u30a4\u30eb\uff08\u5909\u66f4\u5c65\u6b74\u3084\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3082\u3059\u3079\u3066\uff09\u3092\u7ba1\u7406\u3057\u3066\u3044\u308b\u3002 \u30b3\u30df\u30c3\u30c8\uff1a\u89aa\u5b50\u95a2\u4fc2\u3092\u6301\u3064\u30b0\u30e9\u30d5\u3002\u30d5\u30a1\u30a4\u30eb\u306e\u72b6\u614b\u3092\u30bb\u30fc\u30d6\u3059\u308b\u3053\u3068\u3002Working directory => staging area \uff08\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3068\u3082\u547c\u3070\u308c\u308b\uff09=> \u30ea\u30dd\u30b8\u30c8\u30ea\u306b\u30b3\u30df\u30c3\u30c8 \u30d6\u30e9\u30f3\u30c1\uff1a\u30b3\u30df\u30c3\u30c8\u3092\u6307\u3059\u30dd\u30a4\u30f3\u30bf\u3002HEAD\u306f\u4eca\u81ea\u5206\u304c\u4f5c\u696d\u3057\u3066\u3044\u308b\u30d6\u30e9\u30f3\u30c1\u3092\u6307\u3059\u30dd\u30a4\u30f3\u30bf\u3002\u30b3\u30df\u30c3\u30c8\u524d\u306b\u5206\u5c90\u3055\u305b\u308b\u3002\u30de\u30fc\u30b8\u30b3\u30df\u30c3\u30c8\u3092\u3057\u3066\u30de\u30fc\u30b8\u3055\u305b\u308b\u3002 Github \u00b6 \u30cf\u30a4\u30d5\u30f3\u3067\u540d\u524d\u3092\u533a\u5207\u308b\u306e\u304c\u4e00\u822c\u7684 ssh\u3067\u306e\u8a8d\u8a3c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002 \u57fa\u672c\u7684\u306a\u6d41\u308c \u00b6 \u30ed\u30fc\u30ab\u30eb\u306b\u30e6\u30fc\u30b6\u60c5\u5831\u3092\u30bb\u30c3\u30c8\u78ba\u8a8d git config --global user.name \"<username, github\u306eusername>\" git config --global user.email \"<email>\" git config --global --list git config --global --replace-all core.pager \"less -F -X\" git config --global pull.rebase true \u30ea\u30dd\u30b8\u30c8\u30ea\u3092clone git clone <remote_repo_url> git remote -v : \u767b\u9332\u3057\u3066\u3042\u308b\u30ea\u30e2\u30fc\u30c8\u30ea\u30dc\u3092\u78ba\u8a8d git clone \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f origin \u304c\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306b\u7d10\u4ed8\u3044\u3066\u3044\u308b \u30d6\u30e9\u30f3\u30c1\u3092\u4f5c\u6210\uff08\u30d6\u30e9\u30f3\u30c1\u3092\u5207\u308b\uff09 git branch \u30d6\u30e9\u30f3\u30c1\u4e00\u89a7 git branch -a \u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u3092\u542b\u3080\u5168\u3066\u306e\u30d6\u30e9\u30f3\u30c1\u306e\u4e00\u89a7 git branch <branch name> branch name\u3068\u3044\u3046branch\u3092\u4f5c\u6210, HEAD\u306e\u30dd\u30a4\u30f3\u30bf\u5148\u3092\u5207\u308a\u66ff\u3048\u3066\u3044\u308b\u3002 git branch -m <old name> <new name> git branch -d <branch-name> \u30d6\u30e9\u30f3\u30c1\u3092\u524a\u9664 git checkout <branch name> branch name\u306b\u79fb\u52d5\u3002HEAD\u30dd\u30a4\u30f3\u30bf\u306e\u5207\u308a\u66ff\u3048 git checkout -b <branch name> \uff08\u5b9f\u7528\u4e0a\uff09branch \u4f5c\u6210\u3057\u3066branch name\u306b\u79fb\u52d5 \u30d6\u30e9\u30f3\u30c1\u540d\u306f\u30cf\u30a4\u30d5\u30f3\u3067\u533a\u5207\u308b \u30ed\u30fc\u30ab\u30eb\u30d5\u30a1\u30a4\u30eb\uff08at working directory, working tree\uff09\u3092\u66f4\u65b0\u3057\u3066Staging\u30a8\u30ea\u30a2\u306b\u3042\u3052\u308b git diff --<filename> \u3067working directory\u3068staging area\u306ediss\u3092\u78ba\u8a8d git diff HEAD --<filename> \u3067working directory\u3068\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff -staged HEAD --<filename> \u3067staging area\u3068\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff HEAD HEAD^^ --<filename> 2\u3064\u524d\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff origin/main main --<filename> git add <file name> git add . git status \u72b6\u6cc1\u3092\u78ba\u8a8d \u30b3\u30df\u30c3\u30c8\u3059\u308b git commit -m \"commit message\" git tag <tagname> git tag --list git log --oneline --all --graph \u30b3\u30df\u30c3\u30c8\u3057\u305f\u5c65\u6b74\u3092\u78ba\u8a8d \u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306e\u60c5\u5831\u3092pull\u3057\u3066\u304b\u3089\u3001\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u30b8\u30c8\u30ea\u306bpush\u3002pull\u306ffetch + merge git pull <remote ref> <branch name> git pull --rebase <remote ref> <branch name> : pull\u3059\u308b\u3068\u304d\u306brebase\u3059\u308b git pull origin main git push <remote ref> <branch name> git push origin new-branch git tag -a <tagname> <commitID> commit\u306btag\u3092\u3064\u3051\u308b\u3002 git push <remote_ref> <tagname> tag\u3092\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306bpush\u3059\u308b OSS\u306a\u3069\u306e\u5834\u5408\u3067\u306f\u3001\u307e\u305a\u30d5\u30a9\u30fc\u30af\u3082\u3068\u306e\u30ea\u30dd\u3092pull\u3059\u308b\u3002 git remote add upstream <repourl> git pull upstream main git push origin new-branch push\u3057\u305f\u30d6\u30e9\u30f3\u30c1\u3092pull request\u3092\u4f5c\u3063\u3066\u30ea\u30e2\u30fc\u30c8\u306emain\u30d6\u30e9\u30f3\u30c1\u306b\u30de\u30fc\u30b8 Github\u3067\u4f5c\u696d\u3002 pull request \u3092\u30af\u30ea\u30c3\u30af => base (main)\u3068 compare (new branch)\u3092\u6307\u5b9a,\u81ea\u5206\u306e\u30ea\u30dd\u304b\u30d5\u30a9\u30fc\u30af\u3082\u3068\u306e\u30ea\u30dd\u304b\u3092\u78ba\u8a8d => create pull request => Merge pull request \u3092\u62bc\u3059\u3002 \u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306emain\u306e\u53cd\u6620\u3092\u30ed\u30fc\u30ab\u30eb\u30ea\u30dd\u306emain\u306b\u53cd\u6620\uff08pull\uff09 git checkout main git pull origin main \u4e0d\u8981\u306a\u30d6\u30e9\u30f3\u30c1\u3092\u524a\u9664\u3059\u308b\u3002 git branch -d <branch-name> Gighub\u3067 branches \u304b\u3089\u524a\u9664 \u57fa\u672c\u64cd\u4f5c \u00b6 \u30b9\u30af\u30e9\u30c3\u30c1\u304b\u3089\u4f5c\u6210\uff08.git\u306e\u4f5c\u6210\uff09 git init <project-name> .git \u306e\u524a\u9664 rm -rf .git \u65e2\u5b58\u306e\u30d5\u30a9\u30eb\u30c0\u3092git\u30ea\u30dd\u306b\u3059\u308b\u3002 git init \u3000\u305d\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u79fb\u52d5\u3057\u3066\u304b\u3089.git\u306e\u4f5c\u6210 \u65e2\u5b58\u306e\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u3092\u81ea\u5206\u306e\u30ea\u30dd\u3092\u30d5\u30a9\u30fc\u30af\u3057\u3066clone git clone <httsps or ssh> track\u30d5\u30a1\u30a4\u30eb\u3068untrack\u30d5\u30a1\u30a4\u30eb git ls-files \u3067track\u3057\u3066\u3044\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u4e00\u89a7\u3092\u78ba\u8a8d Staging area\u3078\u306eadd\u3092\u30ad\u30e3\u30f3\u30bb\u30eb(git\u306e\u5185\u90e8\u3067\u306f\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u5185\u5bb9\u3092staging area\u306b\u4e0a\u66f8\u304d) git reset HEAD <filename> Working directory\u306e\u5185\u5bb9\u3092\u7121\u3057\u306b\u3059\u308b\u3002(git\u306e\u5185\u90e8\u3067\u306fworking directory\u306e\u5185\u5bb9\u3092staging area \u3067\u4e0a\u66f8\u304d\u3057\u3066\u3044\u308b\u3002) git checkout -- <file name> \u30d5\u30a1\u30a4\u30eb\u540d\u306e\u5909\u66f4\u3092git\u3067\u7ba1\u7406 git mv <filename1> <filename2> (\u30b7\u30a7\u30eb\u306emv\u3067\u5909\u66f4\u3057\u305f\u5834\u5408\u306f git add -A ) \u30d5\u30a1\u30a4\u30eb\u306e\u524a\u9664\u3092Git\u3067\u7ba1\u7406\u3059\u308b\u3002 git rm <filename> (\u30b3\u30df\u30c3\u30c8\u3057\u3066\u304b\u3089\u3067\u306a\u3044\u3068\u4f7f\u3048\u306a\u3044) git commit -m \"deleted\" \u524a\u9664\u5185\u5bb9\u306e\u53d6\u308a\u6d88\u3057 git reset HEAD <filename> git checkout -- <file name> \u30b3\u30df\u30c3\u30c8\u306e\u5c65\u6b74\u3092\u78ba\u8a8d\u3059\u308b git log --oneline, --graph, --<filename>, --follow <filename> git show <commitID> Git\u306e\u7ba1\u7406\u304b\u3089\u5916\u3059\u3002 .gitignore \u30d5\u30a1\u30a4\u30eb \u30b5\u30a4\u30ba\u304c\u5927\u304d\u3044\u30d5\u30a1\u30a4\u30eb\u3084\u30d0\u30a4\u30ca\u30ea\u30fc\u30d5\u30a1\u30a4\u30eb\u3001\u4e2d\u9593\u30d5\u30a1\u30a4\u30eb\u3001\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u542b\u3080\u30d5\u30a1\u30a4\u30eb\u3001\u304f\u30a2\u30c3\u30b7\u30e5\u30d5\u30a1\u30a4\u30eb\u306a\u3069 \u30d6\u30e9\u30f3\u30c1\u3068\u30ed\u30fc\u30ab\u30eb\u3067\u30de\u30fc\u30b8,\u30ed\u30fc\u30ab\u30eb\u3067\u306e\u307frebase\u3059\u308b \u00b6 git merge <branchname> \uff1abranchname\u3092\u4eca\u3044\u308b\u30d6\u30e9\u30f3\u30c1\uff08\u666e\u901a\u306fmain\u30d6\u30e9\u30f3\u30c1\uff09\u306b\u53cd\u6620\u3002 git diff <base> <compare> \uff1abase\uff08main\uff09\u3068compare\uff08\u30d6\u30e9\u30f3\u30c1\uff09\u3092\u4f5c\u6210 conflict\u304c\u8d77\u304d\u3066\u3044\u308b\u5834\u5408\u306f\u30a8\u30c7\u30a3\u30bf\u3067\u958b\u3044\u3066\u30a2\u30ce\u30fc\u30c6\u30b7\u30e7\u30f3\u7b87\u6240\u3092\u6d88\u3059\u3002 git rebase main : main \u30d6\u30e9\u30f3\u30c1\u3092rebase\u3059\u308b\u3002rebase\u306f\u30de\u30fc\u30b8\u30b3\u30df\u30c3\u30c8\u3092\u4f5c\u6210\u3057\u306a\u3044\u3002 \u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u30b8\u30c8\u30ea \u00b6 git fetch <remote_ref> :\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306e\u60c5\u5831\u3092\u3068\u3063\u3066\u304f\u308b\u3002 git pull <remote_ref> <branchname> : git pull \u3067\u30b3\u30f3\u30d5\u30ea\u30af\u30c8\u304c\u3042\u308b\u5834\u5408\u306f\u5bfe\u51e6\u3059\u308b\u3002 Github\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u30d5\u30a9\u30fc\u30af\u5143\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u3078\u306epull request\u3092\u51fa\u3059\u3002 git remote add upstream <repourl> : \u30ed\u30fc\u30ab\u30eb\u306b\u306forigin\u3067\u30a2\u30af\u30bb\u30b9\u53ef\u80fd \u307e\u305a\u30d5\u30a9\u30fc\u30af\u3082\u3068\u306e\u30ea\u30dd\u3092pull\u3057\u3066\u304b\u3089\u81ea\u5206\u306e\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306bpush\u3057\u3066pull request\u3092\u4f5c\u6210\u3002 \u5dee\u5206diff\u3092\u898b\u308b \u00b6 p4merge \u3092\u5c0e\u5165\u3059\u308b\u3002 git diff \u3067working directory\u3068staging area\u306ediss\u3092\u78ba\u8a8d git HEAD \u3067working directory\u3068\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff -- <filename> \u3067working directory\u3068staging area\u306ediss\u3092\u78ba\u8a8d git diff HEAD -- <filename> \u3067working directory\u3068\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff -staged HEAD -- <filename> \u3067staging area\u3068\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff HEAD HEAD^^ -- <filename> 2\u3064\u524d\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff origin/main main -- <filename> Stash\u3092\u4f7f\u3046\u3002 \u00b6 \u4f5c\u696d\u5185\u5bb9\u306e\u4e00\u6642\u56de\u907f - git stash git stash -a git stash list git stash apply git stash drop git stash show stash @{<i>} conflict\u304c\u3042\u308b\u5834\u5408 git mergetool \u3067\u30b3\u30f3\u30d5\u30ea\u30af\u30c8\u306b\u5bfe\u51e6\u3059\u308b\u3002 ## Commit\u306btag\u3092\u4f7f\u3046\u3002 - \u30de\u30a4\u30eb\u30b9\u30c8\u30fc\u30f3\u306btag\u3092\u4f7f\u3063\u3066version\u3092\u7ba1\u7406\u3059\u308b - git tag <tagname> - git tag --list - git tag --delete <tagname> - git tag -a <tagname> tag\u3092\u3064\u3051\u308b\u3002 - git diff <tagname1> <tagname2> - git tag -a <tagname> <commitID> commit\u306btag\u3092\u3064\u3051\u308b\u3002 - git push <remote_ref> <tagname> tag\u3092\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306bpush\u3059\u308b - git push <remote_ref> :<tagname> tag\u3092\u30ea\u30e2\u30fc\u30c8push\u304b\u3089\u524a\u9664 - git checkout tags/<tagname> - git fetch --tgas --all submodule \u00b6 git submodule add <submodule_url> git submodule update git -recurse-submodule update submodule\u306e\u4e2d\u3067git pull\u3059\u308b\u3002 git submodule foreach 'git pull origin main' others \u00b6 convertio.io wiki\u3092\u4f7f\u3046 octotree zenhub\u3092\u4f7f\u3046\uff1a\u30a2\u30b8\u30e3\u30a4\u30eb\u958b\u767a\u306e\u30ab\u30f3\u30d0\u30f3 git revert <commitID> git reset --hard git reset --sorf HEAD \u30d5\u30a1\u30a4\u30eb\u540d \u9593\u9055\u3063\u3066add \u3057\u305f\u3068\u304d git reset \u2013soft HEAD^ \u9593\u9055\u3063\u3066commit\u3057\u305f\u3068\u304d","title":"Git"},{"location":"git/#git","text":"","title":"Git"},{"location":"git/#git_1","text":"Git\u306f\u30d0\u30fc\u30b8\u30e7\u30f3\u7ba1\u7406\u30b7\u30b9\u30c6\u30e0\u306e1\u3064\uff08\u5206\u6563\u7ba1\u7406\u65b9\u5f0f\uff09\u3002\u7279\u5b9a\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u306e\u5dee\u5206\u3092\u78ba\u8a8d\u3057\u305f\u308a\u3001\u524d\u306e\u30d0\u30fc\u30b8\u30e7\u30f3\u3092\u78ba\u8a8d\u3057\u305f\u308a\u3059\u308b\u3002","title":"Git\u3068\u306f"},{"location":"git/#_1","text":"\u30ea\u30dd\u30b8\u30c8\u30ea\uff1a\u30d7\u30ed\u30b8\u30a7\u30af\u30c8\u306e\u5168\u3066\u306e\u30d5\u30a1\u30a4\u30eb\uff08\u5909\u66f4\u5c65\u6b74\u3084\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3082\u3059\u3079\u3066\uff09\u3092\u7ba1\u7406\u3057\u3066\u3044\u308b\u3002 \u30b3\u30df\u30c3\u30c8\uff1a\u89aa\u5b50\u95a2\u4fc2\u3092\u6301\u3064\u30b0\u30e9\u30d5\u3002\u30d5\u30a1\u30a4\u30eb\u306e\u72b6\u614b\u3092\u30bb\u30fc\u30d6\u3059\u308b\u3053\u3068\u3002Working directory => staging area \uff08\u30a4\u30f3\u30c7\u30c3\u30af\u30b9\u3068\u3082\u547c\u3070\u308c\u308b\uff09=> \u30ea\u30dd\u30b8\u30c8\u30ea\u306b\u30b3\u30df\u30c3\u30c8 \u30d6\u30e9\u30f3\u30c1\uff1a\u30b3\u30df\u30c3\u30c8\u3092\u6307\u3059\u30dd\u30a4\u30f3\u30bf\u3002HEAD\u306f\u4eca\u81ea\u5206\u304c\u4f5c\u696d\u3057\u3066\u3044\u308b\u30d6\u30e9\u30f3\u30c1\u3092\u6307\u3059\u30dd\u30a4\u30f3\u30bf\u3002\u30b3\u30df\u30c3\u30c8\u524d\u306b\u5206\u5c90\u3055\u305b\u308b\u3002\u30de\u30fc\u30b8\u30b3\u30df\u30c3\u30c8\u3092\u3057\u3066\u30de\u30fc\u30b8\u3055\u305b\u308b\u3002","title":"\u7528\u8a9e"},{"location":"git/#github","text":"\u30cf\u30a4\u30d5\u30f3\u3067\u540d\u524d\u3092\u533a\u5207\u308b\u306e\u304c\u4e00\u822c\u7684 ssh\u3067\u306e\u8a8d\u8a3c\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u3002","title":"Github"},{"location":"git/#_2","text":"\u30ed\u30fc\u30ab\u30eb\u306b\u30e6\u30fc\u30b6\u60c5\u5831\u3092\u30bb\u30c3\u30c8\u78ba\u8a8d git config --global user.name \"<username, github\u306eusername>\" git config --global user.email \"<email>\" git config --global --list git config --global --replace-all core.pager \"less -F -X\" git config --global pull.rebase true \u30ea\u30dd\u30b8\u30c8\u30ea\u3092clone git clone <remote_repo_url> git remote -v : \u767b\u9332\u3057\u3066\u3042\u308b\u30ea\u30e2\u30fc\u30c8\u30ea\u30dc\u3092\u78ba\u8a8d git clone \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f origin \u304c\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306b\u7d10\u4ed8\u3044\u3066\u3044\u308b \u30d6\u30e9\u30f3\u30c1\u3092\u4f5c\u6210\uff08\u30d6\u30e9\u30f3\u30c1\u3092\u5207\u308b\uff09 git branch \u30d6\u30e9\u30f3\u30c1\u4e00\u89a7 git branch -a \u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u3092\u542b\u3080\u5168\u3066\u306e\u30d6\u30e9\u30f3\u30c1\u306e\u4e00\u89a7 git branch <branch name> branch name\u3068\u3044\u3046branch\u3092\u4f5c\u6210, HEAD\u306e\u30dd\u30a4\u30f3\u30bf\u5148\u3092\u5207\u308a\u66ff\u3048\u3066\u3044\u308b\u3002 git branch -m <old name> <new name> git branch -d <branch-name> \u30d6\u30e9\u30f3\u30c1\u3092\u524a\u9664 git checkout <branch name> branch name\u306b\u79fb\u52d5\u3002HEAD\u30dd\u30a4\u30f3\u30bf\u306e\u5207\u308a\u66ff\u3048 git checkout -b <branch name> \uff08\u5b9f\u7528\u4e0a\uff09branch \u4f5c\u6210\u3057\u3066branch name\u306b\u79fb\u52d5 \u30d6\u30e9\u30f3\u30c1\u540d\u306f\u30cf\u30a4\u30d5\u30f3\u3067\u533a\u5207\u308b \u30ed\u30fc\u30ab\u30eb\u30d5\u30a1\u30a4\u30eb\uff08at working directory, working tree\uff09\u3092\u66f4\u65b0\u3057\u3066Staging\u30a8\u30ea\u30a2\u306b\u3042\u3052\u308b git diff --<filename> \u3067working directory\u3068staging area\u306ediss\u3092\u78ba\u8a8d git diff HEAD --<filename> \u3067working directory\u3068\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff -staged HEAD --<filename> \u3067staging area\u3068\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff HEAD HEAD^^ --<filename> 2\u3064\u524d\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff origin/main main --<filename> git add <file name> git add . git status \u72b6\u6cc1\u3092\u78ba\u8a8d \u30b3\u30df\u30c3\u30c8\u3059\u308b git commit -m \"commit message\" git tag <tagname> git tag --list git log --oneline --all --graph \u30b3\u30df\u30c3\u30c8\u3057\u305f\u5c65\u6b74\u3092\u78ba\u8a8d \u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306e\u60c5\u5831\u3092pull\u3057\u3066\u304b\u3089\u3001\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u30b8\u30c8\u30ea\u306bpush\u3002pull\u306ffetch + merge git pull <remote ref> <branch name> git pull --rebase <remote ref> <branch name> : pull\u3059\u308b\u3068\u304d\u306brebase\u3059\u308b git pull origin main git push <remote ref> <branch name> git push origin new-branch git tag -a <tagname> <commitID> commit\u306btag\u3092\u3064\u3051\u308b\u3002 git push <remote_ref> <tagname> tag\u3092\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306bpush\u3059\u308b OSS\u306a\u3069\u306e\u5834\u5408\u3067\u306f\u3001\u307e\u305a\u30d5\u30a9\u30fc\u30af\u3082\u3068\u306e\u30ea\u30dd\u3092pull\u3059\u308b\u3002 git remote add upstream <repourl> git pull upstream main git push origin new-branch push\u3057\u305f\u30d6\u30e9\u30f3\u30c1\u3092pull request\u3092\u4f5c\u3063\u3066\u30ea\u30e2\u30fc\u30c8\u306emain\u30d6\u30e9\u30f3\u30c1\u306b\u30de\u30fc\u30b8 Github\u3067\u4f5c\u696d\u3002 pull request \u3092\u30af\u30ea\u30c3\u30af => base (main)\u3068 compare (new branch)\u3092\u6307\u5b9a,\u81ea\u5206\u306e\u30ea\u30dd\u304b\u30d5\u30a9\u30fc\u30af\u3082\u3068\u306e\u30ea\u30dd\u304b\u3092\u78ba\u8a8d => create pull request => Merge pull request \u3092\u62bc\u3059\u3002 \u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306emain\u306e\u53cd\u6620\u3092\u30ed\u30fc\u30ab\u30eb\u30ea\u30dd\u306emain\u306b\u53cd\u6620\uff08pull\uff09 git checkout main git pull origin main \u4e0d\u8981\u306a\u30d6\u30e9\u30f3\u30c1\u3092\u524a\u9664\u3059\u308b\u3002 git branch -d <branch-name> Gighub\u3067 branches \u304b\u3089\u524a\u9664","title":"\u57fa\u672c\u7684\u306a\u6d41\u308c"},{"location":"git/#_3","text":"\u30b9\u30af\u30e9\u30c3\u30c1\u304b\u3089\u4f5c\u6210\uff08.git\u306e\u4f5c\u6210\uff09 git init <project-name> .git \u306e\u524a\u9664 rm -rf .git \u65e2\u5b58\u306e\u30d5\u30a9\u30eb\u30c0\u3092git\u30ea\u30dd\u306b\u3059\u308b\u3002 git init \u3000\u305d\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u79fb\u52d5\u3057\u3066\u304b\u3089.git\u306e\u4f5c\u6210 \u65e2\u5b58\u306e\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u3092\u81ea\u5206\u306e\u30ea\u30dd\u3092\u30d5\u30a9\u30fc\u30af\u3057\u3066clone git clone <httsps or ssh> track\u30d5\u30a1\u30a4\u30eb\u3068untrack\u30d5\u30a1\u30a4\u30eb git ls-files \u3067track\u3057\u3066\u3044\u308b\u30d5\u30a1\u30a4\u30eb\u3092\u4e00\u89a7\u3092\u78ba\u8a8d Staging area\u3078\u306eadd\u3092\u30ad\u30e3\u30f3\u30bb\u30eb(git\u306e\u5185\u90e8\u3067\u306f\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u5185\u5bb9\u3092staging area\u306b\u4e0a\u66f8\u304d) git reset HEAD <filename> Working directory\u306e\u5185\u5bb9\u3092\u7121\u3057\u306b\u3059\u308b\u3002(git\u306e\u5185\u90e8\u3067\u306fworking directory\u306e\u5185\u5bb9\u3092staging area \u3067\u4e0a\u66f8\u304d\u3057\u3066\u3044\u308b\u3002) git checkout -- <file name> \u30d5\u30a1\u30a4\u30eb\u540d\u306e\u5909\u66f4\u3092git\u3067\u7ba1\u7406 git mv <filename1> <filename2> (\u30b7\u30a7\u30eb\u306emv\u3067\u5909\u66f4\u3057\u305f\u5834\u5408\u306f git add -A ) \u30d5\u30a1\u30a4\u30eb\u306e\u524a\u9664\u3092Git\u3067\u7ba1\u7406\u3059\u308b\u3002 git rm <filename> (\u30b3\u30df\u30c3\u30c8\u3057\u3066\u304b\u3089\u3067\u306a\u3044\u3068\u4f7f\u3048\u306a\u3044) git commit -m \"deleted\" \u524a\u9664\u5185\u5bb9\u306e\u53d6\u308a\u6d88\u3057 git reset HEAD <filename> git checkout -- <file name> \u30b3\u30df\u30c3\u30c8\u306e\u5c65\u6b74\u3092\u78ba\u8a8d\u3059\u308b git log --oneline, --graph, --<filename>, --follow <filename> git show <commitID> Git\u306e\u7ba1\u7406\u304b\u3089\u5916\u3059\u3002 .gitignore \u30d5\u30a1\u30a4\u30eb \u30b5\u30a4\u30ba\u304c\u5927\u304d\u3044\u30d5\u30a1\u30a4\u30eb\u3084\u30d0\u30a4\u30ca\u30ea\u30fc\u30d5\u30a1\u30a4\u30eb\u3001\u4e2d\u9593\u30d5\u30a1\u30a4\u30eb\u3001\u30d1\u30b9\u30ef\u30fc\u30c9\u3092\u542b\u3080\u30d5\u30a1\u30a4\u30eb\u3001\u304f\u30a2\u30c3\u30b7\u30e5\u30d5\u30a1\u30a4\u30eb\u306a\u3069","title":"\u57fa\u672c\u64cd\u4f5c"},{"location":"git/#rebase","text":"git merge <branchname> \uff1abranchname\u3092\u4eca\u3044\u308b\u30d6\u30e9\u30f3\u30c1\uff08\u666e\u901a\u306fmain\u30d6\u30e9\u30f3\u30c1\uff09\u306b\u53cd\u6620\u3002 git diff <base> <compare> \uff1abase\uff08main\uff09\u3068compare\uff08\u30d6\u30e9\u30f3\u30c1\uff09\u3092\u4f5c\u6210 conflict\u304c\u8d77\u304d\u3066\u3044\u308b\u5834\u5408\u306f\u30a8\u30c7\u30a3\u30bf\u3067\u958b\u3044\u3066\u30a2\u30ce\u30fc\u30c6\u30b7\u30e7\u30f3\u7b87\u6240\u3092\u6d88\u3059\u3002 git rebase main : main \u30d6\u30e9\u30f3\u30c1\u3092rebase\u3059\u308b\u3002rebase\u306f\u30de\u30fc\u30b8\u30b3\u30df\u30c3\u30c8\u3092\u4f5c\u6210\u3057\u306a\u3044\u3002","title":"\u30d6\u30e9\u30f3\u30c1\u3068\u30ed\u30fc\u30ab\u30eb\u3067\u30de\u30fc\u30b8,\u30ed\u30fc\u30ab\u30eb\u3067\u306e\u307frebase\u3059\u308b"},{"location":"git/#_4","text":"git fetch <remote_ref> :\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306e\u60c5\u5831\u3092\u3068\u3063\u3066\u304f\u308b\u3002 git pull <remote_ref> <branchname> : git pull \u3067\u30b3\u30f3\u30d5\u30ea\u30af\u30c8\u304c\u3042\u308b\u5834\u5408\u306f\u5bfe\u51e6\u3059\u308b\u3002 Github\u306f\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u30d5\u30a9\u30fc\u30af\u5143\u306e\u30ea\u30dd\u30b8\u30c8\u30ea\u3078\u306epull request\u3092\u51fa\u3059\u3002 git remote add upstream <repourl> : \u30ed\u30fc\u30ab\u30eb\u306b\u306forigin\u3067\u30a2\u30af\u30bb\u30b9\u53ef\u80fd \u307e\u305a\u30d5\u30a9\u30fc\u30af\u3082\u3068\u306e\u30ea\u30dd\u3092pull\u3057\u3066\u304b\u3089\u81ea\u5206\u306e\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306bpush\u3057\u3066pull request\u3092\u4f5c\u6210\u3002","title":"\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u30b8\u30c8\u30ea"},{"location":"git/#diff","text":"p4merge \u3092\u5c0e\u5165\u3059\u308b\u3002 git diff \u3067working directory\u3068staging area\u306ediss\u3092\u78ba\u8a8d git HEAD \u3067working directory\u3068\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff -- <filename> \u3067working directory\u3068staging area\u306ediss\u3092\u78ba\u8a8d git diff HEAD -- <filename> \u3067working directory\u3068\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff -staged HEAD -- <filename> \u3067staging area\u3068\u30ea\u30dd\u30b8\u30c8\u30ea\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff HEAD HEAD^^ -- <filename> 2\u3064\u524d\u306e\u5dee\u5206\u3092\u78ba\u8a8d git diff origin/main main -- <filename>","title":"\u5dee\u5206diff\u3092\u898b\u308b"},{"location":"git/#stash","text":"\u4f5c\u696d\u5185\u5bb9\u306e\u4e00\u6642\u56de\u907f - git stash git stash -a git stash list git stash apply git stash drop git stash show stash @{<i>} conflict\u304c\u3042\u308b\u5834\u5408 git mergetool \u3067\u30b3\u30f3\u30d5\u30ea\u30af\u30c8\u306b\u5bfe\u51e6\u3059\u308b\u3002 ## Commit\u306btag\u3092\u4f7f\u3046\u3002 - \u30de\u30a4\u30eb\u30b9\u30c8\u30fc\u30f3\u306btag\u3092\u4f7f\u3063\u3066version\u3092\u7ba1\u7406\u3059\u308b - git tag <tagname> - git tag --list - git tag --delete <tagname> - git tag -a <tagname> tag\u3092\u3064\u3051\u308b\u3002 - git diff <tagname1> <tagname2> - git tag -a <tagname> <commitID> commit\u306btag\u3092\u3064\u3051\u308b\u3002 - git push <remote_ref> <tagname> tag\u3092\u30ea\u30e2\u30fc\u30c8\u30ea\u30dd\u306bpush\u3059\u308b - git push <remote_ref> :<tagname> tag\u3092\u30ea\u30e2\u30fc\u30c8push\u304b\u3089\u524a\u9664 - git checkout tags/<tagname> - git fetch --tgas --all","title":"Stash\u3092\u4f7f\u3046\u3002"},{"location":"git/#submodule","text":"git submodule add <submodule_url> git submodule update git -recurse-submodule update submodule\u306e\u4e2d\u3067git pull\u3059\u308b\u3002 git submodule foreach 'git pull origin main'","title":"submodule"},{"location":"git/#others","text":"convertio.io wiki\u3092\u4f7f\u3046 octotree zenhub\u3092\u4f7f\u3046\uff1a\u30a2\u30b8\u30e3\u30a4\u30eb\u958b\u767a\u306e\u30ab\u30f3\u30d0\u30f3 git revert <commitID> git reset --hard git reset --sorf HEAD \u30d5\u30a1\u30a4\u30eb\u540d \u9593\u9055\u3063\u3066add \u3057\u305f\u3068\u304d git reset \u2013soft HEAD^ \u9593\u9055\u3063\u3066commit\u3057\u305f\u3068\u304d","title":"others"},{"location":"labrad/","text":"labrad_hdf5_dataloader \u00b6 labrad hdf5\u304b\u3089ndarray\u5f62\u5f0f\u3067\u30c7\u30fc\u30bf\u3092\u53d6\u308a\u51fa\u3059\u3002 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def labrad_hdf5_ndarray ( dir_path , file_num , file_name ): \"\"\"Load a hdf5 file and return the data (numpy.array) and columns of labels (list) Parameters ---------- dir_path : string Usually this is \"vault\" directory file_num : int hdf5 file number. ex. '000## - measurement_name.hdf5' file_name : string Returns ------- data : ndarray variables : list list of parameters \"\"\" # Load hdf5 file f_name = '0' * ( 5 - len ( str ( file_num ))) + str ( file_num ) + ' - ' + file_name + '.hdf5' f = h5py . File ( dir_path + f_name , 'r' )[ 'DataVault' ] raw_data = f . value attrs = f . attrs # Raw data to np.array data = np . array ([ list ( d ) for d in raw_data ]) # Get varialbles labels indep_keys = sorted ([ str ( x ) for x in list ( attrs . keys ()) if str ( x ) . startswith ( 'Independent' ) and str ( x ) . endswith ( 'label' )]) dep_keys = sorted ([ str ( x ) for x in list ( attrs . keys ()) if str ( x ) . startswith ( 'Dependent' ) and str ( x ) . endswith ( 'label' )]) indep_labels = [ attrs [ c ] for c in indep_keys ] dep_labels = [ attrs [ c ] for c in dep_keys ] variables = indep_labels + dep_labels return data , variables labrad_hdf5_get_parameters \u00b6 labrad hdf5\u304b\u3089DV.add_parameters()\u3067\u52a0\u3048\u305f\u6a5f\u5668\u306e\u8a2d\u5b9a\u306e\u60c5\u5831\u306a\u3069\u3092\u53d6\u5f97\u3059\u308b\u3002 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def labrad_hdf5_get_parameters ( dir_path , file_num , file_name ): \"\"\"Get parameter settings (e.g., ferquency, time constant added by DV.add_parameters()) from a labrad hdf5 file Parameters ---------- dir_path : string Usually this is \"vault\" directory file_num : int hdf5 file number. ex. '00033 - measurement_name.hdf5' file_name : string Returns ------- dictionary Pairs of paramter keys and values Notes ----- The default parameter values are encoded by labrad format. The prefix in endoded values is 'data:application/labrad;base64,' To decode these and get the raw value, we need to simply use DV.get_parameters() or change the backend script in datavault/backend.py This function works in the latter case. \"\"\" # Load hdf5 file f_name = '0' * ( 5 - len ( str ( file_num ))) + str ( file_num ) + ' - ' + file_name + '.hdf5' f = h5py . File ( dir_path + f_name , 'r' )[ 'DataVault' ] attrs = f . attrs # Get parameters labels and values param_ukeys = sorted ([ str ( x ) for x in list ( attrs . keys ()) if str ( x ) . startswith ( 'Param' )]) param_keys = [ c [ 6 :] for c in param_ukeys ] param_values = [ attrs [ c ] for c in param_ukeys ] return { k : v for k , v in zip ( param_keys , param_values )} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def get_parameters_of_func ( offset = None ): \"\"\"Get a dictionary of paramteres of the function. Parameters ---------- offset : int default value is None Return ------ dictionary The dictionary includes pairs of paremeter's name and the corresponding values. References ---------- [1] https://tottoto.net/python3-get-args-of-current-function/ \"\"\" parent_frame = inspect . currentframe () . f_back info = inspect . getargvalues ( parent_frame ) return { key : info . locals [ key ] for key in info . args [ offset :]} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def create_labrad_hdf5file ( DV , file_path , scan_name , scan_var , meas_var ): \"\"\"Create a labrad hdf5 file from ndarray. Parameters ---------- DV : object file_path : string scan_name : string scan_var : list or tuple meas_var : list or tuple Returns ------- int The file number \"\"\" DV . cd ( '' ) try : DV . mkdir ( file_path ) DV . cd ( file_path ) except Exception : DV . cd ( file_path ) file_name = file_path + '_' + scan_name dv_file = DV . new ( file_name , scan_var , meas_var ) print ' \\r ' , \"new file created, file numer: \" , int ( dv_file [ 1 ][ 0 : 5 ]) return int ( dv_file [ 1 ][ 0 : 5 ]) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def write_meas_parameters ( DV , file_path , file_number , date , scan_name , meas_parameters , amplitude , sensitivity ): \"\"\"Write measurement parameters to txt file and labrad hdf5 file. Parameters ---------- DV : object file_path : string file_number : int date : object scan_name : string meas_parameters : dict scan_var : list or tuple meas_var : list or tuple amplitude : float sensitivity : float Returns ------- None \"\"\" if not os . path . isfile ( meas_details_path + file_path + '.txt' ): with open ( meas_details_path + file_path + '.txt' , \"w+\" ) as f : pass with open ( meas_details_path + file_path + '.txt' , \"a\" ) as f : f . write ( \"========\" + \" \\n \" ) f . write ( \"file_number: \" + str ( file_number ) + \" \\n \" + \"date: \" + str ( date ) + \" \\n \" + \"measurement:\" + str ( scan_name ) + \" \\n \" ) for k , v in sorted ( meas_parameters . items ()): print ( k , v ) f . write ( str ( k ) + \": \" + str ( v ) + \" \\n \" ) DV . add_parameter ( str ( k ), str ( v )) for i , LA in enumerate ( LAs ): tc = LA . time_constant () sens = LA . sensitivity () f . write ( \"time_constant_\" + str ( i ) + ' : ' + str ( tc ) + \" \\n \" ) f . write ( \"sensitivity_\" + str ( i ) + ' : ' + str ( sens ) + \" \\n \" ) DV . add_parameter ( \"time_constant_\" + str ( i ), tc ) DV . add_parameter ( \"sensitivity_\" + str ( i ), sens ) def write_meas_parameters_end ( date1 , date2 , file_path ): with open ( meas_details_path + file_path + '.txt' , \"a\" ) as f : f . write ( \"end date: \" + str ( date2 ) + \" \\n \" + \"total time: \" + str ( date2 - date1 ) + \" \\n \" ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def get_variables ( DV ): \"\"\"Get variables of a lablad hdf5 file Parameters ---------- DV : object (datavault) Return ------ list A variable of the a lablad hdf5 file \"\"\" variables = [ DV . variables ()[ 0 ][ i ][ 0 ] for i in range ( len ( DV . variables ()[ 0 ]))] + [ DV . variables ()[ 1 ][ i ][ 0 ] for i in range ( len ( DV . variables ()[ 1 ]))] return variables","title":"LabRAD"},{"location":"labrad/#labrad_hdf5_dataloader","text":"labrad hdf5\u304b\u3089ndarray\u5f62\u5f0f\u3067\u30c7\u30fc\u30bf\u3092\u53d6\u308a\u51fa\u3059\u3002 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def labrad_hdf5_ndarray ( dir_path , file_num , file_name ): \"\"\"Load a hdf5 file and return the data (numpy.array) and columns of labels (list) Parameters ---------- dir_path : string Usually this is \"vault\" directory file_num : int hdf5 file number. ex. '000## - measurement_name.hdf5' file_name : string Returns ------- data : ndarray variables : list list of parameters \"\"\" # Load hdf5 file f_name = '0' * ( 5 - len ( str ( file_num ))) + str ( file_num ) + ' - ' + file_name + '.hdf5' f = h5py . File ( dir_path + f_name , 'r' )[ 'DataVault' ] raw_data = f . value attrs = f . attrs # Raw data to np.array data = np . array ([ list ( d ) for d in raw_data ]) # Get varialbles labels indep_keys = sorted ([ str ( x ) for x in list ( attrs . keys ()) if str ( x ) . startswith ( 'Independent' ) and str ( x ) . endswith ( 'label' )]) dep_keys = sorted ([ str ( x ) for x in list ( attrs . keys ()) if str ( x ) . startswith ( 'Dependent' ) and str ( x ) . endswith ( 'label' )]) indep_labels = [ attrs [ c ] for c in indep_keys ] dep_labels = [ attrs [ c ] for c in dep_keys ] variables = indep_labels + dep_labels return data , variables","title":"labrad_hdf5_dataloader"},{"location":"labrad/#labrad_hdf5_get_parameters","text":"labrad hdf5\u304b\u3089DV.add_parameters()\u3067\u52a0\u3048\u305f\u6a5f\u5668\u306e\u8a2d\u5b9a\u306e\u60c5\u5831\u306a\u3069\u3092\u53d6\u5f97\u3059\u308b\u3002 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 def labrad_hdf5_get_parameters ( dir_path , file_num , file_name ): \"\"\"Get parameter settings (e.g., ferquency, time constant added by DV.add_parameters()) from a labrad hdf5 file Parameters ---------- dir_path : string Usually this is \"vault\" directory file_num : int hdf5 file number. ex. '00033 - measurement_name.hdf5' file_name : string Returns ------- dictionary Pairs of paramter keys and values Notes ----- The default parameter values are encoded by labrad format. The prefix in endoded values is 'data:application/labrad;base64,' To decode these and get the raw value, we need to simply use DV.get_parameters() or change the backend script in datavault/backend.py This function works in the latter case. \"\"\" # Load hdf5 file f_name = '0' * ( 5 - len ( str ( file_num ))) + str ( file_num ) + ' - ' + file_name + '.hdf5' f = h5py . File ( dir_path + f_name , 'r' )[ 'DataVault' ] attrs = f . attrs # Get parameters labels and values param_ukeys = sorted ([ str ( x ) for x in list ( attrs . keys ()) if str ( x ) . startswith ( 'Param' )]) param_keys = [ c [ 6 :] for c in param_ukeys ] param_values = [ attrs [ c ] for c in param_ukeys ] return { k : v for k , v in zip ( param_keys , param_values )} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def get_parameters_of_func ( offset = None ): \"\"\"Get a dictionary of paramteres of the function. Parameters ---------- offset : int default value is None Return ------ dictionary The dictionary includes pairs of paremeter's name and the corresponding values. References ---------- [1] https://tottoto.net/python3-get-args-of-current-function/ \"\"\" parent_frame = inspect . currentframe () . f_back info = inspect . getargvalues ( parent_frame ) return { key : info . locals [ key ] for key in info . args [ offset :]} 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 def create_labrad_hdf5file ( DV , file_path , scan_name , scan_var , meas_var ): \"\"\"Create a labrad hdf5 file from ndarray. Parameters ---------- DV : object file_path : string scan_name : string scan_var : list or tuple meas_var : list or tuple Returns ------- int The file number \"\"\" DV . cd ( '' ) try : DV . mkdir ( file_path ) DV . cd ( file_path ) except Exception : DV . cd ( file_path ) file_name = file_path + '_' + scan_name dv_file = DV . new ( file_name , scan_var , meas_var ) print ' \\r ' , \"new file created, file numer: \" , int ( dv_file [ 1 ][ 0 : 5 ]) return int ( dv_file [ 1 ][ 0 : 5 ]) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 def write_meas_parameters ( DV , file_path , file_number , date , scan_name , meas_parameters , amplitude , sensitivity ): \"\"\"Write measurement parameters to txt file and labrad hdf5 file. Parameters ---------- DV : object file_path : string file_number : int date : object scan_name : string meas_parameters : dict scan_var : list or tuple meas_var : list or tuple amplitude : float sensitivity : float Returns ------- None \"\"\" if not os . path . isfile ( meas_details_path + file_path + '.txt' ): with open ( meas_details_path + file_path + '.txt' , \"w+\" ) as f : pass with open ( meas_details_path + file_path + '.txt' , \"a\" ) as f : f . write ( \"========\" + \" \\n \" ) f . write ( \"file_number: \" + str ( file_number ) + \" \\n \" + \"date: \" + str ( date ) + \" \\n \" + \"measurement:\" + str ( scan_name ) + \" \\n \" ) for k , v in sorted ( meas_parameters . items ()): print ( k , v ) f . write ( str ( k ) + \": \" + str ( v ) + \" \\n \" ) DV . add_parameter ( str ( k ), str ( v )) for i , LA in enumerate ( LAs ): tc = LA . time_constant () sens = LA . sensitivity () f . write ( \"time_constant_\" + str ( i ) + ' : ' + str ( tc ) + \" \\n \" ) f . write ( \"sensitivity_\" + str ( i ) + ' : ' + str ( sens ) + \" \\n \" ) DV . add_parameter ( \"time_constant_\" + str ( i ), tc ) DV . add_parameter ( \"sensitivity_\" + str ( i ), sens ) def write_meas_parameters_end ( date1 , date2 , file_path ): with open ( meas_details_path + file_path + '.txt' , \"a\" ) as f : f . write ( \"end date: \" + str ( date2 ) + \" \\n \" + \"total time: \" + str ( date2 - date1 ) + \" \\n \" ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def get_variables ( DV ): \"\"\"Get variables of a lablad hdf5 file Parameters ---------- DV : object (datavault) Return ------ list A variable of the a lablad hdf5 file \"\"\" variables = [ DV . variables ()[ 0 ][ i ][ 0 ] for i in range ( len ( DV . variables ()[ 0 ]))] + [ DV . variables ()[ 1 ][ i ][ 0 ] for i in range ( len ( DV . variables ()[ 1 ]))] return variables","title":"labrad_hdf5_get_parameters"},{"location":"linux_command/","text":"Linux \u30b3\u30de\u30f3\u30c9 \u00b6 \u30b7\u30a7\u30eb\u306f\u30ab\u30fc\u30cd\u30eb\u306b\u547d\u4ee4\u3092\u51fa\u3057\u3066\u30ab\u30fc\u30cd\u30eb\u304b\u3089\u7d50\u679c\u3092\u53d7\u3051\u53d6\u308b\u305f\u3081\u306e\u3082\u306e bash \u306f\u30b7\u30a7\u30eb\u306e\uff11\u3064\u3000echo $SHELL\u3067\u78ba\u8a8d sh\u306e1\u3064 \u30bf\u30fc\u30df\u30ca\u30eb\uff1a\u5165\u51fa\u529b\u3000\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\uff08Linux\u306e\u5834\u5408\u3067\u306f\u5165\u51fa\u529b\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u306e\u30bf\u30fc\u30df\u30ca\u30eb\u30a8\u30df\u30e5\u30ec\u30fc\u30bf\u3092\u6307\u3059\u3002\u30b3\u30de\u30f3\u30c9\u3092\u3046\u3051\u3068\u3063\u305f\u308a\u51fa\u529b\uff09 \u30d7\u30ed\u30f3\u30d7\u30c8\uff1a\u30ab\u30fc\u30bd\u30eb\u306e\u5de6\u5074[ ^^^^@ ~]\u3000\u30b3\u30de\u30f3\u30c9\u5165\u529b\u3092\u4fc3\u3059 \u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3: \u30d7\u30ed\u30f3\u30d7\u30c8\u306e\u53f3\u5074 \u57fa\u672c\u64cd\u4f5c ctl + a: atama\u306b\u79fb\u52d5 ctrl + e: end\u306b\u79fb\u52d5 ctrl + w:\u3000 word: \u5358\u8a9e\u5358\u4f4d\u3067\u524a\u9664 \u30ab\u30c3\u30c8\u3000\u30a2\u30f3\u30c9\u3000\u30e4\u30f3\u30af ctrl + u \u884c\u982d\u307e\u3067\u30ab\u30c3\u30c8 ctrl + k:\u884c\u672b\u307e\u3067\u30ab\u30c3\u30c8 ctrl + y (yank) \u30bf\u30d6\u3067\u30aa\u30fc\u30c8\u30b3\u30f3\u30d7\u30ea\u30fc\u30c8 ls ls -a echo \u30b3\u30de\u30f3\u30c9 cat/less/tail cat >> cat > wget curl ping host ps kill grep \u30b3\u30de\u30f3\u30c9 space(\u4e00\u753b\u9762\u4e0b)\u3000b\uff08\u4e00\u753b\u9762\u4e0a\uff09 j\uff08\u4e00\u884c\u305a\u3064\u4e0b\uff09 k\uff08\u4e00\u884c\u305a\u3064\u4e0a\uff09 q \u306f\u3082\u3068\u306e\u753b\u9762\u306b\u623b\u308b\uff08quit\uff09 wget \u30b3\u30de\u30f3\u30c9 unzip touch \u30b3\u30de\u30f3\u30c9 rm \u3068rm -r echo \\(PATH export PATH = /path/to/something:\\) PATH\u3092\u8ffd\u52a0\u3059\u308b\u3002 cp /etc/crontab file2 cp file1 directory\u3067\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u30b3\u30d4\u30fc\u53ef\u80fd \u6307\u5b9a\u3057\u305f\u30b3\u30d4\u30fc\u5148\u304c\u5b58\u5728\u3059\u308b\u5834\u5408\u306f\u3001\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u4e2d\u306b\u306a\u308b \u5b58\u5728\u3057\u306a\u3044\u5834\u5408\u306f\u65b0\u3057\u3044\u30d5\u30a1\u30a4\u30eb\u540d\u306b\u306a\u308b\u3002 cp -r dir1 dir2\u3067\u518d\u5e30\u7684\u306b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u30b3\u30d4\u30fc\u53ef\u80fd mv\u30b3\u30de\u30f3\u30c9\u3067\u540d\u524d\u3092\u5909\u3048\u308b\u3053\u3068\u3082\u3067\u304d\u308b\u3057\u3001\u30d5\u30a1\u30a4\u30eb\u3092\u79fb\u52d5\u3067\u304d\u308b\u3002 sh -x \u3067\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u78ba\u8a8d docker \u30d5\u30a1\u30a4\u30eb\u306e\u3068\u304d\u306f-b -p\u3092\u3064\u3051\u308b\u3002 \u30cf\u30fc\u30c9\u30ea\u30f3\u30af \u30b7\u30f3\u30dc\u30ea\u30c3\u30af\u30ea\u30f3\u30af ln file1 file2 (file1\u306bfile2\u3068\u3044\u3046\u30cf\u30fc\u30c9\u30ea\u30f3\u30af\u3092\u4f5c\u6210\u3059\u308b\u3002file1\u3092\u4f5c\u6210\u3057\u3066\u3082file2\u304c\u6b8b\u308b) ln -s file1 file2\u3067\u30b7\u30f3\u30dc\u30ea\u30c3\u30af\u30ea\u30f3\u30af\u3092\u4f5c\u6210\u3059\u308b mkdir -p dir1/dir2/dir3/target touch p dir1/dir2/dir3/target/file ln -s dir1/dir2/dir3/target/ target \u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea(/)\u3068\u30db\u30fc\u30e0\u30c7\u30a3\u30ec\u30af\u30c8\u30ea(~)\u306e\u3061\u3083\u3093\u3068\u3057\u305f\u7406\u89e3 - Qiita \u3082\u306e\u3059\u3054\u3044\u7d30\u304b\u3044\u3053\u3068\u3060\u3051\u3069\u3001\u30d1\u30b9\u306e\u6307\u5b9a\u65b9\u6cd5\u3067\u306e ~ \uff08\u30c1\u30eb\u30c0\uff09\u3068 / \uff08\u30b9\u30e9\u30c3\u30b7\u30e5\uff09\u306e\u7406\u89e3\u304c\u66d6\u6627\u3067\u6c17\u6301\u3061\u60aa\u3044\u601d\u3044\u3092\u3057\u305f\u306e\u3067\u30e1\u30e2\u3002 / : \u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea ~ \uff1a\u4eca\u306e\u30e6\u30fc\u30b6\u30fc\u306e\u30db\u30fc\u30e0\u30c7\u30a3\u30ec\u30af\u30c8\u30ea ~taro : taro\u3068\u3044\u3046\u30e6\u30fc\u30b6\u30fc\u306e\u30db\u30fc\u30e0\u30c7\u30a3\u30ec\u30af\u30c8\u30ea \u30b9\u30e9\u30c3\u30b7\u30e5\u306e\u610f\u5473\u5408\u3044 \u00b6 \u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e / \u3068\u3001\u5404\u30d5\u30a1\u30a4\u30eb\u3084\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u524d\u306b\u3064\u304f / \u306f\u610f\u5473\u5408\u3044\u304c\u9055\u3063\u3066\u3044\u308b\u6a21\u69d8\u3002 \u524d\u8005\uff1a\u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u305d\u306e\u3082\u306e \u5f8c\u8005\uff1a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u533a\u5207\u308b\u3082\u306e \u306a\u306e\u3067\u3001\u4e00\u898b\u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u305b\u3044\u3067\u300c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3068\u306f\u672b\u5c3e\u306b\u30b9\u30e9\u30c3\u30b7\u30e5\u304c\u4ed8\u3044\u3066\u3044\u308b\u3082\u306e\u300d\u3068\u3044\u3046\u52d8\u9055\u3044\u3092\uff08\u5c11\u306a\u304f\u3082\u7b46\u8005\u306f\uff09\u3057\u3061\u3083\u3046\u304c\u3001 hogehoge/ \u304c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306a\u306e\u3067\u306f\u306a\u304f hogehoge \u304c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306a\u306e\u3060\u3002\u30db\u30fc\u30e0\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092 ~/ \u3060\u3068\u601d\u3063\u3066\u3057\u307e\u3063\u3066\u3044\u308b\u4eba\u306f\u591a\u3044\u306e\u3067\u306f\u306a\u3044\u304b\uff1f history !393\u3067\u4f7f\u3048\u308b \u30d4\u30ea\u30aa\u30c9\u3067\u30ab\u30ec\u30f3\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea find . -name '*.txt' -print \u3053\u306e\u30a2\u30b9\u30bf\u30ea\u30b9\u30af\u306f\u30ef\u30a4\u30eb\u30c9\u30ab\u30fc\u30c9\u3067\u30d1\u30b9\u540d\u5c55\u958b\u3068\u306f\u9055\u3046\u3002\u30c0\u30d6\u30eb\u30af\u30aa\u30fc\u30c6\u30b7\u30e7\u30f3\u304b\u3069\u3046\u304b find . -type d \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3060\u3051\u691c\u7d22 find . -type d -a -name share locate \u30b3\u30de\u30f3\u30c9\u306ffind\u30b3\u30de\u30f3\u30c9\u3088\u308a\u3082\u9ad8\u901f\uff08\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304b\u3089\u691c\u7d22\uff09 sudo updatedb\u3092\u3057\u3066\u304b\u3089 locate bash -A doc \u3000and \u691c\u7d22 locate bash doc grep bin /etc/crontab \u30d5\u30a3\u30eb\u30bf history | head wc:\u6587\u5b57\u6570\u3092\u6570\u3048\u308b wc -l ls / | wc -l \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u500b\u6570\u884c\u6570 \u30bd\u30fc\u30c8\u30b3\u30de\u30f3\u30c9 sort word.txt sort -r word.txt sort -n number.txt \u91cd\u8907\u3092\u53d6\u308a\u51fa\u3059 uniq number.txt sort -n number.txt | uniq sort -n number.txt | uniq -c | sort -nr | head -n 3 \u30d5\u30a1\u30a4\u30eb\u3092\u76e3\u8996\u3059\u308b tail -f log.txt \u30e1\u30e2\u30ea\u304b\u3089\u898b\u305f\u5b9f\u884c\u72b6\u614b\u306b\u3042\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u30d7\u30ed\u30bb\u30b9\u3068\u3044\u3046 \u30b8\u30e7\u30d6\u306f\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u306b\u5165\u529b\u3055\u308c\u305f\u884c\uff08\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u3068\u304d\u306f\u8907\u6570\u306b\u306a\u308b\u3002\uff09 ps\u30b3\u30de\u30f3\u30c9 ps -x ps -u sleep\u30b3\u30de\u30f3\u30c9 jobs\u30b3\u30de\u30f3\u30c9 fg\u30b3\u30de\u30f3\u30c9 bg\u30b3\u30de\u30f3\u30c9","title":"Linux"},{"location":"linux_command/#linux","text":"\u30b7\u30a7\u30eb\u306f\u30ab\u30fc\u30cd\u30eb\u306b\u547d\u4ee4\u3092\u51fa\u3057\u3066\u30ab\u30fc\u30cd\u30eb\u304b\u3089\u7d50\u679c\u3092\u53d7\u3051\u53d6\u308b\u305f\u3081\u306e\u3082\u306e bash \u306f\u30b7\u30a7\u30eb\u306e\uff11\u3064\u3000echo $SHELL\u3067\u78ba\u8a8d sh\u306e1\u3064 \u30bf\u30fc\u30df\u30ca\u30eb\uff1a\u5165\u51fa\u529b\u3000\u30cf\u30fc\u30c9\u30a6\u30a7\u30a2\uff08Linux\u306e\u5834\u5408\u3067\u306f\u5165\u51fa\u529b\u30bd\u30d5\u30c8\u30a6\u30a7\u30a2\u306e\u30bf\u30fc\u30df\u30ca\u30eb\u30a8\u30df\u30e5\u30ec\u30fc\u30bf\u3092\u6307\u3059\u3002\u30b3\u30de\u30f3\u30c9\u3092\u3046\u3051\u3068\u3063\u305f\u308a\u51fa\u529b\uff09 \u30d7\u30ed\u30f3\u30d7\u30c8\uff1a\u30ab\u30fc\u30bd\u30eb\u306e\u5de6\u5074[ ^^^^@ ~]\u3000\u30b3\u30de\u30f3\u30c9\u5165\u529b\u3092\u4fc3\u3059 \u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3: \u30d7\u30ed\u30f3\u30d7\u30c8\u306e\u53f3\u5074 \u57fa\u672c\u64cd\u4f5c ctl + a: atama\u306b\u79fb\u52d5 ctrl + e: end\u306b\u79fb\u52d5 ctrl + w:\u3000 word: \u5358\u8a9e\u5358\u4f4d\u3067\u524a\u9664 \u30ab\u30c3\u30c8\u3000\u30a2\u30f3\u30c9\u3000\u30e4\u30f3\u30af ctrl + u \u884c\u982d\u307e\u3067\u30ab\u30c3\u30c8 ctrl + k:\u884c\u672b\u307e\u3067\u30ab\u30c3\u30c8 ctrl + y (yank) \u30bf\u30d6\u3067\u30aa\u30fc\u30c8\u30b3\u30f3\u30d7\u30ea\u30fc\u30c8 ls ls -a echo \u30b3\u30de\u30f3\u30c9 cat/less/tail cat >> cat > wget curl ping host ps kill grep \u30b3\u30de\u30f3\u30c9 space(\u4e00\u753b\u9762\u4e0b)\u3000b\uff08\u4e00\u753b\u9762\u4e0a\uff09 j\uff08\u4e00\u884c\u305a\u3064\u4e0b\uff09 k\uff08\u4e00\u884c\u305a\u3064\u4e0a\uff09 q \u306f\u3082\u3068\u306e\u753b\u9762\u306b\u623b\u308b\uff08quit\uff09 wget \u30b3\u30de\u30f3\u30c9 unzip touch \u30b3\u30de\u30f3\u30c9 rm \u3068rm -r echo \\(PATH export PATH = /path/to/something:\\) PATH\u3092\u8ffd\u52a0\u3059\u308b\u3002 cp /etc/crontab file2 cp file1 directory\u3067\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u30b3\u30d4\u30fc\u53ef\u80fd \u6307\u5b9a\u3057\u305f\u30b3\u30d4\u30fc\u5148\u304c\u5b58\u5728\u3059\u308b\u5834\u5408\u306f\u3001\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u4e2d\u306b\u306a\u308b \u5b58\u5728\u3057\u306a\u3044\u5834\u5408\u306f\u65b0\u3057\u3044\u30d5\u30a1\u30a4\u30eb\u540d\u306b\u306a\u308b\u3002 cp -r dir1 dir2\u3067\u518d\u5e30\u7684\u306b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u30b3\u30d4\u30fc\u53ef\u80fd mv\u30b3\u30de\u30f3\u30c9\u3067\u540d\u524d\u3092\u5909\u3048\u308b\u3053\u3068\u3082\u3067\u304d\u308b\u3057\u3001\u30d5\u30a1\u30a4\u30eb\u3092\u79fb\u52d5\u3067\u304d\u308b\u3002 sh -x \u3067\u30aa\u30d7\u30b7\u30e7\u30f3\u3092\u78ba\u8a8d docker \u30d5\u30a1\u30a4\u30eb\u306e\u3068\u304d\u306f-b -p\u3092\u3064\u3051\u308b\u3002 \u30cf\u30fc\u30c9\u30ea\u30f3\u30af \u30b7\u30f3\u30dc\u30ea\u30c3\u30af\u30ea\u30f3\u30af ln file1 file2 (file1\u306bfile2\u3068\u3044\u3046\u30cf\u30fc\u30c9\u30ea\u30f3\u30af\u3092\u4f5c\u6210\u3059\u308b\u3002file1\u3092\u4f5c\u6210\u3057\u3066\u3082file2\u304c\u6b8b\u308b) ln -s file1 file2\u3067\u30b7\u30f3\u30dc\u30ea\u30c3\u30af\u30ea\u30f3\u30af\u3092\u4f5c\u6210\u3059\u308b mkdir -p dir1/dir2/dir3/target touch p dir1/dir2/dir3/target/file ln -s dir1/dir2/dir3/target/ target \u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea(/)\u3068\u30db\u30fc\u30e0\u30c7\u30a3\u30ec\u30af\u30c8\u30ea(~)\u306e\u3061\u3083\u3093\u3068\u3057\u305f\u7406\u89e3 - Qiita \u3082\u306e\u3059\u3054\u3044\u7d30\u304b\u3044\u3053\u3068\u3060\u3051\u3069\u3001\u30d1\u30b9\u306e\u6307\u5b9a\u65b9\u6cd5\u3067\u306e ~ \uff08\u30c1\u30eb\u30c0\uff09\u3068 / \uff08\u30b9\u30e9\u30c3\u30b7\u30e5\uff09\u306e\u7406\u89e3\u304c\u66d6\u6627\u3067\u6c17\u6301\u3061\u60aa\u3044\u601d\u3044\u3092\u3057\u305f\u306e\u3067\u30e1\u30e2\u3002 / : \u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea ~ \uff1a\u4eca\u306e\u30e6\u30fc\u30b6\u30fc\u306e\u30db\u30fc\u30e0\u30c7\u30a3\u30ec\u30af\u30c8\u30ea ~taro : taro\u3068\u3044\u3046\u30e6\u30fc\u30b6\u30fc\u306e\u30db\u30fc\u30e0\u30c7\u30a3\u30ec\u30af\u30c8\u30ea","title":"Linux \u30b3\u30de\u30f3\u30c9"},{"location":"linux_command/#_1","text":"\u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e / \u3068\u3001\u5404\u30d5\u30a1\u30a4\u30eb\u3084\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u524d\u306b\u3064\u304f / \u306f\u610f\u5473\u5408\u3044\u304c\u9055\u3063\u3066\u3044\u308b\u6a21\u69d8\u3002 \u524d\u8005\uff1a\u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u305d\u306e\u3082\u306e \u5f8c\u8005\uff1a\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u533a\u5207\u308b\u3082\u306e \u306a\u306e\u3067\u3001\u4e00\u898b\u30eb\u30fc\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u305b\u3044\u3067\u300c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3068\u306f\u672b\u5c3e\u306b\u30b9\u30e9\u30c3\u30b7\u30e5\u304c\u4ed8\u3044\u3066\u3044\u308b\u3082\u306e\u300d\u3068\u3044\u3046\u52d8\u9055\u3044\u3092\uff08\u5c11\u306a\u304f\u3082\u7b46\u8005\u306f\uff09\u3057\u3061\u3083\u3046\u304c\u3001 hogehoge/ \u304c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306a\u306e\u3067\u306f\u306a\u304f hogehoge \u304c\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306a\u306e\u3060\u3002\u30db\u30fc\u30e0\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092 ~/ \u3060\u3068\u601d\u3063\u3066\u3057\u307e\u3063\u3066\u3044\u308b\u4eba\u306f\u591a\u3044\u306e\u3067\u306f\u306a\u3044\u304b\uff1f history !393\u3067\u4f7f\u3048\u308b \u30d4\u30ea\u30aa\u30c9\u3067\u30ab\u30ec\u30f3\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea find . -name '*.txt' -print \u3053\u306e\u30a2\u30b9\u30bf\u30ea\u30b9\u30af\u306f\u30ef\u30a4\u30eb\u30c9\u30ab\u30fc\u30c9\u3067\u30d1\u30b9\u540d\u5c55\u958b\u3068\u306f\u9055\u3046\u3002\u30c0\u30d6\u30eb\u30af\u30aa\u30fc\u30c6\u30b7\u30e7\u30f3\u304b\u3069\u3046\u304b find . -type d \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3060\u3051\u691c\u7d22 find . -type d -a -name share locate \u30b3\u30de\u30f3\u30c9\u306ffind\u30b3\u30de\u30f3\u30c9\u3088\u308a\u3082\u9ad8\u901f\uff08\u30c7\u30fc\u30bf\u30d9\u30fc\u30b9\u304b\u3089\u691c\u7d22\uff09 sudo updatedb\u3092\u3057\u3066\u304b\u3089 locate bash -A doc \u3000and \u691c\u7d22 locate bash doc grep bin /etc/crontab \u30d5\u30a3\u30eb\u30bf history | head wc:\u6587\u5b57\u6570\u3092\u6570\u3048\u308b wc -l ls / | wc -l \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u500b\u6570\u884c\u6570 \u30bd\u30fc\u30c8\u30b3\u30de\u30f3\u30c9 sort word.txt sort -r word.txt sort -n number.txt \u91cd\u8907\u3092\u53d6\u308a\u51fa\u3059 uniq number.txt sort -n number.txt | uniq sort -n number.txt | uniq -c | sort -nr | head -n 3 \u30d5\u30a1\u30a4\u30eb\u3092\u76e3\u8996\u3059\u308b tail -f log.txt \u30e1\u30e2\u30ea\u304b\u3089\u898b\u305f\u5b9f\u884c\u72b6\u614b\u306b\u3042\u308b\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u30d7\u30ed\u30bb\u30b9\u3068\u3044\u3046 \u30b8\u30e7\u30d6\u306f\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u306b\u5165\u529b\u3055\u308c\u305f\u884c\uff08\u30d1\u30a4\u30d7\u30e9\u30a4\u30f3\u306e\u3068\u304d\u306f\u8907\u6570\u306b\u306a\u308b\u3002\uff09 ps\u30b3\u30de\u30f3\u30c9 ps -x ps -u sleep\u30b3\u30de\u30f3\u30c9 jobs\u30b3\u30de\u30f3\u30c9 fg\u30b3\u30de\u30f3\u30c9 bg\u30b3\u30de\u30f3\u30c9","title":"\u30b9\u30e9\u30c3\u30b7\u30e5\u306e\u610f\u5473\u5408\u3044"},{"location":"parallel/","text":"","title":"Parallel"},{"location":"plot/","text":"\u753b\u50cf\u3092\u4e26\u3079\u3066plot \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 import matplotlib.pyplot as plt import matplotlib.image as mpimg from PIL import Image IMAGE_DIR = \"/dataset/JAPANESE_FACES/personal_output/\" num_rows , num_cols = 6 , 6 f , axes = plt . subplots ( nrows = num_rows , ncols = num_cols , figsize = ( 24 , 24 )) for index , d in enumerate ( image_list ): plt . axis ( \"off\" ) plt . subplot ( 6 , 6 , index + 1 ) plt . imshow ( mpimg . imread ( IMAGE_DIR + d ))","title":"Plot"},{"location":"plot/#plot","text":"1 2 3 4 5 6 7 8 9 10 11 12 import matplotlib.pyplot as plt import matplotlib.image as mpimg from PIL import Image IMAGE_DIR = \"/dataset/JAPANESE_FACES/personal_output/\" num_rows , num_cols = 6 , 6 f , axes = plt . subplots ( nrows = num_rows , ncols = num_cols , figsize = ( 24 , 24 )) for index , d in enumerate ( image_list ): plt . axis ( \"off\" ) plt . subplot ( 6 , 6 , index + 1 ) plt . imshow ( mpimg . imread ( IMAGE_DIR + d ))","title":"\u753b\u50cf\u3092\u4e26\u3079\u3066plot"},{"location":"python_basis/","text":"Python basis \u00b6 \u57fa\u790e \u00b6 Python\u306f\u3059\u3079\u3066\u304c\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002int, str, \u95a2\u6570 Python\u306f\u52d5\u7684\u578b\u4ed8\u3051\u8a00\u8a9e\u3001\u578b\u3088\u308a\u3082\u632f\u308b\u821e\u3044\u306b\u8208\u5473\u304c\u3042\u308b\u3002 \u4fbf\u5229\u306a\u30d3\u30eb\u30c9\u30a4\u30f3\u95a2\u6570 id():\u5909\u6570\u306e\u5834\u6240\u306eid\u3092\u8fd4\u3059 dir:attribute\u3092\u8fd4\u3059 is\u6f14\u7b97\u5b50\uff1a\u540c\u3058\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304b\u3069\u3046\u304b\u3092\u5224\u65ad\u3059\u308b isinstance:\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u30bf\u30a4\u30d7\u3092\u78ba\u8a8d copy\u3068deepcopy \u578b\u5909\u63db\uff08casting\uff09 \u30a4\u30df\u30e5\u30fc\u30bf\u30d6\u30eb\u3068\u30df\u30e5\u30fc\u30bf\u30d6\u30eb\uff1a\u95a2\u6570\u306e\u4e2d\u3067\u65b0\u3057\u3044\uff08\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\uff09ID\u304c\u4f5c\u3089\u308c\u308b\u3002for\u6587\u3067\u306f\u8db3\u3057\u3066\u3044\u304f\u3068\u304d\u306f\u30ea\u30b9\u30c8\u3092\u4f7f\u3046\u307b\u3046\u304c\u826f\u3044\u3002\uff09 _\u306f\u76f4\u524d\u306e\u5b9f\u884c\u3057\u305f\u623b\u308a\u5024\u3092\u683c\u7d0d\u3059\u308b\u3002 \u30d6\u30fc\u30ea\u30a2\u30f3\u306b\u6bd4\u8f03\u6f14\u7b97\u5b50\u3092\u4f7f\u308f\u306a\u3044\u3002 tuple\u306f\u300c\u4e38\u62ec\u5f27\u3067\u4f5c\u6210\u3055\u308c\u308b\u306e\u3067\u306f\u306a\u304f\u3001\u30ab\u30f3\u30de\u306b\u3088\u3063\u3066\u4f5c\u6210\u3055\u308c\u300d\u307e\u3059 \u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u66f8\u304d\u306b\u306f with open \u3092\u4f7f\u3046\u3002 namedtuple getattr:\u3092\u4f7f\u3046\u3002 https://qiita.com/ganyariya/items/3b8861788ec30238a8a9 \u4e09\u9023\u30af\u30aa\u30fc\u30c8\u306b\u3088\u308b\u8907\u6570\u884c\u6587\u5b57\u5217 shutil\u30e2\u30b8\u30e5\u30fc\u30eb 1 2 method = getattr ( animal , 'walk' , None ) if callable ( method ) vscode \u00b6 vscode\u3067\u81ea\u52d5\u3067\u5909\u6570\u3092\u5236\u5fa1\u3002\u66f8\u304d\u63db\u3048 vscode\u3067linter\u3068formatter\u3092\u8a2d\u5b9a black: https://github.com/psf/black flake8: https://github.com/PyCQA/flake8 isort: https://github.com/PyCQA/isort mypy \u30b3\u30e1\u30f3\u30c8\u3067# TODO \u74b0\u5883\u69cb\u7bc9 \u00b6 1 2 3 4 5 6 7 pip freeze pip freeze > requirements.txt pip install -r requirements.txt #or pipenv --python 3 pipenv install -r ./requirements.txt #\u81ea\u52d5\u3067pipfile\u304c\u4f5c\u6210 pipenv lock ) git\u304b\u3089install \u00b6 1 !pip install git+https://github.com/yseeker/tez_custom \u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30b9\u30bf\u30a4\u30eb \u00b6 pep8 \u00b6 =\u3068\u30aa\u30da\u30ec\u30fc\u30bf\u30fc\u306e\u5468\u308a\u306b\u30b9\u30da\u30fc\u30b9 \u95a2\u6570\u306e\u5f15\u6570\u306e\u5468\u308a\u306b\u30b9\u30da\u30fc\u30b9\u306f\u4e0d\u8981 \u30d7\u30e9\u30a4\u30aa\u30ea\u30c6\u30a3\u304c\u3042\u308b\u5834\u5408\u306f\u30b9\u30da\u30fc\u30b9\u3092\u7121\u304f\u3059 \u30ab\u30f3\u30de\u306e\u3042\u3068\u306b\u30b9\u30da\u30fc\u30b9\u3092\u5165\u308c\u308b\u3002 \u6700\u5f8c\u306e\u8981\u7d20\u306b\u30ab\u30f3\u30de\u3082\u3064\u3051\u308b\uff08\u62ec\u5f27\u9589\u3058\u3092\u6b21\u306e\u884c\u306b\u3059\u308b\u3002\uff09 \u95a2\u6570\u306e\u5f15\u6570\u306e\u982d\u3092\u63c3\u3048\u3066\u6539\u884c\u3059\u308b\u3002 \u95a2\u6570\u9593\u306f\u4e8c\u884c\u3042\u3051\u308b\u3002 \u30af\u30e9\u30b9\u306e\u30e1\u30bd\u30c3\u30c9\u9593\u306f1\u884c import \u306e\u9806\u756a standrd library third party our library local library \u74b0\u5883 \u00b6 pyenv + pipenv\u3092\u4f7f\u3046\u3002 \u95a2\u6570 \u00b6 Python\u3067\u306f \u5168\u3066\u53c2\u7167\u6e21\u3057 \u3002 constant variable \u5927\u6587\u5b57\u3067\u66f8\u304f \u30e2\u30b8\u30e5\u30fc\u30eb \uff08\u30d5\u30a1\u30a4\u30eb\u5358\u4f4d\u3067\u5206\u3051\u3066\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u8a18\u8f09\u3057\u305f\u3082\u306e\uff09\uff1c \u30d1\u30c3\u30b1\u30fc\u30b8 \uff08\u8907\u6570\u306e\u30d5\u30a1\u30a4\u30eb\u3001\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u69cb\u9020\u304b\u3089\u306a\u308a\u3001\u30eb\u30fc\u30eb\u306b\u5f93\u3063\u3066\u305d\u308c\u3089\u3092\u3072\u3068\u56fa\u307e\u308a\u306b\u3057\u305f\u3082\u306e\uff09\uff1c \u30e9\u30a4\u30d6\u30e9\u30ea \u3002 \u30d1\u30c3\u30b1\u30fc\u30b8\u306b\u306f\u3001\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3067\u968e\u5c64\u5316\u3055\u305b\u305f\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8aad\u307f\u8fbc\u307e\u305b\u308b\u305f\u3081\u306b init .py \u304c\u5fc5\u8981\uff08\u3053\u306e\u3068\u304d\u76f8\u5bfeimport\u3082\u884c\u3046\uff09 \u5f15\u6570\uff08arguments\uff09 \uff1a\u5b9f\u5f15\u6570\u3002\u95a2\u6570\u306b\u6e21\u3055\u308c\u308b\u5177\u4f53\u7684\u306a\u5024 \u30d1\u30e9\u30e1\u30fc\u30bf\uff08parameters\uff09 \uff1a\u4eee\u5f15\u6570\u3002\u95a2\u6570\u306b\u6e21\u3055\u308c\u308b\u5177\u4f53\u7684\u306a\u5024\u306e\u30d7\u30ec\u30fc\u30b9\u30db\u30eb\u30c0\u3002 https://qiita.com/raviqqe/items/ee2bcb6bef86502f8cc6#%E5%BC%95%E6%95%B0%E3%81%AF-2-x-2--4-%E7%A8%AE%E9%A1%9E positional paremeters \uff1a\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u5024\uff08arguments\uff09\u306a\u3057\u3002 keyword parameters \uff1a\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u5024\u3042\u308a\u3002 \u53ef\u5909\u9577\u5f15\u6570 : args, *kwargs, \u69d8\u3005\u306a\u9577\u3055\u306e\u5f15\u6570\u3092\u53d7\u3051\u53d6\u308c\u308b\u3002 global \u3068 nonlocal \uff08nested\u95a2\u6570\u306e\u3068\u304d\u306b\u5b9a\u7fa9\uff09 \u30e9\u30e0\u30c0\u95a2\u6570 \uff08\u95a2\u6570\u540d\u304c\u7121\u3044\u95a2\u6570\uff09:\u95a2\u6570\u540d\u3068\"return\"\u3092\u7121\u304f\u3059\u3002filter \u95a2\u6570\u306e\u969b\u306b\u4f7f\u3046\u3002 1 lm_add = lambda x , y : x + y \u95a2\u6570\u3082\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3001\u95a2\u6570\u3092\u5f15\u6570\u3067\u3068\u308c\u308b\u3001\u95a2\u6570\u3082return\u3067\u304d\u308b\uff08\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3068\u3057\u3066\u8fd4\u3059\u3002\uff09Closure:\u72b6\u614b\u3092\u30ad\u30fc\u30d7\u3057\u305f\u95a2\u6570\u3002\uff08\u72b6\u614b\u3092\u52d5\u7684\u30fb\u9759\u7684\uff09 sys.path :\u306b\u5165\u308c\u308b\u3068\u30ab\u30b9\u30bf\u30e0\u3067\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u4f7f\u3048\u308b\u3002pip\u3092\u4f7f\u3046\u3068site-packages\u306e\u4e2d\u3067\u7ba1\u7406\u3055\u308c\u308b\u3002 \u6b63\u898f\u8868\u73fe \u00b6 re.search('[0-9]', string) re.search('^[0-9]', string):\u6700\u521d\u306e\u6587\u5b57 re.search('^[0-9]{4}', string):\u6700\u521d\u306e\u6587\u5b57 \u30ea\u30d4\u30fc\u30c8 re.search('^[0-9]{2-4}', string):\u6700\u521d\u306e\u6587\u5b572-4\u6587\u5b57 \u30ea\u30d4\u30fc\u30c8 re.search('^[0-9]{2-4}$', string):\u6700\u5f8c\u306e\u6587\u5b572-4\u6587\u5b57 \u30ea\u30d4\u30fc\u30c8 re.search('a*b', 'aaaab')\u5de6\u306e\u30d1\u30bf\u30fc\u30f3\u30920\u56de\u4ee5\u4e0a\u7e70\u308a\u8fd4\u3059 re.search('a+b', 'aaaab')\u5de6\u306e\u30d1\u30bf\u30fc\u30f3\u30921\u56de\u4ee5\u4e0a\u7e70\u308a\u8fd4\u3059 re.search('ab?c', 'aaaab')\u5de6\u306e\u30d1\u30bf\u30fc\u30f3\u30920\u56de\u304b1\u56de\u7e70\u308a\u8fd4\u3059 abc|012 or te(s|x)t \u30b0\u30eb\u30fc\u30d7 'h.t'\u4efb\u610f\u306e\u4e00\u6587\u5b57 \u30a8\u30b9\u30b1\u30fc\u30d7'h.t' \\w [a-zA-Z0-9_]\u306b\u30de\u30c3\u30c1 \u30af\u30e9\u30b9 \u00b6 \u5c5e\u6027\uff08\u30e1\u30f3\u30d0\u5909\u6570\u3001\u30e1\u30f3\u30d0\u95a2\u6570\uff09, \u30e1\u30bd\u30c3\u30c9\uff08instancemethod, static method, class method\uff09, \u30d7\u30ed\u30d1\u30c6\u30a3 * \u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u5909\u6570\u3068\u30af\u30e9\u30b9\u5909\u6570 https://docs.python.org/ja/3/library/functions.html https://qiita.com/ichi_taro3/items/cd71a8e43040abb446a1 \u6163\u7fd2\u7684\u306a\u547d\u540d\u898f\u5247\u3068\u3057\u3066\u306e\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8(non public)\u5316\uff08\u30a2\u30f3\u30c0\u30fc\u30d0\u30fc\uff09\u3002\u6226\u95d8\u306b\u30a2\u30f3\u30c0\u30fc\u30d0\u30fc\u3092\u3064\u3051\u3066_\u540d\u524d\u3068\u3059\u308b \u30cd\u30fc\u30e0\u30de\u30f3\u30b0\u30ea\u30f3\u30b0\uff08\u96e3\u53f7\u5316\uff09\u8981\u7d20\u540d\u306e\u524d\u306b\"__\"\uff08\u30a2\u30f3\u30c0\u30fc\u30d0\u30fc2\u3064\uff09\u3092\u3064\u3051\u307e\u3059\u3002 \u7d99\u627f\u6642\u306e\u540d\u524d\u4fee\u98fe\u306f__\u3092\u4f7f\u3044\u3053\u306a\u3059\u3002 \u30dd\u30ea\u30e2\u30fc\u30d5\u30a3\u30ba\u30e0\u306f\u7d99\u627f\u3092\u3057\u3066\u3044\u308bint\u3082str\u3082print\u3092\u3059\u308b\u3068\u540c\u3058\u3088\u3046\u306b\u632f\u308b\u821e\u3046 \u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\uff1a\u30b5\u30d6\u30af\u30e9\u30b9\u306e\u3067\u540c\u3058\u540d\u524d\u306e\u95a2\u6570\u3092\u5b9a\u7fa9\u3059\u308b\u3002 .\u3068\u304b..\u3067\u76f8\u5bfe\u30a4\u30f3\u30dd\u30fc\u30c8\u3067\u304d\u308b\u3002 \u30c7\u30b3\u30ec\u30fc\u30bf \u00b6 https://qiita.com/koshigoe/items/848ddc0272b3cee92134 @staticmethod \uff1a\u307b\u3068\u3093\u3069\u30af\u30e9\u30b9\u5916\u306e\u95a2\u6570\u3068\u3057\u3066\u6271\u3046\u3002\uff08self\u306f\u3044\u3089\u306a\u3044\uff09 @classmethod \uff1acls\u306b\u5f15\u6570\u3092\u3068\u3063\u3066\u3001class\u306e\u60c5\u5831\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u3002\u7d99\u627f\u3059\u308b\u3068\u304d\u306fstaticmethod\u3067\u306f\u547c\u3076\u3068\u304d\u306b\u554f\u984c\u304c\u767a\u751f\u3059\u308b\u3002classmethod\u3092\u4f7f\u3046\u3002 @property \uff1a\u5909\u6570\u3092\u30ab\u30d7\u30bb\u30eb\u5316\u3057\u3001\u5909\u6570\u3060\u3051\u5916\u306b\u8fd4\u305b\u308b\u3088\u3046\u306b\u3059\u308b\u3002setter\u3068\u30bb\u30c3\u30c8\u3067\u4f7f\u3046\u3002\u5916\u304b\u3089\u5185\u90e8\u306e\u5024\u3092\u30bb\u30c3\u30c8\u3067\u304d\u308b\u3002 1 2 3 4 5 6 7 8 9 10 11 class Example : def __init__ ( self , x , y ): self . _x = x self . _y = y @property def x ( self ): return self . _x @x . setter def x ( self , dx ): self . _x += dx self . _x = max ( 0 , min ( self . MAX_X , self . _x )) @dataclass \uff1a\u30c7\u30fc\u30bf\u3092\u683c\u7d0d\u3059\u308b\u30af\u30e9\u30b9\u3092\u7c21\u5358\u306b\u4f5c\u6210\u3059\u308b\u30c7\u30b3\u30ec\u30fc\u30bf\u306a\u3069\u3092\u63d0\u4f9b 1 2 3 4 5 6 7 8 @dataclass class InventoryItem : name : str price : float quantity : int = 0 def total_cost ( self ) -> float : return self . price * self . quantity \u30de\u30b8\u30c3\u30af\u30e1\u30bd\u30c3\u30c9\uff08\u7279\u6b8a\u30e1\u30bd\u30c3\u30c9\uff09 \u00b6 http://diveintopython3-ja.rdy.jp/special-method-names.html __init__ \uff1a\u30af\u30e9\u30b9\u306e\u521d\u671f\u5316\u3002\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u3092\u547c\u3076\u3002\u89aa\u30af\u30e9\u30b9\u306e\u30b3\u30f3\u30b9\u30bf\u30af\u30bf\u3092\u547c\u3076\u3068\u304d\u306f\u3001super. init ()\u3068\u3059\u308b\u3002 __del__ \uff1a\u30c7\u30b9\u30c8\u30e9\u30af\u30bf\u3002\u57fa\u672c\u7684\u306b\u306f\u4f7f\u308f\u306a\u3044\u3002\u4ee3\u308f\u308a\u306bwith\u69cb\u6587\u3092\u4f7f\u3046\u3002 __call__ \uff1a\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u95a2\u6570\u306e\u3088\u3046\u306b\u6271\u3048\u308b\u3002 __len__ \uff1a len\u30e1\u30bd\u30c3\u30c9\u306b\u5bfe\u3059\u308bint\u578b\u306e\u5024\u3092\u8fd4\u3059 __getitem__ :\u30a4\u30f3\u30c7\u30af\u30b7\u30f3\u30b0\uff08\u914d\u5217\u306e\u3088\u3046\u306b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u30a2\u30af\u30bb\u30b9\u3059\u308b\uff09\u3002\u30b7\u30fc\u30b1\u30f3\u30b9\u578b\uff08list, tuple, str, range\uff09 __iter__ :iterator\u3092\u8fd4\u3059\u7279\u6b8a\u30e1\u30bd\u30c3\u30c9 __next__ :\u8981\u7d20\u3092\u53cd\u5fa9\u3057\u3066\u53d6\u308a\u51fa\u3059\u3053\u3068\u306e\u3067\u304d\u308b\u7279\u6b8a\u30e1\u30bd\u30c3\u30c9\u3067\u3059\u3002 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class FooIterator (): def __init__ ( self , foo ): # foo\u306fiterable\u306a\u30aa\u30d6\u30b8\u30a7\u30af\u30c8 self . _i = 0 self . _foo = foo def __iter__ ( self ): return self def __next__ ( self ): try : v = self . _foo . _L [ self . _i ] self . _i += 1 return v except IndexError : raise StopIteration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Odd : def __init__ ( self ): self . i = 1 def __contains__ ( self , x ): return x % 2 == 1 def __str__ ( self ): return \"odd numbers\" def __iter__ ( self ): return self def __next__ ( self ): result = self . i self . i += 2 return result def __getitem__ ( self , i ): return 2 * i + 1 def __len__ ( self ): return 0 __contains__ \uff1a\u30b3\u30f3\u30c6\u30ca\u578b\u3092\u5b9a\u7fa9\u3002\u72ec\u81ea\u30af\u30e9\u30b9\u306bin\u3092\u5b9a\u7fa9\u3067\u304d\u308b\u3002\uff08list, dict, tuple, str, collections.defaultdict\uff09 __str__ \uff1aprint\u95a2\u6570\u306e\u969b\u306b\u547c\u3070\u308c\u308b\u3002 __repr__ \uff1a\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u518d\u751f\u6210\u3059\u308b\u305f\u3081\u306b\u4f7f\u3048\u308b\u3088\u3046\u306a\u3088\u308a\u6b63\u78ba\u306a\u60c5\u5831\u3092\u8fd4\u3059 __name__ :\u30e2\u30b8\u30e5\u30fc\u30eb\u5185\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u306b\u304a\u3044\u3066\u306f\u30e2\u30b8\u30e5\u30fc\u30eb\u540d\u3002\u95a2\u6570\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u304a\u3044\u3066\u306f\u95a2\u6570\u540d\u306b\u306a\u308b\u3002 __doc__ : __buidins__ :\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u3002 set or get members getitem (), setitem () and iterate over items iter () and to get the number of items - method len () The behaviour of sorted() built-in function is to iterate over elements of your container and compare them using methods you mentioned cmp (), ge (), le () This is because reversing a collection doesn't care about values of items but sorting it depends on these values. \u2013 ElmoVanKielmo Feb 19 '18 at 15:12 it seems to me the only important difference is that reversed() looks for a reversed () method in the container its reversing whereas sorted() doesn't look for a sorted () method. \u2013 gregrf Feb 19 '18 at 15:17 This is the technical difference https://stackoverflow.com/questions/48868228/is-there-a-magic-method-for-sorted-in-python generetor \u5f0f \u00b6 \u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u53d6\u308a\u306a\u3069\u90e8\u5206\u7684\u306b\u30e1\u30e2\u30ea\u306b\u8f09\u305b\u3066\u3044\u304f\u5834\u5408\u306b\u4f7f\u3046\u3002 generator\u306f\u30e9\u30f3\u30c0\u30e0\u30a2\u30af\u30bb\u30b9\u3067\u304d\u306a\u3044 ex. range(10) https://www.atmarkit.co.jp/ait/articles/1908/20/news024.html https://qiita.com/knknkn1162/items/17f7f370a2cc27f812ee 1 2 3 4 5 6 7 8 # generator expression ( x * x for x in numbers ) # generator function # \u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066yield\u3092\u8fd4\u3059\u3002 # next\u3067\u5024\u3092\u53d6\u5f97\u3067\u304d\u308b\u3002 def gen_func (): for x in numbers : yield x * x \u30a8\u30e9\u30fc \u00b6 https://note.nkmk.me/python-error-message/ https://note.nkmk.me/python-try-except-else-finally/ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 try : print ( a / b ) #\u4f8b\u5916\u3092\u610f\u56f3\u7684\u306b\u767a\u751f\u3055\u305b\u308b raise ZeroDivisionError except ZeroDivisionError as e : print ( 'catch ZeroDivisionError:' , e ) except ValueError as e : print ( '\u6570\u5b57\u4ee5\u5916\u304c\u5165\u529b\u3055\u308c\u307e\u3057\u305f\u3002\u6570\u5b57\u306e\u307f\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044' ) print ( 'catch ValueError:' , e ) else : \u4f8b\u5916\u304c\u8d77\u304d\u305f\u3068\u304d\u306f\u5b9f\u884c\u3057\u306a\u3044\u30b3\u30fc\u30c9 finally : \u5e38\u306b\u5b9f\u884c\u3059\u308b\u30b3\u30fc\u30c9 finally \u306f\u30ad\u30e3\u30c3\u30c1\u3055\u308c\u306a\u304f\u3066\u3082\u30a8\u30e9\u30fc\u306e\u524d\u306b\u5b9f\u884c\u3055\u308c\u308b raise \u306f\u30a8\u30e9\u30fc\u3092\u767a\u751f\u3055\u305b\u308b\u3002 \u4f8b\u5916\u306e\u81ea\u4f5c Exception \u30af\u30e9\u30b9\u3092\u7d99\u627f\u3059\u308b traceback.print_exc() tracebackmodudle \u30c6\u30b9\u30c8 \u00b6 unittest \u00b6 assert\u30b3\u30fc\u30c9\u3067\u30c6\u30b9\u30c8\u3057\u3066\u3044\u304f\u3002 \u30c6\u30b9\u30c8\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u66f8\u304f\u3002 Test runnner: unittest, self.assertEqual(power(base, exp), 8) python -m unittest test.py\u3092\u4f7f\u3046 \u4f8b\u5916\u30b1\u30fc\u30b9\u306fwith \u30b9\u30c6\u30fc\u30c8\u30e1\u30f3\u30c8\u3092\u4f7f\u3063\u3066\u66f8\u304f\u3002 with self.assertRaise(Typeerror) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #https://qiita.com/phorizon20/items/acb929772aaae4f52101 def fizzbuzz ( number ): if number % 15 == 0 : return \"FizzBuzz\" if number % 5 == 0 : return \"Buzz\" if number % 3 == 0 : return \"Fizz\" return number import unittest import fizzbuzz as fb class FizzBuzzTest ( unittest . TestCase ): def setUp ( self ): # \u521d\u671f\u5316\u51e6\u7406 pass def tearDown ( self ): # \u7d42\u4e86\u51e6\u7406 pass def test_normal ( self ): self . assertEqual ( 1 , fb . fizzbuzz ( 1 )) def test_fizz ( self ): self . assertEqual ( \"Fizz\" , fb . fizzbuzz ( 3 )) def test_buzz ( self ): self . assertEqual ( \"Buzz\" , fb . fizzbuzz ( 5 )) def test_fizzbuzz ( self ): self . assertEqual ( \"FizzBuzz\" , fb . fizzbuzz ( 15 )) pytest \u00b6 pytest assert\u3067\u7c21\u6f54\u306b\u66f8\u3051\u308b\u3002 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #https://kazuhira-r.hatenablog.com/entry/2020/03/14/173536 class Calc : def add ( self , x , y ): return x + y def minus ( self , x , y ): return x - y def multiply ( self , x , y ): return x * y def divide ( self , x , y ): return x / y from sample.calc import Calc def test_add (): calc = Calc () assert calc . add ( 1 , 3 ) == 4 def test_minus (): calc = Calc () assert calc . minus ( 5 , 3 ) == 2 def test_multiply (): calc = Calc () assert calc . multiply ( 2 , 3 ) == 6 def test_divide (): calc = Calc () assert calc . divide ( 10 , 2 ) == 5 \u30c6\u30b9\u30c8\u30ab\u30d0\u30ec\u30c3\u30b8 pytest-cov:\u30ab\u30d0\u30fc\u7387\u3092\u30c1\u30a7\u30c3\u30af\u3059\u308b\u3002 html\u3084xml\u3067\u51fa\u529b\u3067\u304d\u308b\u3002--cov-append \u30ea\u30f3\u30af \u00b6 https://qiita.com/ganyariya/items/fb3f38c2f4a35d1ee2e8 https://qiita.com/knknkn1162/items/17f7f370a2cc27f812ee http://diveintopython3-ja.rdy.jp/special-method-names.html utils \u00b6 \u30d5\u30a1\u30a4\u30eb\u53d6\u5f97 \u00b6 1 2 import glob glob . glob ( '/folder/* /*.dcm' ) \u8f9e\u66f8\u306a\u3069\u306e\u4fdd\u5b58 \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 import pickle with open ( \"data.pkl\" , \"wb\" ) as pkl_handle : pickle . dump ( dictionary_data , pkl_handle ) # LOAD with open ( \"data.pkl\" , \"rb\" ) as pkl_handle : output = pickle . load ( pkl_handle ) import mpu your_data = { 'foo' : 'bar' } mpu . io . write ( 'filename.pickle' , data ) unserialized_data = mpu . io . read ( 'filename.pickle' ) # https://stackoverflow.com/questions/11218477/how-can-i-use-pickle-to-save-a-dict CSV : Super simple format (read & write) JSON : Nice for writing human-readable data; VERY commonly used (read & write) YAML : YAML is a superset of JSON, but easier to read (read & write, comparison of JSON and YAML) pickle : A Python serialization format (read & write) MessagePack (Python package): More compact representation (read & write) HDF5 (Python package): Nice for matrices (read & write) XML : exists too sigh (read & write) dicom\u30d5\u30a1\u30a4\u30eb \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def dicom2array ( path , voi_lut = True , fix_monochrome = True ): # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way dicom = pydicom . read_file ( path ) # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to # \"human-friendly\" view if voi_lut : data = apply_voi_lut ( dicom . pixel_array , dicom ) else : data = dicom . pixel_array # depending on this value, X-ray may look inverted - fix that: if fix_monochrome and dicom . PhotometricInterpretation == \"MONOCHROME1\" : data = np . amax ( data ) - data data = data - np . min ( data ) data = data / np . max ( data ) data = ( data * 255 ) . astype ( np . uint8 ) return data def resize ( array , size , keep_ratio = False , resample = Image . LANCZOS ): # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image im = Image . fromarray ( array ) if keep_ratio : im . thumbnail (( size , size ), resample ) else : im = im . resize (( size , size ), resample ) return im def resize_and_save ( file_path ): split = 'train' if 'train' in file_path else 'test' base_dir = f '/kaggle/working/ { split } ' img = dicom2array ( file_path ) h , w = img . shape [: 2 ] # orig hw if aspect_ratio : r = dim / max ( h , w ) # resize image to img_size interp = cv2 . INTER_AREA if r < 1 else cv2 . INTER_LINEAR if r != 1 : # always resize down, only resize up if training with augmentation img = cv2 . resize ( img , ( int ( w * r ), int ( h * r )), interpolation = interp ) else : img = cv2 . resize ( img , ( dim , dim ), cv2 . INTER_AREA ) filename = file_path . split ( '/' )[ - 1 ] . split ( '.' )[ 0 ] cv2 . imwrite ( os . path . join ( base_dir , f ' { filename } .jpg' ), img ) return filename . replace ( 'dcm' , '' ) + '_image' , w , h","title":"Basics"},{"location":"python_basis/#python-basis","text":"","title":"Python basis"},{"location":"python_basis/#_1","text":"Python\u306f\u3059\u3079\u3066\u304c\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3002int, str, \u95a2\u6570 Python\u306f\u52d5\u7684\u578b\u4ed8\u3051\u8a00\u8a9e\u3001\u578b\u3088\u308a\u3082\u632f\u308b\u821e\u3044\u306b\u8208\u5473\u304c\u3042\u308b\u3002 \u4fbf\u5229\u306a\u30d3\u30eb\u30c9\u30a4\u30f3\u95a2\u6570 id():\u5909\u6570\u306e\u5834\u6240\u306eid\u3092\u8fd4\u3059 dir:attribute\u3092\u8fd4\u3059 is\u6f14\u7b97\u5b50\uff1a\u540c\u3058\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u304b\u3069\u3046\u304b\u3092\u5224\u65ad\u3059\u308b isinstance:\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u30bf\u30a4\u30d7\u3092\u78ba\u8a8d copy\u3068deepcopy \u578b\u5909\u63db\uff08casting\uff09 \u30a4\u30df\u30e5\u30fc\u30bf\u30d6\u30eb\u3068\u30df\u30e5\u30fc\u30bf\u30d6\u30eb\uff1a\u95a2\u6570\u306e\u4e2d\u3067\u65b0\u3057\u3044\uff08\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\uff09ID\u304c\u4f5c\u3089\u308c\u308b\u3002for\u6587\u3067\u306f\u8db3\u3057\u3066\u3044\u304f\u3068\u304d\u306f\u30ea\u30b9\u30c8\u3092\u4f7f\u3046\u307b\u3046\u304c\u826f\u3044\u3002\uff09 _\u306f\u76f4\u524d\u306e\u5b9f\u884c\u3057\u305f\u623b\u308a\u5024\u3092\u683c\u7d0d\u3059\u308b\u3002 \u30d6\u30fc\u30ea\u30a2\u30f3\u306b\u6bd4\u8f03\u6f14\u7b97\u5b50\u3092\u4f7f\u308f\u306a\u3044\u3002 tuple\u306f\u300c\u4e38\u62ec\u5f27\u3067\u4f5c\u6210\u3055\u308c\u308b\u306e\u3067\u306f\u306a\u304f\u3001\u30ab\u30f3\u30de\u306b\u3088\u3063\u3066\u4f5c\u6210\u3055\u308c\u300d\u307e\u3059 \u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u66f8\u304d\u306b\u306f with open \u3092\u4f7f\u3046\u3002 namedtuple getattr:\u3092\u4f7f\u3046\u3002 https://qiita.com/ganyariya/items/3b8861788ec30238a8a9 \u4e09\u9023\u30af\u30aa\u30fc\u30c8\u306b\u3088\u308b\u8907\u6570\u884c\u6587\u5b57\u5217 shutil\u30e2\u30b8\u30e5\u30fc\u30eb 1 2 method = getattr ( animal , 'walk' , None ) if callable ( method )","title":"\u57fa\u790e"},{"location":"python_basis/#vscode","text":"vscode\u3067\u81ea\u52d5\u3067\u5909\u6570\u3092\u5236\u5fa1\u3002\u66f8\u304d\u63db\u3048 vscode\u3067linter\u3068formatter\u3092\u8a2d\u5b9a black: https://github.com/psf/black flake8: https://github.com/PyCQA/flake8 isort: https://github.com/PyCQA/isort mypy \u30b3\u30e1\u30f3\u30c8\u3067# TODO","title":"vscode"},{"location":"python_basis/#_2","text":"1 2 3 4 5 6 7 pip freeze pip freeze > requirements.txt pip install -r requirements.txt #or pipenv --python 3 pipenv install -r ./requirements.txt #\u81ea\u52d5\u3067pipfile\u304c\u4f5c\u6210 pipenv lock )","title":"\u74b0\u5883\u69cb\u7bc9"},{"location":"python_basis/#gitinstall","text":"1 !pip install git+https://github.com/yseeker/tez_custom","title":"git\u304b\u3089install"},{"location":"python_basis/#_3","text":"","title":"\u30b3\u30fc\u30c7\u30a3\u30f3\u30b0\u30b9\u30bf\u30a4\u30eb"},{"location":"python_basis/#pep8","text":"=\u3068\u30aa\u30da\u30ec\u30fc\u30bf\u30fc\u306e\u5468\u308a\u306b\u30b9\u30da\u30fc\u30b9 \u95a2\u6570\u306e\u5f15\u6570\u306e\u5468\u308a\u306b\u30b9\u30da\u30fc\u30b9\u306f\u4e0d\u8981 \u30d7\u30e9\u30a4\u30aa\u30ea\u30c6\u30a3\u304c\u3042\u308b\u5834\u5408\u306f\u30b9\u30da\u30fc\u30b9\u3092\u7121\u304f\u3059 \u30ab\u30f3\u30de\u306e\u3042\u3068\u306b\u30b9\u30da\u30fc\u30b9\u3092\u5165\u308c\u308b\u3002 \u6700\u5f8c\u306e\u8981\u7d20\u306b\u30ab\u30f3\u30de\u3082\u3064\u3051\u308b\uff08\u62ec\u5f27\u9589\u3058\u3092\u6b21\u306e\u884c\u306b\u3059\u308b\u3002\uff09 \u95a2\u6570\u306e\u5f15\u6570\u306e\u982d\u3092\u63c3\u3048\u3066\u6539\u884c\u3059\u308b\u3002 \u95a2\u6570\u9593\u306f\u4e8c\u884c\u3042\u3051\u308b\u3002 \u30af\u30e9\u30b9\u306e\u30e1\u30bd\u30c3\u30c9\u9593\u306f1\u884c import \u306e\u9806\u756a standrd library third party our library local library","title":"pep8"},{"location":"python_basis/#_4","text":"pyenv + pipenv\u3092\u4f7f\u3046\u3002","title":"\u74b0\u5883"},{"location":"python_basis/#_5","text":"Python\u3067\u306f \u5168\u3066\u53c2\u7167\u6e21\u3057 \u3002 constant variable \u5927\u6587\u5b57\u3067\u66f8\u304f \u30e2\u30b8\u30e5\u30fc\u30eb \uff08\u30d5\u30a1\u30a4\u30eb\u5358\u4f4d\u3067\u5206\u3051\u3066\u30d7\u30ed\u30b0\u30e9\u30e0\u3092\u8a18\u8f09\u3057\u305f\u3082\u306e\uff09\uff1c \u30d1\u30c3\u30b1\u30fc\u30b8 \uff08\u8907\u6570\u306e\u30d5\u30a1\u30a4\u30eb\u3001\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u69cb\u9020\u304b\u3089\u306a\u308a\u3001\u30eb\u30fc\u30eb\u306b\u5f93\u3063\u3066\u305d\u308c\u3089\u3092\u3072\u3068\u56fa\u307e\u308a\u306b\u3057\u305f\u3082\u306e\uff09\uff1c \u30e9\u30a4\u30d6\u30e9\u30ea \u3002 \u30d1\u30c3\u30b1\u30fc\u30b8\u306b\u306f\u3001\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3067\u968e\u5c64\u5316\u3055\u305b\u305f\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u8aad\u307f\u8fbc\u307e\u305b\u308b\u305f\u3081\u306b init .py \u304c\u5fc5\u8981\uff08\u3053\u306e\u3068\u304d\u76f8\u5bfeimport\u3082\u884c\u3046\uff09 \u5f15\u6570\uff08arguments\uff09 \uff1a\u5b9f\u5f15\u6570\u3002\u95a2\u6570\u306b\u6e21\u3055\u308c\u308b\u5177\u4f53\u7684\u306a\u5024 \u30d1\u30e9\u30e1\u30fc\u30bf\uff08parameters\uff09 \uff1a\u4eee\u5f15\u6570\u3002\u95a2\u6570\u306b\u6e21\u3055\u308c\u308b\u5177\u4f53\u7684\u306a\u5024\u306e\u30d7\u30ec\u30fc\u30b9\u30db\u30eb\u30c0\u3002 https://qiita.com/raviqqe/items/ee2bcb6bef86502f8cc6#%E5%BC%95%E6%95%B0%E3%81%AF-2-x-2--4-%E7%A8%AE%E9%A1%9E positional paremeters \uff1a\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u5024\uff08arguments\uff09\u306a\u3057\u3002 keyword parameters \uff1a\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u5024\u3042\u308a\u3002 \u53ef\u5909\u9577\u5f15\u6570 : args, *kwargs, \u69d8\u3005\u306a\u9577\u3055\u306e\u5f15\u6570\u3092\u53d7\u3051\u53d6\u308c\u308b\u3002 global \u3068 nonlocal \uff08nested\u95a2\u6570\u306e\u3068\u304d\u306b\u5b9a\u7fa9\uff09 \u30e9\u30e0\u30c0\u95a2\u6570 \uff08\u95a2\u6570\u540d\u304c\u7121\u3044\u95a2\u6570\uff09:\u95a2\u6570\u540d\u3068\"return\"\u3092\u7121\u304f\u3059\u3002filter \u95a2\u6570\u306e\u969b\u306b\u4f7f\u3046\u3002 1 lm_add = lambda x , y : x + y \u95a2\u6570\u3082\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3001\u95a2\u6570\u3092\u5f15\u6570\u3067\u3068\u308c\u308b\u3001\u95a2\u6570\u3082return\u3067\u304d\u308b\uff08\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3068\u3057\u3066\u8fd4\u3059\u3002\uff09Closure:\u72b6\u614b\u3092\u30ad\u30fc\u30d7\u3057\u305f\u95a2\u6570\u3002\uff08\u72b6\u614b\u3092\u52d5\u7684\u30fb\u9759\u7684\uff09 sys.path :\u306b\u5165\u308c\u308b\u3068\u30ab\u30b9\u30bf\u30e0\u3067\u30e2\u30b8\u30e5\u30fc\u30eb\u3092\u4f7f\u3048\u308b\u3002pip\u3092\u4f7f\u3046\u3068site-packages\u306e\u4e2d\u3067\u7ba1\u7406\u3055\u308c\u308b\u3002","title":"\u95a2\u6570"},{"location":"python_basis/#_6","text":"re.search('[0-9]', string) re.search('^[0-9]', string):\u6700\u521d\u306e\u6587\u5b57 re.search('^[0-9]{4}', string):\u6700\u521d\u306e\u6587\u5b57 \u30ea\u30d4\u30fc\u30c8 re.search('^[0-9]{2-4}', string):\u6700\u521d\u306e\u6587\u5b572-4\u6587\u5b57 \u30ea\u30d4\u30fc\u30c8 re.search('^[0-9]{2-4}$', string):\u6700\u5f8c\u306e\u6587\u5b572-4\u6587\u5b57 \u30ea\u30d4\u30fc\u30c8 re.search('a*b', 'aaaab')\u5de6\u306e\u30d1\u30bf\u30fc\u30f3\u30920\u56de\u4ee5\u4e0a\u7e70\u308a\u8fd4\u3059 re.search('a+b', 'aaaab')\u5de6\u306e\u30d1\u30bf\u30fc\u30f3\u30921\u56de\u4ee5\u4e0a\u7e70\u308a\u8fd4\u3059 re.search('ab?c', 'aaaab')\u5de6\u306e\u30d1\u30bf\u30fc\u30f3\u30920\u56de\u304b1\u56de\u7e70\u308a\u8fd4\u3059 abc|012 or te(s|x)t \u30b0\u30eb\u30fc\u30d7 'h.t'\u4efb\u610f\u306e\u4e00\u6587\u5b57 \u30a8\u30b9\u30b1\u30fc\u30d7'h.t' \\w [a-zA-Z0-9_]\u306b\u30de\u30c3\u30c1","title":"\u6b63\u898f\u8868\u73fe"},{"location":"python_basis/#_7","text":"\u5c5e\u6027\uff08\u30e1\u30f3\u30d0\u5909\u6570\u3001\u30e1\u30f3\u30d0\u95a2\u6570\uff09, \u30e1\u30bd\u30c3\u30c9\uff08instancemethod, static method, class method\uff09, \u30d7\u30ed\u30d1\u30c6\u30a3 * \u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u5909\u6570\u3068\u30af\u30e9\u30b9\u5909\u6570 https://docs.python.org/ja/3/library/functions.html https://qiita.com/ichi_taro3/items/cd71a8e43040abb446a1 \u6163\u7fd2\u7684\u306a\u547d\u540d\u898f\u5247\u3068\u3057\u3066\u306e\u30d7\u30e9\u30a4\u30d9\u30fc\u30c8(non public)\u5316\uff08\u30a2\u30f3\u30c0\u30fc\u30d0\u30fc\uff09\u3002\u6226\u95d8\u306b\u30a2\u30f3\u30c0\u30fc\u30d0\u30fc\u3092\u3064\u3051\u3066_\u540d\u524d\u3068\u3059\u308b \u30cd\u30fc\u30e0\u30de\u30f3\u30b0\u30ea\u30f3\u30b0\uff08\u96e3\u53f7\u5316\uff09\u8981\u7d20\u540d\u306e\u524d\u306b\"__\"\uff08\u30a2\u30f3\u30c0\u30fc\u30d0\u30fc2\u3064\uff09\u3092\u3064\u3051\u307e\u3059\u3002 \u7d99\u627f\u6642\u306e\u540d\u524d\u4fee\u98fe\u306f__\u3092\u4f7f\u3044\u3053\u306a\u3059\u3002 \u30dd\u30ea\u30e2\u30fc\u30d5\u30a3\u30ba\u30e0\u306f\u7d99\u627f\u3092\u3057\u3066\u3044\u308bint\u3082str\u3082print\u3092\u3059\u308b\u3068\u540c\u3058\u3088\u3046\u306b\u632f\u308b\u821e\u3046 \u30aa\u30fc\u30d0\u30fc\u30e9\u30a4\u30c9\uff1a\u30b5\u30d6\u30af\u30e9\u30b9\u306e\u3067\u540c\u3058\u540d\u524d\u306e\u95a2\u6570\u3092\u5b9a\u7fa9\u3059\u308b\u3002 .\u3068\u304b..\u3067\u76f8\u5bfe\u30a4\u30f3\u30dd\u30fc\u30c8\u3067\u304d\u308b\u3002","title":"\u30af\u30e9\u30b9"},{"location":"python_basis/#_8","text":"https://qiita.com/koshigoe/items/848ddc0272b3cee92134 @staticmethod \uff1a\u307b\u3068\u3093\u3069\u30af\u30e9\u30b9\u5916\u306e\u95a2\u6570\u3068\u3057\u3066\u6271\u3046\u3002\uff08self\u306f\u3044\u3089\u306a\u3044\uff09 @classmethod \uff1acls\u306b\u5f15\u6570\u3092\u3068\u3063\u3066\u3001class\u306e\u60c5\u5831\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u3002\u7d99\u627f\u3059\u308b\u3068\u304d\u306fstaticmethod\u3067\u306f\u547c\u3076\u3068\u304d\u306b\u554f\u984c\u304c\u767a\u751f\u3059\u308b\u3002classmethod\u3092\u4f7f\u3046\u3002 @property \uff1a\u5909\u6570\u3092\u30ab\u30d7\u30bb\u30eb\u5316\u3057\u3001\u5909\u6570\u3060\u3051\u5916\u306b\u8fd4\u305b\u308b\u3088\u3046\u306b\u3059\u308b\u3002setter\u3068\u30bb\u30c3\u30c8\u3067\u4f7f\u3046\u3002\u5916\u304b\u3089\u5185\u90e8\u306e\u5024\u3092\u30bb\u30c3\u30c8\u3067\u304d\u308b\u3002 1 2 3 4 5 6 7 8 9 10 11 class Example : def __init__ ( self , x , y ): self . _x = x self . _y = y @property def x ( self ): return self . _x @x . setter def x ( self , dx ): self . _x += dx self . _x = max ( 0 , min ( self . MAX_X , self . _x )) @dataclass \uff1a\u30c7\u30fc\u30bf\u3092\u683c\u7d0d\u3059\u308b\u30af\u30e9\u30b9\u3092\u7c21\u5358\u306b\u4f5c\u6210\u3059\u308b\u30c7\u30b3\u30ec\u30fc\u30bf\u306a\u3069\u3092\u63d0\u4f9b 1 2 3 4 5 6 7 8 @dataclass class InventoryItem : name : str price : float quantity : int = 0 def total_cost ( self ) -> float : return self . price * self . quantity","title":"\u30c7\u30b3\u30ec\u30fc\u30bf"},{"location":"python_basis/#_9","text":"http://diveintopython3-ja.rdy.jp/special-method-names.html __init__ \uff1a\u30af\u30e9\u30b9\u306e\u521d\u671f\u5316\u3002\u30b3\u30f3\u30b9\u30c8\u30e9\u30af\u30bf\u3092\u547c\u3076\u3002\u89aa\u30af\u30e9\u30b9\u306e\u30b3\u30f3\u30b9\u30bf\u30af\u30bf\u3092\u547c\u3076\u3068\u304d\u306f\u3001super. init ()\u3068\u3059\u308b\u3002 __del__ \uff1a\u30c7\u30b9\u30c8\u30e9\u30af\u30bf\u3002\u57fa\u672c\u7684\u306b\u306f\u4f7f\u308f\u306a\u3044\u3002\u4ee3\u308f\u308a\u306bwith\u69cb\u6587\u3092\u4f7f\u3046\u3002 __call__ \uff1a\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u3092\u95a2\u6570\u306e\u3088\u3046\u306b\u6271\u3048\u308b\u3002 __len__ \uff1a len\u30e1\u30bd\u30c3\u30c9\u306b\u5bfe\u3059\u308bint\u578b\u306e\u5024\u3092\u8fd4\u3059 __getitem__ :\u30a4\u30f3\u30c7\u30af\u30b7\u30f3\u30b0\uff08\u914d\u5217\u306e\u3088\u3046\u306b\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u30a2\u30af\u30bb\u30b9\u3059\u308b\uff09\u3002\u30b7\u30fc\u30b1\u30f3\u30b9\u578b\uff08list, tuple, str, range\uff09 __iter__ :iterator\u3092\u8fd4\u3059\u7279\u6b8a\u30e1\u30bd\u30c3\u30c9 __next__ :\u8981\u7d20\u3092\u53cd\u5fa9\u3057\u3066\u53d6\u308a\u51fa\u3059\u3053\u3068\u306e\u3067\u304d\u308b\u7279\u6b8a\u30e1\u30bd\u30c3\u30c9\u3067\u3059\u3002 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class FooIterator (): def __init__ ( self , foo ): # foo\u306fiterable\u306a\u30aa\u30d6\u30b8\u30a7\u30af\u30c8 self . _i = 0 self . _foo = foo def __iter__ ( self ): return self def __next__ ( self ): try : v = self . _foo . _L [ self . _i ] self . _i += 1 return v except IndexError : raise StopIteration 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Odd : def __init__ ( self ): self . i = 1 def __contains__ ( self , x ): return x % 2 == 1 def __str__ ( self ): return \"odd numbers\" def __iter__ ( self ): return self def __next__ ( self ): result = self . i self . i += 2 return result def __getitem__ ( self , i ): return 2 * i + 1 def __len__ ( self ): return 0 __contains__ \uff1a\u30b3\u30f3\u30c6\u30ca\u578b\u3092\u5b9a\u7fa9\u3002\u72ec\u81ea\u30af\u30e9\u30b9\u306bin\u3092\u5b9a\u7fa9\u3067\u304d\u308b\u3002\uff08list, dict, tuple, str, collections.defaultdict\uff09 __str__ \uff1aprint\u95a2\u6570\u306e\u969b\u306b\u547c\u3070\u308c\u308b\u3002 __repr__ \uff1a\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u518d\u751f\u6210\u3059\u308b\u305f\u3081\u306b\u4f7f\u3048\u308b\u3088\u3046\u306a\u3088\u308a\u6b63\u78ba\u306a\u60c5\u5831\u3092\u8fd4\u3059 __name__ :\u30e2\u30b8\u30e5\u30fc\u30eb\u5185\u306e\u30b9\u30af\u30ea\u30d7\u30c8\u306b\u304a\u3044\u3066\u306f\u30e2\u30b8\u30e5\u30fc\u30eb\u540d\u3002\u95a2\u6570\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u306b\u304a\u3044\u3066\u306f\u95a2\u6570\u540d\u306b\u306a\u308b\u3002 __doc__ : __buidins__ :\u306b\u30a2\u30af\u30bb\u30b9\u3067\u304d\u308b\u3002 set or get members getitem (), setitem () and iterate over items iter () and to get the number of items - method len () The behaviour of sorted() built-in function is to iterate over elements of your container and compare them using methods you mentioned cmp (), ge (), le () This is because reversing a collection doesn't care about values of items but sorting it depends on these values. \u2013 ElmoVanKielmo Feb 19 '18 at 15:12 it seems to me the only important difference is that reversed() looks for a reversed () method in the container its reversing whereas sorted() doesn't look for a sorted () method. \u2013 gregrf Feb 19 '18 at 15:17 This is the technical difference https://stackoverflow.com/questions/48868228/is-there-a-magic-method-for-sorted-in-python","title":"\u30de\u30b8\u30c3\u30af\u30e1\u30bd\u30c3\u30c9\uff08\u7279\u6b8a\u30e1\u30bd\u30c3\u30c9\uff09"},{"location":"python_basis/#generetor","text":"\u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u53d6\u308a\u306a\u3069\u90e8\u5206\u7684\u306b\u30e1\u30e2\u30ea\u306b\u8f09\u305b\u3066\u3044\u304f\u5834\u5408\u306b\u4f7f\u3046\u3002 generator\u306f\u30e9\u30f3\u30c0\u30e0\u30a2\u30af\u30bb\u30b9\u3067\u304d\u306a\u3044 ex. range(10) https://www.atmarkit.co.jp/ait/articles/1908/20/news024.html https://qiita.com/knknkn1162/items/17f7f370a2cc27f812ee 1 2 3 4 5 6 7 8 # generator expression ( x * x for x in numbers ) # generator function # \u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u306b\u3088\u3063\u3066yield\u3092\u8fd4\u3059\u3002 # next\u3067\u5024\u3092\u53d6\u5f97\u3067\u304d\u308b\u3002 def gen_func (): for x in numbers : yield x * x","title":"generetor \u5f0f"},{"location":"python_basis/#_10","text":"https://note.nkmk.me/python-error-message/ https://note.nkmk.me/python-try-except-else-finally/ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 try : print ( a / b ) #\u4f8b\u5916\u3092\u610f\u56f3\u7684\u306b\u767a\u751f\u3055\u305b\u308b raise ZeroDivisionError except ZeroDivisionError as e : print ( 'catch ZeroDivisionError:' , e ) except ValueError as e : print ( '\u6570\u5b57\u4ee5\u5916\u304c\u5165\u529b\u3055\u308c\u307e\u3057\u305f\u3002\u6570\u5b57\u306e\u307f\u3092\u5165\u529b\u3057\u3066\u304f\u3060\u3055\u3044' ) print ( 'catch ValueError:' , e ) else : \u4f8b\u5916\u304c\u8d77\u304d\u305f\u3068\u304d\u306f\u5b9f\u884c\u3057\u306a\u3044\u30b3\u30fc\u30c9 finally : \u5e38\u306b\u5b9f\u884c\u3059\u308b\u30b3\u30fc\u30c9 finally \u306f\u30ad\u30e3\u30c3\u30c1\u3055\u308c\u306a\u304f\u3066\u3082\u30a8\u30e9\u30fc\u306e\u524d\u306b\u5b9f\u884c\u3055\u308c\u308b raise \u306f\u30a8\u30e9\u30fc\u3092\u767a\u751f\u3055\u305b\u308b\u3002 \u4f8b\u5916\u306e\u81ea\u4f5c Exception \u30af\u30e9\u30b9\u3092\u7d99\u627f\u3059\u308b traceback.print_exc() tracebackmodudle","title":"\u30a8\u30e9\u30fc"},{"location":"python_basis/#_11","text":"","title":"\u30c6\u30b9\u30c8"},{"location":"python_basis/#unittest","text":"assert\u30b3\u30fc\u30c9\u3067\u30c6\u30b9\u30c8\u3057\u3066\u3044\u304f\u3002 \u30c6\u30b9\u30c8\u30b9\u30af\u30ea\u30d7\u30c8\u3092\u66f8\u304f\u3002 Test runnner: unittest, self.assertEqual(power(base, exp), 8) python -m unittest test.py\u3092\u4f7f\u3046 \u4f8b\u5916\u30b1\u30fc\u30b9\u306fwith \u30b9\u30c6\u30fc\u30c8\u30e1\u30f3\u30c8\u3092\u4f7f\u3063\u3066\u66f8\u304f\u3002 with self.assertRaise(Typeerror) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #https://qiita.com/phorizon20/items/acb929772aaae4f52101 def fizzbuzz ( number ): if number % 15 == 0 : return \"FizzBuzz\" if number % 5 == 0 : return \"Buzz\" if number % 3 == 0 : return \"Fizz\" return number import unittest import fizzbuzz as fb class FizzBuzzTest ( unittest . TestCase ): def setUp ( self ): # \u521d\u671f\u5316\u51e6\u7406 pass def tearDown ( self ): # \u7d42\u4e86\u51e6\u7406 pass def test_normal ( self ): self . assertEqual ( 1 , fb . fizzbuzz ( 1 )) def test_fizz ( self ): self . assertEqual ( \"Fizz\" , fb . fizzbuzz ( 3 )) def test_buzz ( self ): self . assertEqual ( \"Buzz\" , fb . fizzbuzz ( 5 )) def test_fizzbuzz ( self ): self . assertEqual ( \"FizzBuzz\" , fb . fizzbuzz ( 15 ))","title":"unittest"},{"location":"python_basis/#pytest","text":"pytest assert\u3067\u7c21\u6f54\u306b\u66f8\u3051\u308b\u3002 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 #https://kazuhira-r.hatenablog.com/entry/2020/03/14/173536 class Calc : def add ( self , x , y ): return x + y def minus ( self , x , y ): return x - y def multiply ( self , x , y ): return x * y def divide ( self , x , y ): return x / y from sample.calc import Calc def test_add (): calc = Calc () assert calc . add ( 1 , 3 ) == 4 def test_minus (): calc = Calc () assert calc . minus ( 5 , 3 ) == 2 def test_multiply (): calc = Calc () assert calc . multiply ( 2 , 3 ) == 6 def test_divide (): calc = Calc () assert calc . divide ( 10 , 2 ) == 5 \u30c6\u30b9\u30c8\u30ab\u30d0\u30ec\u30c3\u30b8 pytest-cov:\u30ab\u30d0\u30fc\u7387\u3092\u30c1\u30a7\u30c3\u30af\u3059\u308b\u3002 html\u3084xml\u3067\u51fa\u529b\u3067\u304d\u308b\u3002--cov-append","title":"pytest"},{"location":"python_basis/#_12","text":"https://qiita.com/ganyariya/items/fb3f38c2f4a35d1ee2e8 https://qiita.com/knknkn1162/items/17f7f370a2cc27f812ee http://diveintopython3-ja.rdy.jp/special-method-names.html","title":"\u30ea\u30f3\u30af"},{"location":"python_basis/#utils","text":"","title":"utils"},{"location":"python_basis/#_13","text":"1 2 import glob glob . glob ( '/folder/* /*.dcm' )","title":"\u30d5\u30a1\u30a4\u30eb\u53d6\u5f97"},{"location":"python_basis/#_14","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 import pickle with open ( \"data.pkl\" , \"wb\" ) as pkl_handle : pickle . dump ( dictionary_data , pkl_handle ) # LOAD with open ( \"data.pkl\" , \"rb\" ) as pkl_handle : output = pickle . load ( pkl_handle ) import mpu your_data = { 'foo' : 'bar' } mpu . io . write ( 'filename.pickle' , data ) unserialized_data = mpu . io . read ( 'filename.pickle' ) # https://stackoverflow.com/questions/11218477/how-can-i-use-pickle-to-save-a-dict CSV : Super simple format (read & write) JSON : Nice for writing human-readable data; VERY commonly used (read & write) YAML : YAML is a superset of JSON, but easier to read (read & write, comparison of JSON and YAML) pickle : A Python serialization format (read & write) MessagePack (Python package): More compact representation (read & write) HDF5 (Python package): Nice for matrices (read & write) XML : exists too sigh (read & write)","title":"\u8f9e\u66f8\u306a\u3069\u306e\u4fdd\u5b58"},{"location":"python_basis/#dicom","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def dicom2array ( path , voi_lut = True , fix_monochrome = True ): # Original from: https://www.kaggle.com/raddar/convert-dicom-to-np-array-the-correct-way dicom = pydicom . read_file ( path ) # VOI LUT (if available by DICOM device) is used to transform raw DICOM data to # \"human-friendly\" view if voi_lut : data = apply_voi_lut ( dicom . pixel_array , dicom ) else : data = dicom . pixel_array # depending on this value, X-ray may look inverted - fix that: if fix_monochrome and dicom . PhotometricInterpretation == \"MONOCHROME1\" : data = np . amax ( data ) - data data = data - np . min ( data ) data = data / np . max ( data ) data = ( data * 255 ) . astype ( np . uint8 ) return data def resize ( array , size , keep_ratio = False , resample = Image . LANCZOS ): # Original from: https://www.kaggle.com/xhlulu/vinbigdata-process-and-resize-to-image im = Image . fromarray ( array ) if keep_ratio : im . thumbnail (( size , size ), resample ) else : im = im . resize (( size , size ), resample ) return im def resize_and_save ( file_path ): split = 'train' if 'train' in file_path else 'test' base_dir = f '/kaggle/working/ { split } ' img = dicom2array ( file_path ) h , w = img . shape [: 2 ] # orig hw if aspect_ratio : r = dim / max ( h , w ) # resize image to img_size interp = cv2 . INTER_AREA if r < 1 else cv2 . INTER_LINEAR if r != 1 : # always resize down, only resize up if training with augmentation img = cv2 . resize ( img , ( int ( w * r ), int ( h * r )), interpolation = interp ) else : img = cv2 . resize ( img , ( dim , dim ), cv2 . INTER_AREA ) filename = file_path . split ( '/' )[ - 1 ] . split ( '.' )[ 0 ] cv2 . imwrite ( os . path . join ( base_dir , f ' { filename } .jpg' ), img ) return filename . replace ( 'dcm' , '' ) + '_image' , w , h","title":"dicom\u30d5\u30a1\u30a4\u30eb"},{"location":"pytorch_basis/","text":"Pytorch basis \u00b6 \u30c1\u30fc\u30c8\u30b7\u30fc\u30c8 \u00b6 https://qiita.com/dokkozo/items/e173acded17a142e6d02 Basis \u00b6 flatten() : view(-1) squeeze() : view(*[s for s int t.shape if s != 1])\u3000\u8981\u7d20\u6570\u304c1\u306e\u8ef8\u3092\u524a\u9664\u3059\u308b\u3002\u6b21\u5143\u3092\u6e1b\u3089\u3059\u3002 unsqueeze(i) view( t.shape[:i-1], 1, t.shape[i:])\u3000\u6b21\u5143\u3092\u5897\u3084\u3059 https://stackoverflow.com/questions/57234095/what-is-the-difference-between-flatten-and-view-1-in-pytorch Utils \u00b6 functions \u00b6 Sigmoid\u95a2\u6570\uff08ndarray\uff09 \u00b6 CPU\u4e0a\u3067Sigmoid\u95a2\u6570\u3092\u4f7f\u3046\u3002 1 2 3 4 5 6 def sigmoid ( gamma ): if gamma < 0 : return 1 - 1 / ( 1 + math . exp ( gamma )) return 1 / ( 1 + math . exp ( - gamma )) sigmoid_v = np . vectorize ( sigmoid ) seed\u8a2d\u5b9a \u00b6 1 2 3 4 5 6 7 8 def set_seed ( seed = 0 ): np . random . seed ( seed ) random_state = np . random . RandomState ( seed ) random . seed ( seed ) torch . manual_seed ( seed ) torch . cuda . manual_seed ( seed ) os . environ [ 'PYTHONHASHSEED' ] = str ( seed ) return random_state mixup \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def mixup_data ( inputs , targets , alpha = 1.0 ): if alpha > 0 : lam = np . random . beta ( alpha , alpha ) else : lam = 1 batch_size = inputs . size ()[ 0 ] index = torch . randperm ( batch_size ) mixed_inputs = lam * inputs + ( 1 - lam ) * inputs [ index , :] targets_a , targets_b = targets , targets [ index ] return mixed_inputs , targets_a , targets_b , lam def mixup_criterion ( criterion , outputs , targets_a , targets_b , lam ): return lam * criterion ( outputs , targets_a ) + ( 1 - lam ) * criterion ( outputs , targets_b ) classes \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class AverageMeter (): def __init__ ( self ): self . val = 0 self . avg = 0 self . sum = 0 self . count = 0 def reset ( self ): self . val = 0 self . avg = 0 self . sum = 0 self . count = 0 def update ( self , val , n = 1 ): self . val = val self . sum += val * n self . count += n self . avg = self . sum / self . count Dataset \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class Dataset (): def __init__ ( self , image_paths , targets , transform = None ): self . image_paths = image_paths self . targets = targets self . transform = None def __len__ ( self ): return len ( self . image_paths ) def __getitem__ ( self , item ): targets = self . targets [ item ] image = np . load ( self . image_paths [ item ]) image = image [ np . newaxis , ] if self . transform : image = self . transform ( image ) return torch . tensor ( image , dtype = torch . float ), torch . tensor ( targets , dtype = torch . float ) Model \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 class BasicNN ( nn . Module ): def __init__ ( self ): super () . __init__ () self . model = timm . create_model ( CFG . pretrained_model_name , pretrained = CFG . pretrained , in_chans = CFG . input_channels ) if not CFG . pretrained : self . model . load_state_dict ( torch . load ( CFG . pretrained_path )) self . model . classifier = nn . Linear ( self . model . classifier . in_features , CFG . out_dim ) def forward ( self , inputs ): outputs = self . model ( inputs ) return outputs Trainer \u00b6 \u521d\u671f\u5316 \u00b6 \u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8\u306e\u4fdd\u5b58\uff06\u8aad\u307f\u8fbc\u307f : torch.save(model.state_dict(), model_path) , model.load_state_dict(torch.load(model_path)) AMP\uff08Automatic Mixed Precision\uff1a\u6df7\u5408\u7cbe\u5ea6\uff09\u3092\u7528\u3044\u305f\u9ad8\u901f\u5316 :\u901a\u5e38\u3001FP32\uff0832\u30d3\u30c3\u30c8\u6d6e\u52d5\u5c0f\u6570\u70b9\uff09\u3067\u8a08\u7b97\u3055\u308c\u307e\u3059\u304c\u3001\u534a\u5206\u306eFP16\uff0816\u30d3\u30c3\u30c8\u6d6e\u52d5\u5c0f\u6570\u70b9\uff09\u3067\u7cbe\u5ea6\u3092\u843d\u3068\u3055\u305a\u306b\u30e1\u30e2\u30ea\u306e\u4f7f\u7528\u91cf\u3092\u7bc0\u7d04\u3057\u3001\u8a08\u7b97\u901f\u5ea6\u3082\u5411\u4e0a\u3055\u305b\u308b\u6a5f\u80fd\u3002\u8a08\u7b97\u7cbe\u5ea6\u3092\u843d\u3068\u3057\u3066\u3082\u63a8\u8ad6\u306e\u7cbe\u5ea6\u304c\u843d\u3061\u306b\u304f\u3044 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 class Trainer (): def __init__ ( self , model , train_dataset , valid_dataset = None , train_batchsize = 16 , valid_batchsize = 16 , valid_targets = None , num_workers = 4 , fp16 = True , multiple_GPU = False , determinstic = True , benchmark = False ): self . device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) self . model = model self . model . to ( self . device ) self . valid_targets = valid_targets self . criterion = nn . BCEWithLogitsLoss () self . optimizer = self . configure_optimizer () self . scheduler_after_step = self . configure_scheduler_after_step () self . scheduler_after_epoch = self . configure_scheduler_after_epoch () torch . backends . cudnn . deterministic = determinstic torch . backends . cudnn . benchmark = benchmark self . fp16 = fp16 self . scaler = torch . cuda . amp . GradScaler () self . current_epoch = 0 if num_workers == - 1 : num_workers = psutil . cpu_count () self . multiple_GPU = multiple_GPU if multiple_GPU and torch . cuda . device_count () > 1 : print ( \"Let's use\" , torch . cuda . device_count (), \"GPUs!\" ) self = nn . DataParallel ( self ) self . train_loader = torch . utils . data . DataLoader ( dataset = train_dataset , batch_size = train_batchsize , shuffle = True , num_workers = num_workers , drop_last = True , pin_memory = True ) self . valid_loader = torch . utils . data . DataLoader ( dataset = valid_dataset , batch_size = valid_batchsize , shuffle = False , num_workers = num_workers , drop_last = False , pin_memory = True ) wandb\u521d\u671f\u5316 \u00b6 1 2 3 4 5 6 7 8 9 10 11 def _init_wandb ( self , cfg ): hyperparams = { 'batch_size' : cfg . batch_size , 'epochs' : cfg . epochs } wandb . init ( config = hyperparams , project = cfg . project_name , name = cfg . wandb_exp_name , ) wandb . watch ( self . model ) optimizer, schedular, metric\u306e\u8a2d\u5b9a \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def configure_optimizer ( self ): opt = torch . optim . Adam ( self . model . parameters (), lr = CFG . lr ) return opt def configure_scheduler_after_step ( self ): sch = torch . optim . lr_scheduler . OneCycleLR ( optimizer = self . optimizer , epochs = CFG . epochs , steps_per_epoch = 3500 , max_lr = 5.0e-4 , pct_start = 0.1 , anneal_strategy = 'cos' , div_factor = 1.0e+3 , final_div_factor = 1.0e+3 ) return sch def configure_scheduler_after_epoch ( self ): return None def epoch_metrics ( self , outputs , targets ): preds = sigmoid_v ( outputs ) return metrics . roc_auc_score ( targets , preds ) def monitor_metrics ( self , outputs , targets ): preds = outputs . sigmoid () . cpu () . detach () . numpy () targets = targets . cpu () . detach () . numpy () if len ( np . unique ( targets )) > 1 : roc_auc = metrics . roc_auc_score ( targets , preds ) else : roc_auc = 0.5 return roc_auc 1step\u3054\u3068\u306e\u8a13\u7df4\u3001\u691c\u8a3c\u3001\u63a8\u8ad6 \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def train_one_step ( self , inputs , targets ): inputs = inputs . to ( self . device , non_blocking = True ) targets = targets . to ( self . device , non_blocking = True ) inputs , targets_a , targets_b , lam = mixup_data ( inputs , targets , alpha = CFG . mixup_alpha ) self . optimizer . zero_grad () with torch . set_grad_enabled ( True ): if self . fp16 : with torch . cuda . amp . autocast ( self . fp16 ): outputs = self . model ( inputs ) outputs = outputs . flatten () #loss = self.criterion(outputs.flatten(), targets) loss = mixup_criterion ( self . criterion , outputs . flatten (), targets_a , targets_b , lam ) metrics = self . monitor_metrics ( outputs , targets ) self . scaler . scale ( loss ) . backward () self . scaler . step ( self . optimizer ) self . scaler . update () else : outputs = self . model ( inputs ) outputs = outputs . flatten () metrics = self . monitor_metrics ( outputs , targets ) loss = self . criterion ( outputs . flatten (), targets ) loss . backward () self . optimizer . step () if self . scheduler_after_step : self . scheduler_after_step . step () return outputs , loss , metrics def validate_one_step ( self , inputs , targets = None ): inputs = inputs . to ( self . device , non_blocking = True ) if targets is not None : targets = targets . to ( self . device , non_blocking = True ) with torch . no_grad (): outputs = self . model ( inputs ) outputs = outputs . flatten () loss = self . criterion ( outputs . flatten (), targets ) metrics = self . monitor_metrics ( outputs , targets ) return outputs , loss , metrics else : outputs = self . model ( inputs ) outputs = outputs . flatten () return outputs , None , None def predict_one_step ( self , inputs ): outputs , _ , _ = self . validate_one_step ( inputs ) return outputs 1epoch\u3054\u3068\u306e\u8a13\u7df4\u3001\u691c\u8a3c\u3001\u63a8\u8ad6 \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def train_one_epoch ( self , data_loader ): self . model . train () running_loss , running_metrics = AverageMeter (), AverageMeter () tk0 = tqdm ( data_loader , total = len ( data_loader ), position = 0 , leave = True ) for b_idx , ( inputs , targets ) in enumerate ( tk0 ): _ , loss , metrics = self . train_one_step ( inputs , targets ) running_loss . update ( loss . item (), data_loader . batch_size ) running_metrics . update ( metrics , data_loader . batch_size ) current_lr = self . optimizer . param_groups [ 0 ][ 'lr' ] wandb . log ({ \"train/step\" : b_idx , \"train/loss_step\" : running_loss . avg , \"lr\" : current_lr }) tk0 . set_postfix ( train_loss = running_loss . avg , train_step_metrics = running_metrics . avg , stage = \"train\" , lr = current_lr ) if self . scheduler_after_epoch : self . scheduler_after_epoch . step () tk0 . close () return running_loss . avg def validate_one_epoch ( self , data_loader ): self . model . eval () running_loss , running_metrics = AverageMeter (), AverageMeter () outputs_list = [] tk0 = tqdm ( data_loader , total = len ( data_loader ), position = 0 , leave = True ) for b_idx , ( inputs , targets ) in enumerate ( tk0 ): outputs_one_batch , loss , metrics = self . validate_one_step ( inputs , targets ) outputs_list . append ( outputs_one_batch . cpu () . detach () . numpy ()) running_loss . update ( loss . item (), data_loader . batch_size ) running_metrics . update ( metrics , data_loader . batch_size ) tk0 . set_postfix ( valid_loss = running_loss . avg , validate_step_metrics = running_metrics . avg , stage = \"validation\" ) wandb . log ({ \"valid/step\" : b_idx , \"valid/metric_step\" : running_metrics . avg , \"valid/loss\" : running_loss . avg , }) outputs_arr = np . concatenate ( outputs_list ) valid_metric_val = self . epoch_metrics ( outputs_arr , self . valid_targets ) tk0 . close () return valid_metric_val , running_loss . avg def predict ( self , dataset , batch_size = 16 , num_workers = 8 , ): self . model . eval () self . test_loader = torch . utils . data . DataLoader ( dataset = test_dataset , batch_size = batch_size , shuffle = False , num_workers = num_workers , drop_last = False , pin_memory = True ) outputs_list = [] tk0 = tqdm ( self . test_loader , total = len ( self . test_loader ), position = 0 , leave = True ) for b_idx , ( inputs , targets ) in enumerate ( tk0 ): outputs_one_batch = self . predict_one_step ( inputs ) outputs_list . append ( outputs_one_batch . cpu () . detach () . numpy ()) tk0 . set_postfix ( stage = \"inference\" ) tk0 . close () outputs_arr = np . concatenate ( outputs_list ) return outputs_arr \u30e2\u30c7\u30eb\u306e\u4fdd\u5b58\u3068\u8aad\u307f\u8fbc\u307f \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def save ( self , model_path ): model_state_dict = self . model . state_dict () if self . optimizer is not None : opt_state_dict = self . optimizer . state_dict () else : opt_state_dict = None if self . scheduler_after_step is not None : sch_state_dict_after_step = self . scheduler_after_step . state_dict () else : sch_state_dict_after_step = None if self . scheduler_after_epoch is not None : sch_state_dict_after_epoch = self . scheduler_after_epoch . state_dict () else : sch_state_dict_after_epoch = None model_dict = {} model_dict [ \"state_dict\" ] = model_state_dict model_dict [ \"optimizer\" ] = opt_state_dict model_dict [ \"scheduler_after_step\" ] = sch_state_dict_after_step model_dict [ \"scheduler_after_epoch\" ] = sch_state_dict_after_epoch model_dict [ \"epoch\" ] = self . current_epoch model_dict [ \"fp16\" ] = self . fp16 model_dict [ \"multiple_GPU\" ] = self . multiple_GPU torch . save ( model_dict , model_path ) def load ( self , model_path ): self . device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) if next ( self . model . parameters ()) . device != self . device : self . model . to ( self . device ) model_dict = torch . load ( model_path , map_location = torch . device ( self . device )) self . model . load_state_dict ( model_dict [ \"state_dict\" ]) \u30e2\u30c7\u30eb\u306e\u8a13\u7df4\u3068\u691c\u8a3c\uff08fit\u95a2\u6570\uff09 \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def fit ( self , cfg , epochs = 5 , checkpoint_save_path = './' , mode = 'max' , patience = 10 , delta = 0.001 , ): set_seed ( CFG . seed ) self . _init_wandb ( cfg ) path_directory = Path ( checkpoint_save_path ) if mode == 'max' : current_best_valid_metrics = - float ( 'inf' ) else : current_best_valid_metrics = float ( 'inf' ) early_stopping_counter = 0 for epoch in range ( epochs ): self . current_epoch = epoch train_loss = self . train_one_epoch ( self . train_loader ) if valid_dataset : valid_metrics , valid_loss = self . validate_one_epoch ( self . valid_loader ) # Early Stopping and save at the check points. if mode == 'max' : if valid_metrics < current_best_valid_metrics + delta : early_stopping_counter += 1 print ( f 'EarlyStopping counter: { early_stopping_counter } out of { patience } ' ) if early_stopping_counter >= patience : break else : print ( f \"Validation score improved ( { current_best_valid_metrics } --> { valid_metrics } ). Saving the check point!\" ) current_best_valid_metrics = valid_metrics self . save ( checkpoint_save_path + f \" { cfg . pretrained_model_name } _epoch { epoch } .cpt\" ) else : if valid_metrics > current_best_valid_metrics - delta : early_stopping_counter += 1 print ( f 'EarlyStopping counter: { early_stopping_counter } out of { patience } ' ) if early_stopping_counter >= patience : break else : print ( f \"Validation score improved ( { current_best_valid_metrics } --> { valid_metrics } ). Saving the check point!\" ) current_best_valid_metrics = valid_metrics self . save ( checkpoint_save_path + f \" { cfg . pretrained_model_name } _epoch { epoch } .cpt\" ) #writer.add_scalar(\"Loss/train\", 1.0, epoch) print ( f 'epoch: { epoch } , validate_epoch_metrics : { valid_metrics } ' ) wandb . log ({ \"epoch\" : epoch , \"train/loss\" : train_loss , \"valid/loss\" : valid_loss , \"valid/metric\" : valid_metrics , }) wandb . finish () torch . cuda . empty_cache () gc . collect ()","title":"pytorch templates"},{"location":"pytorch_basis/#pytorch-basis","text":"","title":"Pytorch basis"},{"location":"pytorch_basis/#_1","text":"https://qiita.com/dokkozo/items/e173acded17a142e6d02","title":"\u30c1\u30fc\u30c8\u30b7\u30fc\u30c8"},{"location":"pytorch_basis/#basis","text":"flatten() : view(-1) squeeze() : view(*[s for s int t.shape if s != 1])\u3000\u8981\u7d20\u6570\u304c1\u306e\u8ef8\u3092\u524a\u9664\u3059\u308b\u3002\u6b21\u5143\u3092\u6e1b\u3089\u3059\u3002 unsqueeze(i) view( t.shape[:i-1], 1, t.shape[i:])\u3000\u6b21\u5143\u3092\u5897\u3084\u3059 https://stackoverflow.com/questions/57234095/what-is-the-difference-between-flatten-and-view-1-in-pytorch","title":"Basis"},{"location":"pytorch_basis/#utils","text":"","title":"Utils"},{"location":"pytorch_basis/#functions","text":"","title":"functions"},{"location":"pytorch_basis/#sigmoidndarray","text":"CPU\u4e0a\u3067Sigmoid\u95a2\u6570\u3092\u4f7f\u3046\u3002 1 2 3 4 5 6 def sigmoid ( gamma ): if gamma < 0 : return 1 - 1 / ( 1 + math . exp ( gamma )) return 1 / ( 1 + math . exp ( - gamma )) sigmoid_v = np . vectorize ( sigmoid )","title":"Sigmoid\u95a2\u6570\uff08ndarray\uff09"},{"location":"pytorch_basis/#seed","text":"1 2 3 4 5 6 7 8 def set_seed ( seed = 0 ): np . random . seed ( seed ) random_state = np . random . RandomState ( seed ) random . seed ( seed ) torch . manual_seed ( seed ) torch . cuda . manual_seed ( seed ) os . environ [ 'PYTHONHASHSEED' ] = str ( seed ) return random_state","title":"seed\u8a2d\u5b9a"},{"location":"pytorch_basis/#mixup","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 def mixup_data ( inputs , targets , alpha = 1.0 ): if alpha > 0 : lam = np . random . beta ( alpha , alpha ) else : lam = 1 batch_size = inputs . size ()[ 0 ] index = torch . randperm ( batch_size ) mixed_inputs = lam * inputs + ( 1 - lam ) * inputs [ index , :] targets_a , targets_b = targets , targets [ index ] return mixed_inputs , targets_a , targets_b , lam def mixup_criterion ( criterion , outputs , targets_a , targets_b , lam ): return lam * criterion ( outputs , targets_a ) + ( 1 - lam ) * criterion ( outputs , targets_b )","title":"mixup"},{"location":"pytorch_basis/#classes","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class AverageMeter (): def __init__ ( self ): self . val = 0 self . avg = 0 self . sum = 0 self . count = 0 def reset ( self ): self . val = 0 self . avg = 0 self . sum = 0 self . count = 0 def update ( self , val , n = 1 ): self . val = val self . sum += val * n self . count += n self . avg = self . sum / self . count","title":"classes"},{"location":"pytorch_basis/#dataset","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 class Dataset (): def __init__ ( self , image_paths , targets , transform = None ): self . image_paths = image_paths self . targets = targets self . transform = None def __len__ ( self ): return len ( self . image_paths ) def __getitem__ ( self , item ): targets = self . targets [ item ] image = np . load ( self . image_paths [ item ]) image = image [ np . newaxis , ] if self . transform : image = self . transform ( image ) return torch . tensor ( image , dtype = torch . float ), torch . tensor ( targets , dtype = torch . float )","title":"Dataset"},{"location":"pytorch_basis/#model","text":"1 2 3 4 5 6 7 8 9 10 11 12 class BasicNN ( nn . Module ): def __init__ ( self ): super () . __init__ () self . model = timm . create_model ( CFG . pretrained_model_name , pretrained = CFG . pretrained , in_chans = CFG . input_channels ) if not CFG . pretrained : self . model . load_state_dict ( torch . load ( CFG . pretrained_path )) self . model . classifier = nn . Linear ( self . model . classifier . in_features , CFG . out_dim ) def forward ( self , inputs ): outputs = self . model ( inputs ) return outputs","title":"Model"},{"location":"pytorch_basis/#trainer","text":"","title":"Trainer"},{"location":"pytorch_basis/#_2","text":"\u30c1\u30a7\u30c3\u30af\u30dd\u30a4\u30f3\u30c8\u306e\u4fdd\u5b58\uff06\u8aad\u307f\u8fbc\u307f : torch.save(model.state_dict(), model_path) , model.load_state_dict(torch.load(model_path)) AMP\uff08Automatic Mixed Precision\uff1a\u6df7\u5408\u7cbe\u5ea6\uff09\u3092\u7528\u3044\u305f\u9ad8\u901f\u5316 :\u901a\u5e38\u3001FP32\uff0832\u30d3\u30c3\u30c8\u6d6e\u52d5\u5c0f\u6570\u70b9\uff09\u3067\u8a08\u7b97\u3055\u308c\u307e\u3059\u304c\u3001\u534a\u5206\u306eFP16\uff0816\u30d3\u30c3\u30c8\u6d6e\u52d5\u5c0f\u6570\u70b9\uff09\u3067\u7cbe\u5ea6\u3092\u843d\u3068\u3055\u305a\u306b\u30e1\u30e2\u30ea\u306e\u4f7f\u7528\u91cf\u3092\u7bc0\u7d04\u3057\u3001\u8a08\u7b97\u901f\u5ea6\u3082\u5411\u4e0a\u3055\u305b\u308b\u6a5f\u80fd\u3002\u8a08\u7b97\u7cbe\u5ea6\u3092\u843d\u3068\u3057\u3066\u3082\u63a8\u8ad6\u306e\u7cbe\u5ea6\u304c\u843d\u3061\u306b\u304f\u3044 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 class Trainer (): def __init__ ( self , model , train_dataset , valid_dataset = None , train_batchsize = 16 , valid_batchsize = 16 , valid_targets = None , num_workers = 4 , fp16 = True , multiple_GPU = False , determinstic = True , benchmark = False ): self . device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) self . model = model self . model . to ( self . device ) self . valid_targets = valid_targets self . criterion = nn . BCEWithLogitsLoss () self . optimizer = self . configure_optimizer () self . scheduler_after_step = self . configure_scheduler_after_step () self . scheduler_after_epoch = self . configure_scheduler_after_epoch () torch . backends . cudnn . deterministic = determinstic torch . backends . cudnn . benchmark = benchmark self . fp16 = fp16 self . scaler = torch . cuda . amp . GradScaler () self . current_epoch = 0 if num_workers == - 1 : num_workers = psutil . cpu_count () self . multiple_GPU = multiple_GPU if multiple_GPU and torch . cuda . device_count () > 1 : print ( \"Let's use\" , torch . cuda . device_count (), \"GPUs!\" ) self = nn . DataParallel ( self ) self . train_loader = torch . utils . data . DataLoader ( dataset = train_dataset , batch_size = train_batchsize , shuffle = True , num_workers = num_workers , drop_last = True , pin_memory = True ) self . valid_loader = torch . utils . data . DataLoader ( dataset = valid_dataset , batch_size = valid_batchsize , shuffle = False , num_workers = num_workers , drop_last = False , pin_memory = True )","title":"\u521d\u671f\u5316"},{"location":"pytorch_basis/#wandb","text":"1 2 3 4 5 6 7 8 9 10 11 def _init_wandb ( self , cfg ): hyperparams = { 'batch_size' : cfg . batch_size , 'epochs' : cfg . epochs } wandb . init ( config = hyperparams , project = cfg . project_name , name = cfg . wandb_exp_name , ) wandb . watch ( self . model )","title":"wandb\u521d\u671f\u5316"},{"location":"pytorch_basis/#optimizer-schedular-metric","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 def configure_optimizer ( self ): opt = torch . optim . Adam ( self . model . parameters (), lr = CFG . lr ) return opt def configure_scheduler_after_step ( self ): sch = torch . optim . lr_scheduler . OneCycleLR ( optimizer = self . optimizer , epochs = CFG . epochs , steps_per_epoch = 3500 , max_lr = 5.0e-4 , pct_start = 0.1 , anneal_strategy = 'cos' , div_factor = 1.0e+3 , final_div_factor = 1.0e+3 ) return sch def configure_scheduler_after_epoch ( self ): return None def epoch_metrics ( self , outputs , targets ): preds = sigmoid_v ( outputs ) return metrics . roc_auc_score ( targets , preds ) def monitor_metrics ( self , outputs , targets ): preds = outputs . sigmoid () . cpu () . detach () . numpy () targets = targets . cpu () . detach () . numpy () if len ( np . unique ( targets )) > 1 : roc_auc = metrics . roc_auc_score ( targets , preds ) else : roc_auc = 0.5 return roc_auc","title":"optimizer, schedular, metric\u306e\u8a2d\u5b9a"},{"location":"pytorch_basis/#1step","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 def train_one_step ( self , inputs , targets ): inputs = inputs . to ( self . device , non_blocking = True ) targets = targets . to ( self . device , non_blocking = True ) inputs , targets_a , targets_b , lam = mixup_data ( inputs , targets , alpha = CFG . mixup_alpha ) self . optimizer . zero_grad () with torch . set_grad_enabled ( True ): if self . fp16 : with torch . cuda . amp . autocast ( self . fp16 ): outputs = self . model ( inputs ) outputs = outputs . flatten () #loss = self.criterion(outputs.flatten(), targets) loss = mixup_criterion ( self . criterion , outputs . flatten (), targets_a , targets_b , lam ) metrics = self . monitor_metrics ( outputs , targets ) self . scaler . scale ( loss ) . backward () self . scaler . step ( self . optimizer ) self . scaler . update () else : outputs = self . model ( inputs ) outputs = outputs . flatten () metrics = self . monitor_metrics ( outputs , targets ) loss = self . criterion ( outputs . flatten (), targets ) loss . backward () self . optimizer . step () if self . scheduler_after_step : self . scheduler_after_step . step () return outputs , loss , metrics def validate_one_step ( self , inputs , targets = None ): inputs = inputs . to ( self . device , non_blocking = True ) if targets is not None : targets = targets . to ( self . device , non_blocking = True ) with torch . no_grad (): outputs = self . model ( inputs ) outputs = outputs . flatten () loss = self . criterion ( outputs . flatten (), targets ) metrics = self . monitor_metrics ( outputs , targets ) return outputs , loss , metrics else : outputs = self . model ( inputs ) outputs = outputs . flatten () return outputs , None , None def predict_one_step ( self , inputs ): outputs , _ , _ = self . validate_one_step ( inputs ) return outputs","title":"1step\u3054\u3068\u306e\u8a13\u7df4\u3001\u691c\u8a3c\u3001\u63a8\u8ad6"},{"location":"pytorch_basis/#1epoch","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 def train_one_epoch ( self , data_loader ): self . model . train () running_loss , running_metrics = AverageMeter (), AverageMeter () tk0 = tqdm ( data_loader , total = len ( data_loader ), position = 0 , leave = True ) for b_idx , ( inputs , targets ) in enumerate ( tk0 ): _ , loss , metrics = self . train_one_step ( inputs , targets ) running_loss . update ( loss . item (), data_loader . batch_size ) running_metrics . update ( metrics , data_loader . batch_size ) current_lr = self . optimizer . param_groups [ 0 ][ 'lr' ] wandb . log ({ \"train/step\" : b_idx , \"train/loss_step\" : running_loss . avg , \"lr\" : current_lr }) tk0 . set_postfix ( train_loss = running_loss . avg , train_step_metrics = running_metrics . avg , stage = \"train\" , lr = current_lr ) if self . scheduler_after_epoch : self . scheduler_after_epoch . step () tk0 . close () return running_loss . avg def validate_one_epoch ( self , data_loader ): self . model . eval () running_loss , running_metrics = AverageMeter (), AverageMeter () outputs_list = [] tk0 = tqdm ( data_loader , total = len ( data_loader ), position = 0 , leave = True ) for b_idx , ( inputs , targets ) in enumerate ( tk0 ): outputs_one_batch , loss , metrics = self . validate_one_step ( inputs , targets ) outputs_list . append ( outputs_one_batch . cpu () . detach () . numpy ()) running_loss . update ( loss . item (), data_loader . batch_size ) running_metrics . update ( metrics , data_loader . batch_size ) tk0 . set_postfix ( valid_loss = running_loss . avg , validate_step_metrics = running_metrics . avg , stage = \"validation\" ) wandb . log ({ \"valid/step\" : b_idx , \"valid/metric_step\" : running_metrics . avg , \"valid/loss\" : running_loss . avg , }) outputs_arr = np . concatenate ( outputs_list ) valid_metric_val = self . epoch_metrics ( outputs_arr , self . valid_targets ) tk0 . close () return valid_metric_val , running_loss . avg def predict ( self , dataset , batch_size = 16 , num_workers = 8 , ): self . model . eval () self . test_loader = torch . utils . data . DataLoader ( dataset = test_dataset , batch_size = batch_size , shuffle = False , num_workers = num_workers , drop_last = False , pin_memory = True ) outputs_list = [] tk0 = tqdm ( self . test_loader , total = len ( self . test_loader ), position = 0 , leave = True ) for b_idx , ( inputs , targets ) in enumerate ( tk0 ): outputs_one_batch = self . predict_one_step ( inputs ) outputs_list . append ( outputs_one_batch . cpu () . detach () . numpy ()) tk0 . set_postfix ( stage = \"inference\" ) tk0 . close () outputs_arr = np . concatenate ( outputs_list ) return outputs_arr","title":"1epoch\u3054\u3068\u306e\u8a13\u7df4\u3001\u691c\u8a3c\u3001\u63a8\u8ad6"},{"location":"pytorch_basis/#_3","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 def save ( self , model_path ): model_state_dict = self . model . state_dict () if self . optimizer is not None : opt_state_dict = self . optimizer . state_dict () else : opt_state_dict = None if self . scheduler_after_step is not None : sch_state_dict_after_step = self . scheduler_after_step . state_dict () else : sch_state_dict_after_step = None if self . scheduler_after_epoch is not None : sch_state_dict_after_epoch = self . scheduler_after_epoch . state_dict () else : sch_state_dict_after_epoch = None model_dict = {} model_dict [ \"state_dict\" ] = model_state_dict model_dict [ \"optimizer\" ] = opt_state_dict model_dict [ \"scheduler_after_step\" ] = sch_state_dict_after_step model_dict [ \"scheduler_after_epoch\" ] = sch_state_dict_after_epoch model_dict [ \"epoch\" ] = self . current_epoch model_dict [ \"fp16\" ] = self . fp16 model_dict [ \"multiple_GPU\" ] = self . multiple_GPU torch . save ( model_dict , model_path ) def load ( self , model_path ): self . device = torch . device ( \"cuda:0\" if torch . cuda . is_available () else \"cpu\" ) if next ( self . model . parameters ()) . device != self . device : self . model . to ( self . device ) model_dict = torch . load ( model_path , map_location = torch . device ( self . device )) self . model . load_state_dict ( model_dict [ \"state_dict\" ])","title":"\u30e2\u30c7\u30eb\u306e\u4fdd\u5b58\u3068\u8aad\u307f\u8fbc\u307f"},{"location":"pytorch_basis/#fit","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def fit ( self , cfg , epochs = 5 , checkpoint_save_path = './' , mode = 'max' , patience = 10 , delta = 0.001 , ): set_seed ( CFG . seed ) self . _init_wandb ( cfg ) path_directory = Path ( checkpoint_save_path ) if mode == 'max' : current_best_valid_metrics = - float ( 'inf' ) else : current_best_valid_metrics = float ( 'inf' ) early_stopping_counter = 0 for epoch in range ( epochs ): self . current_epoch = epoch train_loss = self . train_one_epoch ( self . train_loader ) if valid_dataset : valid_metrics , valid_loss = self . validate_one_epoch ( self . valid_loader ) # Early Stopping and save at the check points. if mode == 'max' : if valid_metrics < current_best_valid_metrics + delta : early_stopping_counter += 1 print ( f 'EarlyStopping counter: { early_stopping_counter } out of { patience } ' ) if early_stopping_counter >= patience : break else : print ( f \"Validation score improved ( { current_best_valid_metrics } --> { valid_metrics } ). Saving the check point!\" ) current_best_valid_metrics = valid_metrics self . save ( checkpoint_save_path + f \" { cfg . pretrained_model_name } _epoch { epoch } .cpt\" ) else : if valid_metrics > current_best_valid_metrics - delta : early_stopping_counter += 1 print ( f 'EarlyStopping counter: { early_stopping_counter } out of { patience } ' ) if early_stopping_counter >= patience : break else : print ( f \"Validation score improved ( { current_best_valid_metrics } --> { valid_metrics } ). Saving the check point!\" ) current_best_valid_metrics = valid_metrics self . save ( checkpoint_save_path + f \" { cfg . pretrained_model_name } _epoch { epoch } .cpt\" ) #writer.add_scalar(\"Loss/train\", 1.0, epoch) print ( f 'epoch: { epoch } , validate_epoch_metrics : { valid_metrics } ' ) wandb . log ({ \"epoch\" : epoch , \"train/loss\" : train_loss , \"valid/loss\" : valid_loss , \"valid/metric\" : valid_metrics , }) wandb . finish () torch . cuda . empty_cache () gc . collect ()","title":"\u30e2\u30c7\u30eb\u306e\u8a13\u7df4\u3068\u691c\u8a3c\uff08fit\u95a2\u6570\uff09"},{"location":"ssh/","text":"\u30ea\u30e2\u30fc\u30c8\u3067Jupyterlab\u3092\u958b\u304f \u00b6 1 2 3 4 5 6 7 8 9 10 11 ssh -L <host port>:localhost:<remote port> user@remote docker run -it --rm -p <host port>:<remote port> --name <container-name> -v: $PWD :/work -w /work <image-name> /bin/bash jupyter lab --ip 0 .0.0.0 --port <container port> --allow-root #\u540c\u6642\u306b docker run -it --rm -p 9999 :9999 --name kaggle-docker \\ -v: $PWD :/work -v: /dataset:/dataset -w /work kaggle/python-gpu-build \\ jupyter lab --ip 0 .0.0.0 --port 9999 --allow-root","title":"SSH"},{"location":"ssh/#jupyterlab","text":"1 2 3 4 5 6 7 8 9 10 11 ssh -L <host port>:localhost:<remote port> user@remote docker run -it --rm -p <host port>:<remote port> --name <container-name> -v: $PWD :/work -w /work <image-name> /bin/bash jupyter lab --ip 0 .0.0.0 --port <container port> --allow-root #\u540c\u6642\u306b docker run -it --rm -p 9999 :9999 --name kaggle-docker \\ -v: $PWD :/work -v: /dataset:/dataset -w /work kaggle/python-gpu-build \\ jupyter lab --ip 0 .0.0.0 --port 9999 --allow-root","title":"\u30ea\u30e2\u30fc\u30c8\u3067Jupyterlab\u3092\u958b\u304f"},{"location":"templates/","text":"TH \u5de6\u5bc4\u305b TH \u4e2d\u592e\u5bc4\u305b TH \u53f3\u5bc4\u305b TD TD TD TD TD TD Note \u3053\u308c\u306f\u30ce\u30fc\u30c8\u3067\u3059\u3002 Tip \u30d2\u30f3\u30c8\u3067\u3059\u3002 Warning \u3053\u308c\u306f\u8b66\u544a\u3067\u3059\u3002 Danger \u3053\u308c\u306f\u5371\u967a\u3067\u3059\u3002 Success \u3053\u308c\u306f\u6210\u529f\u3067\u3059\u3002 Failure \u3053\u308c\u306f\u5931\u6557\u3067\u3059\u3002 Bug \u3053\u308c\u306f\u30d0\u30b0\u3067\u3059\u3002 Summary \u3053\u308c\u306f\u6982\u8981\u3067\u3059\u3002 Mkdocs \u3068\u306f\u9759\u7684\u30b5\u30a4\u30c8\u30b8\u30a7\u30cd\u30ec\u30fc\u30bf\u3067\u3059\u3002 \u30b3\u30f3\u30c6\u30f3\u30c4\u306f\u57fa\u672c\u7684\u306b markdown 1 \u5f62\u5f0f\u3067\u8a18\u8ff0\u3057\u305f\u30bd\u30fc\u30b9\u30d5\u30a1\u30a4\u30eb\u306b\u306a\u308a\u307e\u3059\u3002 \u5b9a\u7fa9\u8a9e \u3053\u3053\u306b\u8aac\u660e\u3092\u66f8\u304d\u307e\u3059 \u6587\u66f8\u3092\u8a18\u8ff0\u3059\u308b\u305f\u3081\u306e\u8efd\u91cf\u30de\u30fc\u30af\u30a2\u30c3\u30d7\u8a00\u8a9e\u306e\u3072\u3068\u3064 \u21a9","title":"Templates"}]}