{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"docker/","text":"Dockerhub \u306e\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb Dockerfile \u304b\u3089 DockerImage, DockerImage \u304b\u3089\u30b3\u30f3\u30c6\u30ca https://scrapbox.io/llminatoll/docker_run%E3%81%AE%E3%82%AA%E3%83%97%E3%82%B7%E3%83%A7%E3%83%B3%E3%81%84%E3%82%8D%E3%81%84%E3%82%8D https://beyondjapan.com/blog/2016/08/docker-command-reverse-resolutions/ https://smot93516.hatenablog.jp/entry/2018/09/20/001052 https://morizyun.github.io/docker/about-docker-command.html \u793e\u5185\u306e Dockerfile \u306e\u30d9\u30b9\u30c8\u30d7\u30e9\u30af\u30c6\u30a3\u30b9\u3092\u516c\u958b\u3057\u307e\u3059 https://qiita.com/zembutsu/items/a96b68277d699f79418d https://www.slideshare.net/zembutsu/explaining-best-practices-for-writing-dockerfiles https://qiita.com/zembutsu/items/24558f9d0d254e33088f https://www.slideshare.net/zembutsu/what-isdockerdoing https://nykergoto.hatenablog.jp/entry/2020/07/25/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AAdockerfile%E3%82%92%E6%9B%B8%E3%81%8F%E3%81%A8%E3%81%8D%E3%81%AB%E6%B0%97%E3%82%92%E3%81%A4%E3%81%91%E3%81%A8%E3%81%8F%E3%81%A8%E8%89%AF%E3%81%84%E3%81%93 https://qiita.com/zembutsu/items/a96b68277d699f79418d DL/RL on server \u306e Docker \u74b0\u5883\u69cb\u7bc9\u3010\u795d 500DL\uff01\u3011(21/08/04 \u66f4\u65b0) Running Jupyter on a remote Docker container using SSH docker login : dockerhub \u306b\u30ed\u30b0\u30a4\u30f3\u3059\u308b docker pull <image> dockerhub \u304b\u3089\u30a4\u30e1\u30fc\u30b8\u3092\u3068\u3063\u3066\u304f\u308b docker images dockerimage \u306e\u4e00\u89a7\u3092\u8868\u793a docker run <image> create + start, docker \u30a4\u30e1\u30fc\u30b8\u304b\u3089\u30b3\u30f3\u30c6\u30ca\u3092\u4f5c\u6210\u3002\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u30b3\u30de\u30f3\u30c9\u304c\u5b9f\u884c\u3055\u308c\u308b\u3002 docker ps -a \u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u306e\u4e00\u89a7\u3092\u8868\u793a docker run -it ubuntu bash :docker \u3067 ubuntu \u306e bash \u3092\u8d77\u52d5\uff08bash \u3067\u30c7\u30d5\u30a9\u30eb\u30c8\u30b3\u30de\u30f3\u30c9\u4e0a\u66f8\u304d\uff09, -it \u306f bash \u3092\u8d77\u52d5\u72b6\u614b\uff08up\uff09\u306b\u4fdd\u6301\u3059\u308b\u3002-it \u304c\u306a\u3044\u3068 exit \u72b6\u614b\u306b\u5909\u308f\u308b\u3002-i:\u6a19\u6e96\u5165\u529b\u3092\u958b\u304f\u3001-t:\u51fa\u529b\u304c\u304d\u308c\u3044\u306b\u306a\u308b\u3002 ctri + p + q :detach \u7d42\u4e86 docker attach <container> attach \u3067 up \u72b6\u614b\u306e container \u306b\u5165\u308b\u3002 exit :\u7d42\u4e86 docker restart <container> docker exec -it <container> <command> docker commit <container> <new image> \u30b3\u30f3\u30c6\u30ca\u304b\u3089 new image \u3068\u3057\u3066\u4fdd\u5b58 docker commit <container> ubuntu:updated \u30bb\u30df\u30b3\u30ed\u30f3\u3067 tag \u540d\u306b\u306a\u308b image \u540d\u306f repostitory \u540d\uff0b tag \u540d docker tag <source> <target> docker tag ubuntu:updated <username>/my-repo :\u540d\u524d\u306e\u5909\u66f4 library/ubuntu \u306f, \u6b63\u5f0f\u306b\u306f registry-1.docker.io/library/ubuntu:latest docker push <image> docker pull <image> docker rmi <image> docker image \u3092\u524a\u9664 docker rm <container> \u30b3\u30f3\u30c6\u30ca\u306e\u524a\u9664 docker stop <container> \u30b3\u30f3\u30c6\u30ca\u3092\u6b62\u3081\u308b docker system prune :\u30b3\u30f3\u30c6\u30ca\u5168\u524a\u9664 sudo docker system prune -all : \u30b3\u30f3\u30c6\u30ca\u30a4\u30e1\u30fc\u30b8\u5168\u524a\u9664 docker volume prune docker run --name <name> <image> :\u30b3\u30f3\u30c6\u30ca\u306e\u540d\u524d\u3092\u3064\u3051\u308b\u3002 docker run -d <image> :\u30b3\u30f3\u30c6\u30ca\u3092\u8d77\u52d5\u5f8c\u306b detach \u3059\u308b\uff08host \u306b\u623b\u308b\uff09 docker run -rm <image> :\u30b3\u30f3\u30c6\u30ca\u3092 exit \u5f8c\u306b\u524a\u9664\u3059\u308b\u3002 docker images -aq | xargs docker rmi docker ps -aq | xargs docker rm docker stop $(docker ps -q) : \u3059\u3079\u3066\u306e\u30b3\u30f3\u30c6\u30ca\u505c\u6b62 docker rm $(docker ps -q -a) : \u3059\u3079\u3066\u306e\u30b3\u30f3\u30c6\u30ca\u524a\u9664 docker rmi $(docker images -q) : \u3059\u3079\u3066\u306e\u30a4\u30e1\u30fc\u30b8\u524a\u9664 docker-compose logs --tail=100 -f xxxx-server `` docker file \u306e\u4f5c\u6210 \u00b6 1 2 3 4 5 6 7 8 9 10 11 FROM ubuntu:latest ADD copressed.tar / COPY something /new_directory/ ENV key1 value RUN apt update && apt install -y \\ aaa \\ bbb \\ ccc WORKDIR /sample_folder RUN touch something CMD [ \"executable\" , \"param1\" , \"param2\" ] docker build <directory> docker build -t <name> <directory> docker build -f <dockerfilename> <build context> \u540d\u524d\u306f\u30c9\u30c3\u30c8\u3067\u3064\u306a\u304c\u308b\u3053\u3068\u304c\u591a\u3044\u3002Dockerfile \u3068\u3044\u3046\u540d\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u30d3\u30eb\u30c9\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u5165\u3063\u3066\u3044\u306a\u3044\u5834\u5408\u3002 FROM :\u30d9\u30fc\u30b9\u3068\u306a\u308b\u30a4\u30e1\u30fc\u30b8\u3092\u6c7a\u5b9a RUN :Linux \u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3002RUN \u6bce\u306b Layer \u304c\u4f5c\u3089\u308c\u308b\u3002Layer \u6570\u3092\u6700\u5c0f\u9650\u306b\u3059\u308b\u3002&&\u3067\u3064\u306a\u3052\u308b\u3002(\u30d1\u30c3\u30b1\u30fc\u30b8\u540d\u3092\u30a2\u30eb\u30d5\u30a1\u30d9\u30c3\u30c8\u9806\u3067)\\\u30d0\u30c3\u30af\u30b9\u30e9\u30c3\u30b7\u30e5\u3067\u6539\u884c\u3059\u308b\u3002 \u6700\u521d\u306f Layer \u3092\u7d30\u304b\u304f\u5206\u3051\u3066\u901a\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3002\u6700\u5f8c\u306b Layer \u3092\u6700\u5c0f\u9650\u306b\u3059\u308b\u3002 CMD :\u30b3\u30f3\u30c6\u30ca\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u30b3\u30de\u30f3\u30c9\u3092\u6307\u5b9a\u3002CMD [\"command\", \"param1\", \"paramn2\"] ex. CMD [/bin/bash], CMD \u306f\u30ec\u30a4\u30e4\u30fc\u3092\u4f5c\u3089\u306a\u3044\u3002 Docker \u30b3\u30de\u30f3\u30c9\u3067 Docker Daemon \u306b\u547d\u4ee4\u3092\u51fa\u3059 COPY: \u5358\u7d14\u306b\u30d5\u30a1\u30a4\u30eb\u3084\u30d5\u30a9\u30eb\u30c0\u3092\u30b3\u30d4\u30fc\u3059\u308b\u5834\u5408 ADD: tar \u306e\u5727\u7e2e\u30d5\u30a1\u30a4\u30eb\u3092\u89e3\u7b54\u3059\u308b ENTRYPOINT \u306f\u4e0a\u66f8\u304d\u3067\u304d\u306a\u3044\uff08CMD \u306f\u4e0a\u66f8\u304d\u3067\u304d\u308b\uff09\u3002ENTRYPOINT \u304c\u3042\u308b\u3068\u304d\u306f CMD \u306f params \u306e\u307f\u3092\u66f8\u304f\u3002 ENTRYPOINT \u306f\u30b3\u30f3\u30c6\u30ca\u3092\u30b3\u30de\u30f3\u30c9\u306e\u3088\u3046\u306b\u4f7f\u3044\u305f\u3044\u3068\u304d\u3002 ENV :\u74b0\u5883\u5909\u6570\u3092\u8a2d\u5b9a\u3059\u308b\u3002 WORKDIR \u5b9f\u884c\u74b0\u5883\u3092\u5909\u66f4\u3059\u308b\u3002 \u30db\u30b9\u30c8\u3068\u30b3\u30f3\u30c6\u30ca\u3092\u3064\u306a\u3050 \u00b6 docker run -it -v <host>:<container> <image bash> docker run -it -u $(id -u):$(id -g) -v ~/mouted_folder:/new_dir <image> bash -u <uder id>:<group id>: \u30e6\u30fc\u30b6ID\u3068\u30b0\u30eb\u30fc\u30d7ID\u3092\u6307\u5b9a\u3059\u308b -p <host_port>:<container_port> docker run -it -p 8888:8888 --rm jupyter/datascience-notebook bash docker run -it --rm --cpus 4 --memory 2g ubuntu bash docker inspect <container> | grep -i cpu \u30ed\u30fc\u30ab\u30eb\u3067\u74b0\u5883\u69cb\u7bc9 \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 FROM ubuntu:latest RUN apt-get update && apt-get install -y \\ sudo \\ wget \\ vim WORKDIR /opt RUN wget https://repo.continuum.io/archive/Anaconda3-2019.10-Linux-x86_64.sh && \\ sh /opt/Anaconda3-2019.10-Linux-x86_64.sh -b -p /opt/anaconda3 \\ rm -f Anaconda3-2019.10-Linux-x86_64.sh ENV PATH /opt/anaconda3/bin: $PATH RUN pip install --upgrade pip WORKDIR / CMD [ \"jupyter\" , \"lab\" , \"--ip=0.0.0.0\" , \"--allow-root\" , \"--LabAPP.token=''\" ] docker run -p 8888:8888 -v ~/Desktop/ds-pyhton:/work --name my-lab <container> GPU \u74b0\u5883\u4f8b \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04 RUN apt-get update && apt-get install -y \\ sudo \\ wget \\ vim WORKDIR /opt RUN wget https://repo.continuum.io/archive/Anaconda3-2019.10-Linux-x86_64.sh && \\ sh /opt/Anaconda3-2019.10-Linux-x86_64.sh -b -p /opt/anaconda3 \\ rm -f Anaconda3-2019.10-Linux-x86_64.sh ENV PATH /opt/anaconda3/bin: $PATH RUN pip install --upgrade pip && pip install \\ keras == 2 .3 \\ scipy == 1 .4.1 \\ tensorflow-gpu == 2 .1 WORKDIR / CMD [ \"jupyter\" , \"lab\" , \"--ip=0.0.0.0\" , \"--allow-root\" , \"--LabAPP.token=''\" ] 20211205c \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 FROM nvcr.io/nvidia/pytorch:21.11-py3 ENV DEBIAN_FRONTEND = noninteractive ENV TZ = Asia/Tokyo RUN ln -snf /usr/share/zoneinfo/ $TZ /etc/localtime && echo $TZ > /etc/timezone RUN apt-get update && apt-get upgrade -y \\ && apt-get install -y --no-install-recommends \\ sudo \\ wget \\ curl \\ git \\ vim \\ make \\ cmake \\ nodejs \\ default-jdk \\ default-jre \\ libgl1-mesa-dev \\ && apt-get autoremove -y \\ && apt-get clean \\ && rm -rf \\ /var/lib/apt/lists/* \\ /var/cache/apt/* \\ /usr/local/src/* \\ /tmp/* RUN conda install -y \\ nodejs && \\ conda clean -i -t -y RUN python3 -m pip install --upgrade pip \\ && pip install --no-cache-dir --upgrade \\ black \\ jupyterlab \\ jupyterlab_code_formatter \\ lckr-jupyterlab-variableinspector \\ jupyterlab_widgets \\ ipywidgets \\ import-ipynb \\ && jupyter labextension install jupyterlab-plotly@5.4.0 RUN pip install --no-cache-dir --upgrade \\ numpy \\ pandas == 1 .2.5 \\ scipy \\ scikit-learn \\ matplotlib \\ seaborn \\ plotly \\ Pillow \\ opencv-python \\ opencv-contrib-python \\ albumentations \\ requests \\ tqdm \\ xgboost \\ lightgbm \\ optuna \\ timm \\ omegaconf \\ hydra-core \\ pytorch-pfn-extras \\ wandb \\ mlflow \\ pyyaml \\ mplfinance \\ statsmodels \\ shap \\ numba \\ ccxt \\ TA-Lib == 0 .4.21 \\ ta \\ pandas_ta \\ finta \\ tsfresh \\ && rm -rf ~/.cache/pip docker makefile \u00b6 http://www.jsk.t.u-tokyo.ac.jp/~k-okada/makefile/ Docker \u306e Makefile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 NAME = xxx VERSION = xxx build : docker build -t $( NAME ) : $( VERSION ) . restart : stop start start : docker run -itd \\ -p xxx:xxx \\ -v xxx:xxx \\ --name $( NAME ) \\ $( NAME ) : $( VERSION ) bash contener = ` docker ps -a -q ` image = ` docker images | awk '/^<none>/ { print $$3 }' ` clean : @if [ \" $( image ) \" ! = \"\" ] ; then \\ docker rmi $( image ) ; \\ fi @if [ \" $( contener ) \" ! = \"\" ] ; then \\ docker rm $( contener ) ; \\ fi stop : docker rm -f $( NAME ) attach : docker exec -it $( NAME ) /bin/bash logs : docker logs $( NAME ) Laravel \u958b\u767a\u6642\u306b\u4fbf\u5229\u306a make(Makefile)\u30b3\u30de\u30f3\u30c9\u96c6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 up : docker-compose up -d build : docker-compose build create-project : docker-compose up -d --build docker-compose exec app composer create-project --prefer-dist laravel/laravel . docker-compose exec app composer require predis/predis install : docker-compose up -d --build docker-compose exec app composer install docker-compose exec app cp .env.example .env docker-compose exec app php artisan key:generate docker-compose exec app php artisan migrate:fresh --seed reinstall : @make destroy @make install stop : docker-compose stop restart : docker-compose down docker-compose up -d down : docker-compose down destroy : docker-compose down --rmi all --volumes ps : docker-compose ps app : docker-compose exec app bash fresh : docker-compose exec app php artisan migrate:fresh --seed seed : docker-compose exec app php artisan db:seed tinker : docker-compose exec app php artisan tinker dump : docker-compose exec app php artisan dump-server test : docker-compose exec app php ./vendor/bin/phpunit cache : docker-compose exec app composer dump-autoload -o docker-compose exec app php artisan optimize:clear docker-compose exec app php artisan optimize cache-clear : docker-compose exec app php artisan optimize:clear cs : docker-compose exec app ./vendor/bin/phpcs cbf : docker-compose exec app ./vendor/bin/phpcbf db : docker-compose exec db bash sql : docker-compose exec db bash -c 'mysql -u $$MYSQL_USER -p$$MYSQL_PASSWORD $$MYSQL_DATABASE' node : docker-compose exec node ash npm : docker-compose exec node npm install docker-compose exec node npm run dev yarn : docker-compose exec node yarn docker-compose exec node yarn dev 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 DOCKER_REPOSITORY := shibui/ml-system-in-actions ABSOLUTE_PATH := $( shell pwd ) DOCKERFILE := Dockerfile IMAGE_VERSION := 0 .0.1 WEB_SINGLE_PATTERN := web_single_pattern WEB_SINGLE_PATTERN_PORT := 8000 .PHONY : build build : docker build \\ -t $( DOCKER_REPOSITORY ) : $( WEB_SINGLE_PATTERN ) _ $( IMAGE_VERSION ) \\ -f $( DOCKERFILE ) \\ . .PHONY : run run : docker run \\ -it \\ --name $( WEB_SINGLE_PATTERN ) \\ -p $( WEB_SINGLE_PATTERN_PORT ) : $( WEB_SINGLE_PATTERN_PORT ) \\ $( DOCKER_REPOSITORY ) : $( WEB_SINGLE_PATTERN ) _ $( IMAGE_VERSION ) .PHONY : stop stop : docker rm -f $( WEB_SINGLE_PATTERN ) .PHONY : push push : docker push $( DOCKER_REPOSITORY ) : $( WEB_SINGLE_PATTERN ) _ $( IMAGE_VERSION ) .PHONY : build_all build_all : build .PHONY : run_all run_all : run .PHONY : push_all push_all : push","title":"Docker"},{"location":"docker/#docker-file","text":"1 2 3 4 5 6 7 8 9 10 11 FROM ubuntu:latest ADD copressed.tar / COPY something /new_directory/ ENV key1 value RUN apt update && apt install -y \\ aaa \\ bbb \\ ccc WORKDIR /sample_folder RUN touch something CMD [ \"executable\" , \"param1\" , \"param2\" ] docker build <directory> docker build -t <name> <directory> docker build -f <dockerfilename> <build context> \u540d\u524d\u306f\u30c9\u30c3\u30c8\u3067\u3064\u306a\u304c\u308b\u3053\u3068\u304c\u591a\u3044\u3002Dockerfile \u3068\u3044\u3046\u540d\u306e\u30d5\u30a1\u30a4\u30eb\u304c\u30d3\u30eb\u30c9\u30b3\u30f3\u30c6\u30ad\u30b9\u30c8\u306b\u5165\u3063\u3066\u3044\u306a\u3044\u5834\u5408\u3002 FROM :\u30d9\u30fc\u30b9\u3068\u306a\u308b\u30a4\u30e1\u30fc\u30b8\u3092\u6c7a\u5b9a RUN :Linux \u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c\u3002RUN \u6bce\u306b Layer \u304c\u4f5c\u3089\u308c\u308b\u3002Layer \u6570\u3092\u6700\u5c0f\u9650\u306b\u3059\u308b\u3002&&\u3067\u3064\u306a\u3052\u308b\u3002(\u30d1\u30c3\u30b1\u30fc\u30b8\u540d\u3092\u30a2\u30eb\u30d5\u30a1\u30d9\u30c3\u30c8\u9806\u3067)\\\u30d0\u30c3\u30af\u30b9\u30e9\u30c3\u30b7\u30e5\u3067\u6539\u884c\u3059\u308b\u3002 \u6700\u521d\u306f Layer \u3092\u7d30\u304b\u304f\u5206\u3051\u3066\u901a\u308b\u3053\u3068\u3092\u78ba\u8a8d\u3059\u308b\u3002\u6700\u5f8c\u306b Layer \u3092\u6700\u5c0f\u9650\u306b\u3059\u308b\u3002 CMD :\u30b3\u30f3\u30c6\u30ca\u306e\u30c7\u30d5\u30a9\u30eb\u30c8\u306e\u30b3\u30de\u30f3\u30c9\u3092\u6307\u5b9a\u3002CMD [\"command\", \"param1\", \"paramn2\"] ex. CMD [/bin/bash], CMD \u306f\u30ec\u30a4\u30e4\u30fc\u3092\u4f5c\u3089\u306a\u3044\u3002 Docker \u30b3\u30de\u30f3\u30c9\u3067 Docker Daemon \u306b\u547d\u4ee4\u3092\u51fa\u3059 COPY: \u5358\u7d14\u306b\u30d5\u30a1\u30a4\u30eb\u3084\u30d5\u30a9\u30eb\u30c0\u3092\u30b3\u30d4\u30fc\u3059\u308b\u5834\u5408 ADD: tar \u306e\u5727\u7e2e\u30d5\u30a1\u30a4\u30eb\u3092\u89e3\u7b54\u3059\u308b ENTRYPOINT \u306f\u4e0a\u66f8\u304d\u3067\u304d\u306a\u3044\uff08CMD \u306f\u4e0a\u66f8\u304d\u3067\u304d\u308b\uff09\u3002ENTRYPOINT \u304c\u3042\u308b\u3068\u304d\u306f CMD \u306f params \u306e\u307f\u3092\u66f8\u304f\u3002 ENTRYPOINT \u306f\u30b3\u30f3\u30c6\u30ca\u3092\u30b3\u30de\u30f3\u30c9\u306e\u3088\u3046\u306b\u4f7f\u3044\u305f\u3044\u3068\u304d\u3002 ENV :\u74b0\u5883\u5909\u6570\u3092\u8a2d\u5b9a\u3059\u308b\u3002 WORKDIR \u5b9f\u884c\u74b0\u5883\u3092\u5909\u66f4\u3059\u308b\u3002","title":"docker file \u306e\u4f5c\u6210"},{"location":"docker/#_1","text":"docker run -it -v <host>:<container> <image bash> docker run -it -u $(id -u):$(id -g) -v ~/mouted_folder:/new_dir <image> bash -u <uder id>:<group id>: \u30e6\u30fc\u30b6ID\u3068\u30b0\u30eb\u30fc\u30d7ID\u3092\u6307\u5b9a\u3059\u308b -p <host_port>:<container_port> docker run -it -p 8888:8888 --rm jupyter/datascience-notebook bash docker run -it --rm --cpus 4 --memory 2g ubuntu bash docker inspect <container> | grep -i cpu","title":"\u30db\u30b9\u30c8\u3068\u30b3\u30f3\u30c6\u30ca\u3092\u3064\u306a\u3050"},{"location":"docker/#_2","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 FROM ubuntu:latest RUN apt-get update && apt-get install -y \\ sudo \\ wget \\ vim WORKDIR /opt RUN wget https://repo.continuum.io/archive/Anaconda3-2019.10-Linux-x86_64.sh && \\ sh /opt/Anaconda3-2019.10-Linux-x86_64.sh -b -p /opt/anaconda3 \\ rm -f Anaconda3-2019.10-Linux-x86_64.sh ENV PATH /opt/anaconda3/bin: $PATH RUN pip install --upgrade pip WORKDIR / CMD [ \"jupyter\" , \"lab\" , \"--ip=0.0.0.0\" , \"--allow-root\" , \"--LabAPP.token=''\" ] docker run -p 8888:8888 -v ~/Desktop/ds-pyhton:/work --name my-lab <container>","title":"\u30ed\u30fc\u30ab\u30eb\u3067\u74b0\u5883\u69cb\u7bc9"},{"location":"docker/#gpu","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 FROM nvidia/cuda:10.1-cudnn7-runtime-ubuntu18.04 RUN apt-get update && apt-get install -y \\ sudo \\ wget \\ vim WORKDIR /opt RUN wget https://repo.continuum.io/archive/Anaconda3-2019.10-Linux-x86_64.sh && \\ sh /opt/Anaconda3-2019.10-Linux-x86_64.sh -b -p /opt/anaconda3 \\ rm -f Anaconda3-2019.10-Linux-x86_64.sh ENV PATH /opt/anaconda3/bin: $PATH RUN pip install --upgrade pip && pip install \\ keras == 2 .3 \\ scipy == 1 .4.1 \\ tensorflow-gpu == 2 .1 WORKDIR / CMD [ \"jupyter\" , \"lab\" , \"--ip=0.0.0.0\" , \"--allow-root\" , \"--LabAPP.token=''\" ]","title":"GPU \u74b0\u5883\u4f8b"},{"location":"docker/#20211205c","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 FROM nvcr.io/nvidia/pytorch:21.11-py3 ENV DEBIAN_FRONTEND = noninteractive ENV TZ = Asia/Tokyo RUN ln -snf /usr/share/zoneinfo/ $TZ /etc/localtime && echo $TZ > /etc/timezone RUN apt-get update && apt-get upgrade -y \\ && apt-get install -y --no-install-recommends \\ sudo \\ wget \\ curl \\ git \\ vim \\ make \\ cmake \\ nodejs \\ default-jdk \\ default-jre \\ libgl1-mesa-dev \\ && apt-get autoremove -y \\ && apt-get clean \\ && rm -rf \\ /var/lib/apt/lists/* \\ /var/cache/apt/* \\ /usr/local/src/* \\ /tmp/* RUN conda install -y \\ nodejs && \\ conda clean -i -t -y RUN python3 -m pip install --upgrade pip \\ && pip install --no-cache-dir --upgrade \\ black \\ jupyterlab \\ jupyterlab_code_formatter \\ lckr-jupyterlab-variableinspector \\ jupyterlab_widgets \\ ipywidgets \\ import-ipynb \\ && jupyter labextension install jupyterlab-plotly@5.4.0 RUN pip install --no-cache-dir --upgrade \\ numpy \\ pandas == 1 .2.5 \\ scipy \\ scikit-learn \\ matplotlib \\ seaborn \\ plotly \\ Pillow \\ opencv-python \\ opencv-contrib-python \\ albumentations \\ requests \\ tqdm \\ xgboost \\ lightgbm \\ optuna \\ timm \\ omegaconf \\ hydra-core \\ pytorch-pfn-extras \\ wandb \\ mlflow \\ pyyaml \\ mplfinance \\ statsmodels \\ shap \\ numba \\ ccxt \\ TA-Lib == 0 .4.21 \\ ta \\ pandas_ta \\ finta \\ tsfresh \\ && rm -rf ~/.cache/pip","title":"20211205c"},{"location":"docker/#docker-makefile","text":"http://www.jsk.t.u-tokyo.ac.jp/~k-okada/makefile/ Docker \u306e Makefile 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 NAME = xxx VERSION = xxx build : docker build -t $( NAME ) : $( VERSION ) . restart : stop start start : docker run -itd \\ -p xxx:xxx \\ -v xxx:xxx \\ --name $( NAME ) \\ $( NAME ) : $( VERSION ) bash contener = ` docker ps -a -q ` image = ` docker images | awk '/^<none>/ { print $$3 }' ` clean : @if [ \" $( image ) \" ! = \"\" ] ; then \\ docker rmi $( image ) ; \\ fi @if [ \" $( contener ) \" ! = \"\" ] ; then \\ docker rm $( contener ) ; \\ fi stop : docker rm -f $( NAME ) attach : docker exec -it $( NAME ) /bin/bash logs : docker logs $( NAME ) Laravel \u958b\u767a\u6642\u306b\u4fbf\u5229\u306a make(Makefile)\u30b3\u30de\u30f3\u30c9\u96c6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 up : docker-compose up -d build : docker-compose build create-project : docker-compose up -d --build docker-compose exec app composer create-project --prefer-dist laravel/laravel . docker-compose exec app composer require predis/predis install : docker-compose up -d --build docker-compose exec app composer install docker-compose exec app cp .env.example .env docker-compose exec app php artisan key:generate docker-compose exec app php artisan migrate:fresh --seed reinstall : @make destroy @make install stop : docker-compose stop restart : docker-compose down docker-compose up -d down : docker-compose down destroy : docker-compose down --rmi all --volumes ps : docker-compose ps app : docker-compose exec app bash fresh : docker-compose exec app php artisan migrate:fresh --seed seed : docker-compose exec app php artisan db:seed tinker : docker-compose exec app php artisan tinker dump : docker-compose exec app php artisan dump-server test : docker-compose exec app php ./vendor/bin/phpunit cache : docker-compose exec app composer dump-autoload -o docker-compose exec app php artisan optimize:clear docker-compose exec app php artisan optimize cache-clear : docker-compose exec app php artisan optimize:clear cs : docker-compose exec app ./vendor/bin/phpcs cbf : docker-compose exec app ./vendor/bin/phpcbf db : docker-compose exec db bash sql : docker-compose exec db bash -c 'mysql -u $$MYSQL_USER -p$$MYSQL_PASSWORD $$MYSQL_DATABASE' node : docker-compose exec node ash npm : docker-compose exec node npm install docker-compose exec node npm run dev yarn : docker-compose exec node yarn docker-compose exec node yarn dev 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 DOCKER_REPOSITORY := shibui/ml-system-in-actions ABSOLUTE_PATH := $( shell pwd ) DOCKERFILE := Dockerfile IMAGE_VERSION := 0 .0.1 WEB_SINGLE_PATTERN := web_single_pattern WEB_SINGLE_PATTERN_PORT := 8000 .PHONY : build build : docker build \\ -t $( DOCKER_REPOSITORY ) : $( WEB_SINGLE_PATTERN ) _ $( IMAGE_VERSION ) \\ -f $( DOCKERFILE ) \\ . .PHONY : run run : docker run \\ -it \\ --name $( WEB_SINGLE_PATTERN ) \\ -p $( WEB_SINGLE_PATTERN_PORT ) : $( WEB_SINGLE_PATTERN_PORT ) \\ $( DOCKER_REPOSITORY ) : $( WEB_SINGLE_PATTERN ) _ $( IMAGE_VERSION ) .PHONY : stop stop : docker rm -f $( WEB_SINGLE_PATTERN ) .PHONY : push push : docker push $( DOCKER_REPOSITORY ) : $( WEB_SINGLE_PATTERN ) _ $( IMAGE_VERSION ) .PHONY : build_all build_all : build .PHONY : run_all run_all : run .PHONY : push_all push_all : push","title":"docker makefile"},{"location":"linux_command/","text":"Linux \u00b6 \u30ea\u30f3\u30af \u00b6 https://dotinstall.com/lessons/basic_unix_v2 https://prog-8.com/courses/commandline https://uguisu.skr.jp/Windows/ \u201c\u5fdc\u7528\u529b\u201d\u3092\u3064\u3051\u308b\u305f\u3081\u306e Linux \u518d\u5165\u9580 Linux \u8a2d\u5b9a\u95a2\u9023 \u00b6 \u30b7\u30a7\u30eb\u306e Alias \u306e\u8a2d\u5b9a \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # \u3088\u304f\u5229\u7528\u3059\u308b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u982d\u6587\u5b57\u306e\u9023\u7d50 alias abc = 'cd ~/aaa/bbb/ccc' alias g = 'git' alias ga = 'git add' alias gd = 'git diff' alias gs = 'git status' alias gp = 'git push' alias gb = 'git branch' alias gst = 'git status' alias gco = 'git checkout' alias gf = 'git fetch' alias gc = 'git commit' alias cp = 'cp -i' alias mv = 'mv -i' alias rm = 'rm -i' alias hg = 'history | grep' alias tma = 'tmux a -t' alias tmn = 'tmux new-session -s' # u \u304a\u3059\u3059\u3081.vimrc \u00b6 1 2 3 4 5 6 7 8 9 10 11 set number set expandtab set hlsearch set ignorecase set incsearch set smartcase set laststatus=2 set nocompatible set clipboard=unnamed,autoselect set clipboard& clipboard^=unnamedplus syntax on .netrc \u306e\u66f8\u304d\u65b9 \u00b6 1 2 3 4 5 6 7 machine api.wandb.ai login user password **** machine github.com login your_username password *** Linux \u30b3\u30de\u30f3\u30c9 \u00b6 \u53c2\u8003\u30ea\u30f3\u30af \u00b6 https://atmarkit.itmedia.co.jp/ait/articles/1906/05/news004.html https://qiita.com/nmrmsys/items/03f97f5eabec18a3a18b https://qiita.com/arene-calix/items/41d8d4ba572f1d652727 https://qiita.com/savaniased/items/d2c5c699188a0f1623ef https://tech-blog.rakus.co.jp/entry/20210604/linux https://pg-happy.jp/linux-command.html \u30d5\u30a1\u30a4\u30eb\u30fb\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u95a2\u9023 \u00b6 pwd (print working directory) \u00b6 1 2 3 # pwd: \u4eca\u3044\u308b\u30d5\u30a9\u30eb\u30c0\u306e\u7d76\u5bfe\u30d1\u30b9\u3092\u8868\u793a yseeker@~/Desktop $ pwd /home/yseeker/Desktop ls (list) \u00b6 1 2 3 4 5 6 7 ls -alh ls -ltr # -a: \u96a0\u3057\u30d5\u30a1\u30a4\u30eb\u3082\u8868\u793a(\u7531\u6765: all) # -l: \u8a73\u7d30\u306a\u60c5\u5831\u3092\u8868\u793a # -h: M(\u30e1\u30ac)\u3001G(\u30ae\u30ac)\u306a\u3069\u3092\u4ed8\u3051\u3066\u30b5\u30a4\u30ba\u3092\u898b\u3084\u3059\u304f\u3059\u308b(\u7531\u6765:human readable) # -t: \u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u9806\u3067\u8868\u793a(\u7531\u6765: time) # -r: \u9006\u9806\u3067\u8868\u793a(\u7531\u6765: reverse) cd (change directory) \u00b6 1 cd - #\u76f4\u524d\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u79fb\u52d5 mkdir (make directory) \u00b6 1 mkdir -p aaa/bbb/ccc #\u89aa\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3082\u4f5c\u6210 touch \u00b6 \u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\u3001\u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u66f4\u65b0 files \u00b6 file \u306e\u60c5\u5831\u3092\u78ba\u8a8d\u3067\u304d\u308b\u3002 mv \u00b6 \u30d5\u30a1\u30a4\u30eb\u306e\u79fb\u52d5\u3001\u540d\u524d\u5909\u66f4 cp \u00b6 1 2 3 4 # cp -r source/path destination/path: \u30d5\u30a1\u30a4\u30eb\u3084\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u30b3\u30d4\u30fc # * -r: \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u4ee5\u4e0b\u3092\u518d\u5e30\u7684\u306b\u30b3\u30d4\u30fc(ecursive) # * -f: \u78ba\u8a8d\u7121\u3057\u3067\u5f37\u5236\u30b3\u30d4\u30fc(force) # * -p: \u30b3\u30d4\u30fc\u524d\u5f8c\u3067\u30d1\u30fc\u30df\u30c3\u30b7\u30e7\u30f3\u3092\u4fdd\u6301(permission) rm \u00b6 1 2 3 4 5 6 # rm -rf directory_name: \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u524a\u9664 # * -f: \u78ba\u8a8d\u7121\u3057\u3067\u5f37\u5236\u30b3\u30d4\u30fc(\u7531\u6765: force) # * -r: \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u4ee5\u4e0b\u3092\u518d\u5e30\u7684\u306b\u524a\u9664(\u7531\u6765: recursive) $ rm -f *.txt # \u30ef\u30a4\u30eb\u30c9\u30ab\u30fc\u30c9(*)\u3092\u4f7f\u3063\u3066txt\u30d5\u30a1\u30a4\u30eb\u3092\u5168\u524a\u9664 $ rm -rf dir* # \u30ef\u30a4\u30eb\u30c9\u30ab\u30fc\u30c9(*)\u3092\u4f7f\u3063\u3066\u4e00\u62ec\u524a\u9664 tar \u00b6 1 2 3 4 5 # tar -czvf xxx.tgz file1 file2 dir1 : \u5727\u7e2e(file1 file2 dir1\u3092\u30a2\u30fc\u30ab\u30a4\u30d6\u3057\u305f\u5727\u7e2e\u30d5\u30a1\u30a4\u30ebxxx.tgz\u3092\u4f5c\u6210) # tar -tzvf xxx.tgz: \u5727\u7e2e\u30d5\u30a1\u30a4\u30eb\u306b\u542b\u307e\u308c\u308b\u30d5\u30a1\u30a4\u30eb\u540d\u3092\u8868\u793a(=\u5c55\u958b\u306e\u30c6\u30b9\u30c8) # tar -xzvf xxx.tgz: \u5c55\u958b # * c(create), t(test), x(extract) + zvf\u3068\u899a\u3048\u308b tar czvf something.tgz dir* file* zip, unzip \u00b6 1 2 3 $ zip -r \u00abZIP\u30d5\u30a1\u30a4\u30eb\u540d\u00bb \u00ab\u5bfe\u8c61\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u00bb $ tar cvzf \u00abTARGZ\u30d5\u30a1\u30a4\u30eb\u540d\u00bb \u00ab\u5bfe\u8c61\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u00bb unzip -q foo.zip -d bar ln \u00b6 1 2 # \u30b7\u30f3\u30dc\u30ea\u30c3\u30af\u30ea\u30f3\u30af\u306e\u4f5c\u6210 ln -s oroginal_file symbolic_link \u30c6\u30ad\u30b9\u30c8\u51e6\u7406 \u00b6 cat (concatenate) \u00b6 1 2 access.log error1.log error2.log $ cat error*.log # error1.log\u3068error2.log\u3092\u307e\u3068\u3081\u3066\u78ba\u8a8d tail \u00b6 1 2 3 4 5 # \u91cd\u305f\u3044\u30ed\u30b0\u30d5\u30a1\u30a4\u30eb\u306e\u6700\u5f8c\u306e\u65b9\u3060\u3051\u898b\u308b tail -n 3 file1.txt 11 kkk KKK 12 lll LLL 13 mmm MMM less \u00b6 1 2 3 4 5 6 7 8 9 10 # less file1: file1\u3092\u898b\u308b(read only) cat file1 | cmd1 | cmd2 | less: file1\u3092\u3044\u308d\u3044\u308d\u52a0\u5de5\u3057\u305f\u7d50\u679c\u3092\u898b\u308b # command | less - # grep 080 testData | less -N less +F output # * \u30bf\u30fc\u30df\u30ca\u30eb\u306b\u51fa\u529b\u305b\u305a\u3001\u4f55\u304b\u3092\u898b\u305f\u3044\u3068\u304d\u306b\u3068\u308a\u3042\u3048\u305a\u4f7f\u3046\u30b3\u30de\u30f3\u30c9 # gg: \u5148\u982d\u884c\u3078\u79fb\u52d5 # G: \u6700\u7d42\u884c\u3078\u79fb\u52d5 # /pattern: pattern\u3067\u30d5\u30a1\u30a4\u30eb\u5185\u691c\u7d22 # q: \u9589\u3058\u308b wc (word count) \u00b6 1 2 3 4 5 6 7 8 $ wc -l error.log # \u884c\u6570\u30ab\u30a6\u30f3\u30c8(1) 7 error.log # \u30d5\u30a1\u30a4\u30eb\u6570\u30ab\u30a6\u30f3\u30c8 ls | wc -w ls -U1 | wc -l find . -name \"*.jpg\" | wc -l ls -F | grep -v / | wc -l sort, uniq \u00b6 1 2 3 4 5 6 7 # sort file1: file1\u3092\u884c\u5358\u4f4d\u3067\u30bd\u30fc\u30c8 # uniq file1: file1\u306e\u91cd\u8907\u696d\u3092\u524a\u9664 # cat file1 | sort | uniq: file1\u3092\u30bd\u30fc\u30c8\u3057\u3066\u3001\u91cd\u8907\u696d\u3092\u6392\u9664 # * sort\u3068uniq\u306f\u30ef\u30f3\u30bb\u30c3\u30c8\u7684\u306a\u3068\u3053\u308d\u304c\u3042\u308b\u306e\u3067\u307e\u3068\u3081\u3066\u7d39\u4ecb # # * sort\u306f-r\u3067\u9006\u9806\u30bd\u30fc\u30c8\u3001-R\u3067\u30e9\u30f3\u30c0\u30e0\u30bd\u30fc\u30c8\u3001\u307f\u305f\u3044\u306b\u7d50\u69cb\u30aa\u30d7\u30b7\u30e7\u30f3\u304c\u591a\u5f69 # * ls -l\u306e\u5b9f\u884c\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u30b5\u30a4\u30ba\u9806\u3067sort\u3059\u308b\u3001\u307f\u305f\u3044\u306b grep \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # grep ERROR *.log: \u62e1\u5f35\u5b50\u304clog\u306e\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u3001ERROR\u3092\u542b\u3080\u884c\u3060\u3051\u62bd\u51fa # cat error.log | grep ERROR: error.log\u304b\u3089ERROR\u3092\u542b\u3080\u884c\u3060\u3051\u62bd\u51fa # cat error.log | grep -2 ERROR: error.log\u304b\u3089ERROR\u3092\u542b\u3080\u884c\u3068\u305d\u306e\u524d\u5f8c2\u884c\u3092\u51fa\u529b # cat error.log | grep -e ERROR -e WARN: error.log\u304b\u3089ERROR\u307e\u305f\u306fWARN\u3092\u542b\u3080\u884c\u3092\u62bd\u51fa # cat error.log | grep ERROR | grep -v 400: error.log\u304b\u3089ERROR\u3092\u542b\u3080\u884c\u3092\u62bd\u51fa\u3057\u3066\u3001400\u3092\u542b\u3080\u884c\u3092\u6392\u9664\u3057\u305f\u7d50\u679c\u3092\u8868\u793a # * -e: \u8907\u6570\u30ad\u30fc\u30ef\u30fc\u30c9\u3092AND\u6761\u4ef6\u3067\u6307\u5b9a(\u7531\u6765: ?? \u305f\u3076\u3093\u9055\u3046\u3051\u3069\u3001\u500b\u4eba\u7684\u306b\u306f\u30d5\u30e9\u30f3\u30b9\u8a9e\u306eet(=and)\u3060\u3068\u89e3\u91c8\u3057\u3066\u308b) # * -v: \u30ad\u30fc\u30ef\u30fc\u30c9\u3092\u542b\u3080\u884c\u3092\u6392\u9664(\u7531\u6765: verbose??) # \u3069\u306e\u30d5\u30a1\u30a4\u30eb\u304b\u5206\u304b\u3089\u306a\u3044\u3051\u3069\u3001Hoge\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u914d\u4e0b\u3067\u3001piyo\u3068\u3044\u3046\u6587\u5b57\u5217\u3092\u542b\u3093\u3067\u3044\u308b\u90e8\u5206\u3068\u305d\u306e\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u3092\u77e5\u308a\u305f\u3044 find ~/Hoge -name '*.txt' | xargs grep piyo $ pgrep -f vagrant # \u59cb\u672b $ pkill -f vagrant # \u30b7\u30b0\u30ca\u30eb\u3092\u6307\u5b9a $ pkill -SIGKILL -f vagrant https://qiita.com/uraura/items/12ff6112fd392f1be424 find \u00b6 1 2 3 4 5 6 7 8 9 10 # find dir1 -type f: dir1\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u4e00\u89a7\u3092\u8868\u793a # find dir1 -type f -name \"*.js\": dir1\u4ee5\u4e0b\u306ejs\u30d5\u30a1\u30a4\u30eb\u306e\u4e00\u89a7\u3092\u8868\u793a # find dir1 -type d: dir1\u4ee5\u4e0b\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u4e00\u89a7\u3092\u8868\u793a # * ls\u3068\u9055\u3063\u3066\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u304c\u51fa\u529b\u3055\u308c\u308b\u305f\u3081\u3001find xxx | xargs rm -rf \u307f\u305f\u3044\u306b\u4e00\u62ec\u64cd\u4f5c\u306b\u5411\u3044\u3066\u3044\u308b $ find src/ -type f find . -name '*.php' find . -name '???.txt' find . -name \"*.jpg\" | wc -l https://uguisu.skr.jp/Windows/find_xargs2.html sed \u00b6 1 2 3 4 5 6 7 # cat file1 | sed 's/BEFORE/AFTER/g': file1\u4e2d\u306eBEFORE\u3092AFTER\u306b\u4e00\u62ec\u7f6e\u63db # * s/BEFORE/AFTER/g: BEFORE\u3092AFTER\u306b\u7f6e\u63db(\u7531\u6765: substitute\u3068global?) #\u30b5\u30d6\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u542b\u3081\u305f\u6587\u5b57\u5217\u306e\u4e00\u62ec\u5909\u63db find ./ -name '*.php' -exec sed -i 's/TYPO/TYPE/g' {} \\; find ./ -name '*.php' -exec sed -i 's/TYPO/TYPE/g' {} + find ./ -type f | xargs sed -i \"s/hoge/fuga/g\" xargs \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 # cmd1 | xargs cmd2: cmd1\u306e\u5b9f\u884c\u7d50\u679c\u3092\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u5f15\u6570\u3068\u3057\u3066\u53d7\u3051\u53d6\u3063\u3066\u3001cmd2\u3092\u5b9f\u884c find . -name \"*.log\" | xargs rm -fv find TARGET -type d -empty | xargs rm -r find . -name \"*.log\" | xargs -i cp {} /tmp/. #\u6587\u5b57\u5217\u5909\u63db grep -rl 'hogehoge' ./* | xargs perl -i -pe \"s/hogehoge/fugafuga/g\" #100\u30d5\u30a1\u30a4\u30eb\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u9078\u3093\u3067\u30b3\u30d4\u30fc\uff0e find /some/dir -type f -name \"*.jpg\" | shuf -n 100 | xargs cp -vt /target/dir/ #\u691c\u7d22\u3057\u3066\u898b\u3064\u304b\u3063\u305f\u30d5\u30a1\u30a4\u30eb\u306e\u79fb\u52d5 find . -type f -print0 | xargs -0 mv -t /var/tmp/ https://uguisu.skr.jp/Windows/find_xargs2.html <, \uff06> , >> (\u30ea\u30c0\u30a4\u30ec\u30af\u30c8) \u00b6 https://hibiki-press.tech/dev-env/redirect_pipline/1571 1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ echo \"4 ddd DDD\" >> file1.txt # \u30ea\u30c0\u30a4\u30ec\u30af\u30c8(\u8ffd\u8a18) $ cat file1.txt $ echo \"4 ddd DDD\" > file1.txt # \u30ea\u30c0\u30a4\u30ec\u30af\u30c8(\u4e0a\u66f8\u304d) #Python\u30b9\u30af\u30ea\u30d7\u30c8\u3078\u306e\u5165\u529b\u3092\u30d5\u30a1\u30a4\u30ebinput_data\u3078\u5909\u66f4\u3057\u3001 #\u5b9f\u884c\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30ebresult01\u306b\u51fa\u529b $ python3 sample02.py < input_data > result01 \u30a8\u30e9\u30fc\u51fa\u529b\u3082\u66f8\u304f python test.py & > output #sample02.py\u306e\u5b9f\u884c\u7d50\u679c\u3068\u30a8\u30e9\u30fc\u51fa\u529b\u3092\u30d5\u30a1\u30a4\u30ebresult02\u306b\u51fa\u529b $ python3 sample02.py > result02 2 > & 1 \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb \u00b6 echo \u00b6 1 2 3 # echo abc: \u6587\u5b57\u5217abc\u3092\u51fa\u529b # echo $PATH: \u74b0\u5883\u5909\u6570PATH\u3092\u51fa\u529b # print\u3068\u4e00\u7dd2 env \u00b6 1 2 # env | less: \u74b0\u5883\u5909\u6570\u3092\u78ba\u8a8d # * env\u3060\u3051\u3067\u3082\u898b\u308c\u308b\u304c\u3001\u74b0\u5883\u5909\u6570\u304c\u591a\u3044\u5834\u5408\u898b\u5207\u308c\u3066\u3057\u307e\u3046\u305f\u3081less\u3067\u78ba\u8a8d which \u00b6 1 # which cmd: cmd\u306e\u5b9f\u4f53\u304c\u7f6e\u304b\u308c\u3066\u3044\u308b\u5834\u6240\u3092\u8868\u793a source \u00b6 1 2 3 # source ~/.bashrc: .bashrc\u3092\u518d\u8aad\u307f\u8fbc\u307f # . ~/.bashrc: \u2191\u3068\u540c\u3058(.\u306fsource\u306e\u30a8\u30a4\u30ea\u30a2\u30b9) # * \u30b7\u30a7\u30eb\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3092\u5909\u66f4\u3057\u305f\u5f8c\u306e\u518d\u8aad\u307f\u8fbc\u307f\u3067\u4f7f\u3046\u30b1\u30fc\u30b9\u304c100% chmod \u00b6 1 2 3 chmod 755 *.sh #sh\u30d5\u30a1\u30a4\u30eb\u306b\u5b9f\u884c\u6a29\u9650\u3092\u4ed8\u4e0e chmod 644 *.js #js\u30d5\u30a1\u30a4\u30eb\u3092\u666e\u901a\u306b\u8aad\u307f\u66f8\u304d\u3067\u304d\u308b\u8a2d\u5b9a\u306b\u3059\u308b chmod ugo+rwx -R /* OS \u95a2\u9023 \u00b6 df \u00b6 1 2 # df -h: \u30c7\u30a3\u30b9\u30af\u306e\u4f7f\u7528\u91cf/\u7a7a\u304d\u5bb9\u91cf\u3092\u5358\u4f4d\u4ed8\u304d\u3067\u8868\u793a(\u7531\u6765: human readable) # df: \u30c7\u30a3\u30b9\u30af\u306e\u4f7f\u7528\u91cf/\u7a7a\u304d\u5bb9\u91cf\u3092\u8868 du \u00b6 1 2 3 4 5 # du -h: \u5404\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u5bb9\u91cf\u3092\u5358\u4f4d\u4ed8\u304d\u3067\u8868\u793a(\u7531\u6765: human readable) # \u30ab\u30ec\u30f3\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u5bb9\u91cf\u3092\u8868\u793a\uff0e\u6df1\u30551 du -h -d1 . du -h -d 1 | sort -h free \u00b6 1 free -h #\u30e1\u30e2\u30ea\u4f7f\u7528\u72b6\u6cc1\u3092\u5358\u4f4d\u4ed8\u304d\u3067\u8868\u793a(\u7531\u6765: human readable) top, ps, kill \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 top #CPU\u3084\u30e1\u30e2\u30ea\u306e\u4f7f\u7528\u72b6\u6cc1\u3092\u78ba\u8a8d # * \u30c7\u30d5\u30a9\u30eb\u30c8\u3060\u3068CPU\u4f7f\u7528\u7387\u306e\u591a\u3044\u30d7\u30ed\u30bb\u30b9\u304c\u4e0a\u306b\u6765\u308b # * %CPU\u304cCPU\u4f7f\u7528\u7387\u3002\u3069\u306e\u30d7\u30ed\u30bb\u30b9\u304c\u9ad8\u8ca0\u8377\u304b\u3092\u78ba\u8a8d\u3067\u304d\u308b\u3002 ps -ef #\u5168\u3066\u306e\u30d7\u30ed\u30bb\u30b9\u306e\u8a73\u7d30\u306a\u60c5\u5831\u3092\u898b\u308b(\u7531\u6765: every, full) # * \u7528\u90141: \u3042\u308b\u30d7\u30ed\u30bb\u30b9\u304c\u751f\u304d\u3066\u308b\u304b\u3069\u3046\u304b\u30c1\u30a7\u30c3\u30af (web\u30b5\u30fc\u30d0\u8d77\u52d5\u3057\u3066\u308b?) # * \u7528\u90142: \u3042\u308b\u30d7\u30ed\u30bb\u30b9\u306ePID(\u30d7\u30ed\u30bb\u30b9ID)\u3092\u30c1\u30a7\u30c3\u30af -> kill ${PID} ps aux # kill 123: \u30d7\u30ed\u30bb\u30b9ID\u304c123\u306e\u30d7\u30ed\u30bb\u30b9\u3092\u505c\u6b62\u3055\u305b\u308b(SIGTERM\u3092\u9001\u308b) # kill -9 123: \u30d7\u30ed\u30bb\u30b9ID\u304c123\u306e\u30d7\u30ed\u30bb\u30b9\u3092\u554f\u7b54\u7121\u7528\u3067\u6bba\u3059(9\u306fSIGKILL\u306e\u30b7\u30b0\u30ca\u30eb\u756a\u53f7) # kill -KILL 123: -9\u3068\u540c\u3058 kill -9 [ \u756a\u53f7 ] # pkill process_name_prefix: process_name_prefix\u3067\u59cb\u307e\u308b\u30d7\u30ed\u30bb\u30b9\u3059\u3079\u3066\u3092\u7d42\u4e86\u3055\u305b\u308b # pkill -9 process_name_prefix: process_name_prefix\u3067\u59cb\u307e\u308b\u30d7\u30ed\u30bb\u30b9\u3059\u3079\u3066\u3092\u554f\u7b54\u7121\u7528\u3067\u7d42\u4e86\u3055\u305b\u308b \u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u5b9f\u884c \u00b6 1 2 3 4 5 6 7 8 cmd1 #cmd1\u3092\u30d5\u30a9\u30a2\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u5b9f\u884c cmd1 & #cmd1\u3092\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u5b9f\u884c #\u30d5\u30a9\u30a2\u30b0\u30e9\u30a6\u30f3\u30c9 \u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u306b\u5207\u308a\u66ff\u3048 jobs #job\u756a\u53f7\u3092\u8abf\u3079\u308b fg %1 bg %1 \u306b\u5207\u308a\u66ff\u3048 # * \u91cd\u305f\u3044\u30d0\u30c3\u30c1\u51e6\u7406\u3084\u3001\u4e00\u6642\u7684\u306bweb\u30b5\u30fc\u30d0\u3092\u52d5\u304b\u3057\u305f\u3044\u3068\u304d\u306f\u3001 # \u30b3\u30de\u30f3\u30c9\u3092\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u5b9f\u884c\u3059\u308b\u3068\u4fbf\u5229 &&, || \u00b6 1 2 3 4 # cmd1 && cmd2: cmd1\u304c\u6210\u529f\u3057\u305f\u3089\u3001cmd2\u3092\u5b9f\u884c(cmd1\u304c\u5931\u6557\u3057\u305f\u3089\u305d\u3053\u3067\u7d42\u308f\u308a) # cmd1 || cmd2: cmd1\u304c\u5931\u6557\u3057\u305f\u3089\u3001cmd2\u3092\u5b9f\u884c(cmd1\u304c\u6210\u529f\u3057\u305f\u3089\u305d\u3053\u3067\u7d42\u308f\u308a) # * \u7528\u90141: \u30ef\u30f3\u30e9\u30a4\u30ca\u30fc\u3067\u3061\u3087\u3063\u3068\u3057\u305f\u9010\u6b21\u51e6\u7406\u3092\u66f8\u304f # * \u7528\u90142: cmd1 || echo \"error message\" \u30ea\u30e2\u30fc\u30c8 \u00b6 ssh \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 # -i : \u9375\u30d5\u30a1\u30a4\u30eb # -L: \u30dd\u30fc\u30c8\u30d5\u30a9\u30ef\u30fc\u30c7\u30a3\u30f3\u30b0 ssh -L <host port>:localhost:<remote port> user@remote #https://qiita.com/wnoguchi/items/a72a042bb8159c35d056 # ECDSA521 bit ssh-keygen -t ecdsa -b 521 -C \"wnoguchi-mbp\" # Ed25519 ssh-keygen -t ed25519 -P \"\" -f serial-server.pem ssh-keygen -t ed25519 cat public_key >> ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys scp \u00b6 1 2 # -i : \u9375\u30d5\u30a1\u30a4\u30eb # -r : \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u79fb\u52d5 useful commands \u00b6 \u5bb9\u91cf\u306e\u5927\u304d\u3044\u30d5\u30a1\u30a4\u30eb\u306e\u7279\u5b9a \u00b6 \u4f7f\u7528\u91cf\u304c\u591a\u3044\u9806\u306b 5 \u4ef6\u3092\u53d6\u5f97\u3059\u308b 1 du -sm ./* | sort -rn | head -5 \u5bb9\u91cf\u3092\u304f\u3063\u3066\u308b\u30d9\u30b9\u30c8 100 1 du -ma | sort -rn | head -100 \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u307f\u3092\u691c\u7d22\u3059\u308b\u5834\u5408 1 du -m | sort -rn | head -100 30 \u65e5\u9593\u7de8\u96c6\u304c\u306a\u3044\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u30b5\u30a4\u30ba\u9806\u3067\u8868\u793a 1 find ./ -mtime +30 -prune -exec du -sh {} \\;|sort -hr \u30ab\u30ec\u30f3\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u5bb9\u91cf\u3092\u8868\u793a\uff0e\u6df1\u3055 1\uff0e 1 du -h -d1 . 100 \u30d5\u30a1\u30a4\u30eb\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u9078\u3093\u3067\u30b3\u30d4\u30fc\uff0e 1 find /some/dir -type f -name \"*.jpg\" | shuf -n 100 | xargs cp -vt /target/dir/ tgt_dir \u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3092\u5229\u7528\u3057\u3066\u3001src_dir \u304b\u3089 dst_fir \u3078\u3068\u30d5\u30a1\u30a4\u30eb\u3092\u79fb\u52d5 1 ls tgt_dir | while read name; do mv src_dir/${name:0:-4}* dst_dir/; done tmux \u00b6 https://golang.hateblo.jp/entry/2019/10/11/133000 https://qiita.com/nmrmsys/items/03f97f5eabec18a3a18b 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # \u65b0\u898f\u30bb\u30c3\u30b7\u30e7\u30f3\u958b\u59cb tmux # \u540d\u524d\u3092\u3064\u3051\u3066\u65b0\u898f\u30bb\u30c3\u30b7\u30e7\u30f3\u958b\u59cb tmux new -s <\u30bb\u30c3\u30b7\u30e7\u30f3\u540d> # \u30bb\u30c3\u30b7\u30e7\u30f3\u306e\u4e00\u89a7\u8868\u793a tmux ls # \u63a5\u7d9a\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306e\u4e00\u89a7\u8868\u793a tmux lsc # \u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u518d\u958b \u203b-t <\u5bfe\u8c61\u30bb\u30c3\u30b7\u30e7\u30f3\u540d>\u3067\u30bb\u30c3\u30b7\u30e7\u30f3\u540d\u306e\u6307\u5b9a\u3082\u53ef\u80fd tmux a -t [ session-name ] # \u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u7d42\u4e86 \u203b-t <\u5bfe\u8c61\u30bb\u30c3\u30b7\u30e7\u30f3\u540d>\u3067\u30bb\u30c3\u30b7\u30e7\u30f3\u540d\u306e\u6307\u5b9a\u3082\u53ef\u80fd tmux kill-session -t [ session-name ] # tmux\u5168\u4f53\u3092\u7d42\u4e86 tmux kill-server # \u305d\u306e\u4ed6\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c tmux [ command [ flags ]] ctrl-b c : \u65b0\u3057\u3044\u30a6\u30a4\u30f3\u30c9\u30a6\u3092\u8ffd\u52a0 ctrl-b b : \u30a6\u30a4\u30f3\u30c9\u30a6\u3092\u79fb\u52d5 ctrl-b & : \u30a2\u30af\u30c6\u30a3\u30d6\u306a\u30a6\u30a3\u30f3\u30c9\u30a6\u3092\u524a\u9664 ctrl-b % : \u5de6\u53f3\u306e\u30da\u30a4\u30f3\u306b\u79fb\u52d5 ctrl-b \" : \u4e0a\u4e0b\u306e\u30da\u30a4\u30f3\u306b\u79fb\u52d5 : ctrl-b o or \u30ab\u30fc\u30bd\u30eb\uff1a\u30da\u30a4\u30f3\u9593\u306e\u79fb\u52d5 ctrl-b x : \u30da\u30a4\u30f3\u5206\u5272\u306e\u89e3\u9664 ctrl-b d: detach gunicorn, uvicorn \u00b6","title":"Linux"},{"location":"linux_command/#linux","text":"","title":"Linux"},{"location":"linux_command/#_1","text":"https://dotinstall.com/lessons/basic_unix_v2 https://prog-8.com/courses/commandline https://uguisu.skr.jp/Windows/ \u201c\u5fdc\u7528\u529b\u201d\u3092\u3064\u3051\u308b\u305f\u3081\u306e Linux \u518d\u5165\u9580","title":"\u30ea\u30f3\u30af"},{"location":"linux_command/#linux_1","text":"","title":"Linux \u8a2d\u5b9a\u95a2\u9023"},{"location":"linux_command/#alias","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # \u3088\u304f\u5229\u7528\u3059\u308b\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u982d\u6587\u5b57\u306e\u9023\u7d50 alias abc = 'cd ~/aaa/bbb/ccc' alias g = 'git' alias ga = 'git add' alias gd = 'git diff' alias gs = 'git status' alias gp = 'git push' alias gb = 'git branch' alias gst = 'git status' alias gco = 'git checkout' alias gf = 'git fetch' alias gc = 'git commit' alias cp = 'cp -i' alias mv = 'mv -i' alias rm = 'rm -i' alias hg = 'history | grep' alias tma = 'tmux a -t' alias tmn = 'tmux new-session -s' # u","title":"\u30b7\u30a7\u30eb\u306e Alias \u306e\u8a2d\u5b9a"},{"location":"linux_command/#vimrc","text":"1 2 3 4 5 6 7 8 9 10 11 set number set expandtab set hlsearch set ignorecase set incsearch set smartcase set laststatus=2 set nocompatible set clipboard=unnamed,autoselect set clipboard& clipboard^=unnamedplus syntax on","title":"\u304a\u3059\u3059\u3081.vimrc"},{"location":"linux_command/#netrc","text":"1 2 3 4 5 6 7 machine api.wandb.ai login user password **** machine github.com login your_username password ***","title":".netrc \u306e\u66f8\u304d\u65b9"},{"location":"linux_command/#linux_2","text":"","title":"Linux \u30b3\u30de\u30f3\u30c9"},{"location":"linux_command/#_2","text":"https://atmarkit.itmedia.co.jp/ait/articles/1906/05/news004.html https://qiita.com/nmrmsys/items/03f97f5eabec18a3a18b https://qiita.com/arene-calix/items/41d8d4ba572f1d652727 https://qiita.com/savaniased/items/d2c5c699188a0f1623ef https://tech-blog.rakus.co.jp/entry/20210604/linux https://pg-happy.jp/linux-command.html","title":"\u53c2\u8003\u30ea\u30f3\u30af"},{"location":"linux_command/#_3","text":"","title":"\u30d5\u30a1\u30a4\u30eb\u30fb\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u95a2\u9023"},{"location":"linux_command/#pwd-print-working-directory","text":"1 2 3 # pwd: \u4eca\u3044\u308b\u30d5\u30a9\u30eb\u30c0\u306e\u7d76\u5bfe\u30d1\u30b9\u3092\u8868\u793a yseeker@~/Desktop $ pwd /home/yseeker/Desktop","title":"pwd (print working directory)"},{"location":"linux_command/#ls-list","text":"1 2 3 4 5 6 7 ls -alh ls -ltr # -a: \u96a0\u3057\u30d5\u30a1\u30a4\u30eb\u3082\u8868\u793a(\u7531\u6765: all) # -l: \u8a73\u7d30\u306a\u60c5\u5831\u3092\u8868\u793a # -h: M(\u30e1\u30ac)\u3001G(\u30ae\u30ac)\u306a\u3069\u3092\u4ed8\u3051\u3066\u30b5\u30a4\u30ba\u3092\u898b\u3084\u3059\u304f\u3059\u308b(\u7531\u6765:human readable) # -t: \u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u9806\u3067\u8868\u793a(\u7531\u6765: time) # -r: \u9006\u9806\u3067\u8868\u793a(\u7531\u6765: reverse)","title":"ls (list)"},{"location":"linux_command/#cd-change-directory","text":"1 cd - #\u76f4\u524d\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306b\u79fb\u52d5","title":"cd (change directory)"},{"location":"linux_command/#mkdir-make-directory","text":"1 mkdir -p aaa/bbb/ccc #\u89aa\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3082\u4f5c\u6210","title":"mkdir (make directory)"},{"location":"linux_command/#touch","text":"\u30d5\u30a1\u30a4\u30eb\u306e\u4f5c\u6210\u3001\u30bf\u30a4\u30e0\u30b9\u30bf\u30f3\u30d7\u66f4\u65b0","title":"touch"},{"location":"linux_command/#files","text":"file \u306e\u60c5\u5831\u3092\u78ba\u8a8d\u3067\u304d\u308b\u3002","title":"files"},{"location":"linux_command/#mv","text":"\u30d5\u30a1\u30a4\u30eb\u306e\u79fb\u52d5\u3001\u540d\u524d\u5909\u66f4","title":"mv"},{"location":"linux_command/#cp","text":"1 2 3 4 # cp -r source/path destination/path: \u30d5\u30a1\u30a4\u30eb\u3084\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u30b3\u30d4\u30fc # * -r: \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u4ee5\u4e0b\u3092\u518d\u5e30\u7684\u306b\u30b3\u30d4\u30fc(ecursive) # * -f: \u78ba\u8a8d\u7121\u3057\u3067\u5f37\u5236\u30b3\u30d4\u30fc(force) # * -p: \u30b3\u30d4\u30fc\u524d\u5f8c\u3067\u30d1\u30fc\u30df\u30c3\u30b7\u30e7\u30f3\u3092\u4fdd\u6301(permission)","title":"cp"},{"location":"linux_command/#rm","text":"1 2 3 4 5 6 # rm -rf directory_name: \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u524a\u9664 # * -f: \u78ba\u8a8d\u7121\u3057\u3067\u5f37\u5236\u30b3\u30d4\u30fc(\u7531\u6765: force) # * -r: \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u4ee5\u4e0b\u3092\u518d\u5e30\u7684\u306b\u524a\u9664(\u7531\u6765: recursive) $ rm -f *.txt # \u30ef\u30a4\u30eb\u30c9\u30ab\u30fc\u30c9(*)\u3092\u4f7f\u3063\u3066txt\u30d5\u30a1\u30a4\u30eb\u3092\u5168\u524a\u9664 $ rm -rf dir* # \u30ef\u30a4\u30eb\u30c9\u30ab\u30fc\u30c9(*)\u3092\u4f7f\u3063\u3066\u4e00\u62ec\u524a\u9664","title":"rm"},{"location":"linux_command/#tar","text":"1 2 3 4 5 # tar -czvf xxx.tgz file1 file2 dir1 : \u5727\u7e2e(file1 file2 dir1\u3092\u30a2\u30fc\u30ab\u30a4\u30d6\u3057\u305f\u5727\u7e2e\u30d5\u30a1\u30a4\u30ebxxx.tgz\u3092\u4f5c\u6210) # tar -tzvf xxx.tgz: \u5727\u7e2e\u30d5\u30a1\u30a4\u30eb\u306b\u542b\u307e\u308c\u308b\u30d5\u30a1\u30a4\u30eb\u540d\u3092\u8868\u793a(=\u5c55\u958b\u306e\u30c6\u30b9\u30c8) # tar -xzvf xxx.tgz: \u5c55\u958b # * c(create), t(test), x(extract) + zvf\u3068\u899a\u3048\u308b tar czvf something.tgz dir* file*","title":"tar"},{"location":"linux_command/#zip-unzip","text":"1 2 3 $ zip -r \u00abZIP\u30d5\u30a1\u30a4\u30eb\u540d\u00bb \u00ab\u5bfe\u8c61\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u00bb $ tar cvzf \u00abTARGZ\u30d5\u30a1\u30a4\u30eb\u540d\u00bb \u00ab\u5bfe\u8c61\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u00bb unzip -q foo.zip -d bar","title":"zip, unzip"},{"location":"linux_command/#ln","text":"1 2 # \u30b7\u30f3\u30dc\u30ea\u30c3\u30af\u30ea\u30f3\u30af\u306e\u4f5c\u6210 ln -s oroginal_file symbolic_link","title":"ln"},{"location":"linux_command/#_4","text":"","title":"\u30c6\u30ad\u30b9\u30c8\u51e6\u7406"},{"location":"linux_command/#cat-concatenate","text":"1 2 access.log error1.log error2.log $ cat error*.log # error1.log\u3068error2.log\u3092\u307e\u3068\u3081\u3066\u78ba\u8a8d","title":"cat (concatenate)"},{"location":"linux_command/#tail","text":"1 2 3 4 5 # \u91cd\u305f\u3044\u30ed\u30b0\u30d5\u30a1\u30a4\u30eb\u306e\u6700\u5f8c\u306e\u65b9\u3060\u3051\u898b\u308b tail -n 3 file1.txt 11 kkk KKK 12 lll LLL 13 mmm MMM","title":"tail"},{"location":"linux_command/#less","text":"1 2 3 4 5 6 7 8 9 10 # less file1: file1\u3092\u898b\u308b(read only) cat file1 | cmd1 | cmd2 | less: file1\u3092\u3044\u308d\u3044\u308d\u52a0\u5de5\u3057\u305f\u7d50\u679c\u3092\u898b\u308b # command | less - # grep 080 testData | less -N less +F output # * \u30bf\u30fc\u30df\u30ca\u30eb\u306b\u51fa\u529b\u305b\u305a\u3001\u4f55\u304b\u3092\u898b\u305f\u3044\u3068\u304d\u306b\u3068\u308a\u3042\u3048\u305a\u4f7f\u3046\u30b3\u30de\u30f3\u30c9 # gg: \u5148\u982d\u884c\u3078\u79fb\u52d5 # G: \u6700\u7d42\u884c\u3078\u79fb\u52d5 # /pattern: pattern\u3067\u30d5\u30a1\u30a4\u30eb\u5185\u691c\u7d22 # q: \u9589\u3058\u308b","title":"less"},{"location":"linux_command/#wc-word-count","text":"1 2 3 4 5 6 7 8 $ wc -l error.log # \u884c\u6570\u30ab\u30a6\u30f3\u30c8(1) 7 error.log # \u30d5\u30a1\u30a4\u30eb\u6570\u30ab\u30a6\u30f3\u30c8 ls | wc -w ls -U1 | wc -l find . -name \"*.jpg\" | wc -l ls -F | grep -v / | wc -l","title":"wc (word count)"},{"location":"linux_command/#sort-uniq","text":"1 2 3 4 5 6 7 # sort file1: file1\u3092\u884c\u5358\u4f4d\u3067\u30bd\u30fc\u30c8 # uniq file1: file1\u306e\u91cd\u8907\u696d\u3092\u524a\u9664 # cat file1 | sort | uniq: file1\u3092\u30bd\u30fc\u30c8\u3057\u3066\u3001\u91cd\u8907\u696d\u3092\u6392\u9664 # * sort\u3068uniq\u306f\u30ef\u30f3\u30bb\u30c3\u30c8\u7684\u306a\u3068\u3053\u308d\u304c\u3042\u308b\u306e\u3067\u307e\u3068\u3081\u3066\u7d39\u4ecb # # * sort\u306f-r\u3067\u9006\u9806\u30bd\u30fc\u30c8\u3001-R\u3067\u30e9\u30f3\u30c0\u30e0\u30bd\u30fc\u30c8\u3001\u307f\u305f\u3044\u306b\u7d50\u69cb\u30aa\u30d7\u30b7\u30e7\u30f3\u304c\u591a\u5f69 # * ls -l\u306e\u5b9f\u884c\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30eb\u30b5\u30a4\u30ba\u9806\u3067sort\u3059\u308b\u3001\u307f\u305f\u3044\u306b","title":"sort, uniq"},{"location":"linux_command/#grep","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # grep ERROR *.log: \u62e1\u5f35\u5b50\u304clog\u306e\u30d5\u30a1\u30a4\u30eb\u304b\u3089\u3001ERROR\u3092\u542b\u3080\u884c\u3060\u3051\u62bd\u51fa # cat error.log | grep ERROR: error.log\u304b\u3089ERROR\u3092\u542b\u3080\u884c\u3060\u3051\u62bd\u51fa # cat error.log | grep -2 ERROR: error.log\u304b\u3089ERROR\u3092\u542b\u3080\u884c\u3068\u305d\u306e\u524d\u5f8c2\u884c\u3092\u51fa\u529b # cat error.log | grep -e ERROR -e WARN: error.log\u304b\u3089ERROR\u307e\u305f\u306fWARN\u3092\u542b\u3080\u884c\u3092\u62bd\u51fa # cat error.log | grep ERROR | grep -v 400: error.log\u304b\u3089ERROR\u3092\u542b\u3080\u884c\u3092\u62bd\u51fa\u3057\u3066\u3001400\u3092\u542b\u3080\u884c\u3092\u6392\u9664\u3057\u305f\u7d50\u679c\u3092\u8868\u793a # * -e: \u8907\u6570\u30ad\u30fc\u30ef\u30fc\u30c9\u3092AND\u6761\u4ef6\u3067\u6307\u5b9a(\u7531\u6765: ?? \u305f\u3076\u3093\u9055\u3046\u3051\u3069\u3001\u500b\u4eba\u7684\u306b\u306f\u30d5\u30e9\u30f3\u30b9\u8a9e\u306eet(=and)\u3060\u3068\u89e3\u91c8\u3057\u3066\u308b) # * -v: \u30ad\u30fc\u30ef\u30fc\u30c9\u3092\u542b\u3080\u884c\u3092\u6392\u9664(\u7531\u6765: verbose??) # \u3069\u306e\u30d5\u30a1\u30a4\u30eb\u304b\u5206\u304b\u3089\u306a\u3044\u3051\u3069\u3001Hoge\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u914d\u4e0b\u3067\u3001piyo\u3068\u3044\u3046\u6587\u5b57\u5217\u3092\u542b\u3093\u3067\u3044\u308b\u90e8\u5206\u3068\u305d\u306e\u30c6\u30ad\u30b9\u30c8\u30d5\u30a1\u30a4\u30eb\u3092\u77e5\u308a\u305f\u3044 find ~/Hoge -name '*.txt' | xargs grep piyo $ pgrep -f vagrant # \u59cb\u672b $ pkill -f vagrant # \u30b7\u30b0\u30ca\u30eb\u3092\u6307\u5b9a $ pkill -SIGKILL -f vagrant https://qiita.com/uraura/items/12ff6112fd392f1be424","title":"grep"},{"location":"linux_command/#find","text":"1 2 3 4 5 6 7 8 9 10 # find dir1 -type f: dir1\u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u4e00\u89a7\u3092\u8868\u793a # find dir1 -type f -name \"*.js\": dir1\u4ee5\u4e0b\u306ejs\u30d5\u30a1\u30a4\u30eb\u306e\u4e00\u89a7\u3092\u8868\u793a # find dir1 -type d: dir1\u4ee5\u4e0b\u306e\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u4e00\u89a7\u3092\u8868\u793a # * ls\u3068\u9055\u3063\u3066\u30d5\u30a1\u30a4\u30eb\u30d1\u30b9\u304c\u51fa\u529b\u3055\u308c\u308b\u305f\u3081\u3001find xxx | xargs rm -rf \u307f\u305f\u3044\u306b\u4e00\u62ec\u64cd\u4f5c\u306b\u5411\u3044\u3066\u3044\u308b $ find src/ -type f find . -name '*.php' find . -name '???.txt' find . -name \"*.jpg\" | wc -l https://uguisu.skr.jp/Windows/find_xargs2.html","title":"find"},{"location":"linux_command/#sed","text":"1 2 3 4 5 6 7 # cat file1 | sed 's/BEFORE/AFTER/g': file1\u4e2d\u306eBEFORE\u3092AFTER\u306b\u4e00\u62ec\u7f6e\u63db # * s/BEFORE/AFTER/g: BEFORE\u3092AFTER\u306b\u7f6e\u63db(\u7531\u6765: substitute\u3068global?) #\u30b5\u30d6\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u542b\u3081\u305f\u6587\u5b57\u5217\u306e\u4e00\u62ec\u5909\u63db find ./ -name '*.php' -exec sed -i 's/TYPO/TYPE/g' {} \\; find ./ -name '*.php' -exec sed -i 's/TYPO/TYPE/g' {} + find ./ -type f | xargs sed -i \"s/hoge/fuga/g\"","title":"sed"},{"location":"linux_command/#xargs","text":"1 2 3 4 5 6 7 8 9 10 11 12 # cmd1 | xargs cmd2: cmd1\u306e\u5b9f\u884c\u7d50\u679c\u3092\u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u5f15\u6570\u3068\u3057\u3066\u53d7\u3051\u53d6\u3063\u3066\u3001cmd2\u3092\u5b9f\u884c find . -name \"*.log\" | xargs rm -fv find TARGET -type d -empty | xargs rm -r find . -name \"*.log\" | xargs -i cp {} /tmp/. #\u6587\u5b57\u5217\u5909\u63db grep -rl 'hogehoge' ./* | xargs perl -i -pe \"s/hogehoge/fugafuga/g\" #100\u30d5\u30a1\u30a4\u30eb\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u9078\u3093\u3067\u30b3\u30d4\u30fc\uff0e find /some/dir -type f -name \"*.jpg\" | shuf -n 100 | xargs cp -vt /target/dir/ #\u691c\u7d22\u3057\u3066\u898b\u3064\u304b\u3063\u305f\u30d5\u30a1\u30a4\u30eb\u306e\u79fb\u52d5 find . -type f -print0 | xargs -0 mv -t /var/tmp/ https://uguisu.skr.jp/Windows/find_xargs2.html","title":"xargs"},{"location":"linux_command/#_5","text":"https://hibiki-press.tech/dev-env/redirect_pipline/1571 1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ echo \"4 ddd DDD\" >> file1.txt # \u30ea\u30c0\u30a4\u30ec\u30af\u30c8(\u8ffd\u8a18) $ cat file1.txt $ echo \"4 ddd DDD\" > file1.txt # \u30ea\u30c0\u30a4\u30ec\u30af\u30c8(\u4e0a\u66f8\u304d) #Python\u30b9\u30af\u30ea\u30d7\u30c8\u3078\u306e\u5165\u529b\u3092\u30d5\u30a1\u30a4\u30ebinput_data\u3078\u5909\u66f4\u3057\u3001 #\u5b9f\u884c\u7d50\u679c\u3092\u30d5\u30a1\u30a4\u30ebresult01\u306b\u51fa\u529b $ python3 sample02.py < input_data > result01 \u30a8\u30e9\u30fc\u51fa\u529b\u3082\u66f8\u304f python test.py & > output #sample02.py\u306e\u5b9f\u884c\u7d50\u679c\u3068\u30a8\u30e9\u30fc\u51fa\u529b\u3092\u30d5\u30a1\u30a4\u30ebresult02\u306b\u51fa\u529b $ python3 sample02.py > result02 2 > & 1","title":"&lt;, \uff06&gt; , &gt;&gt; (\u30ea\u30c0\u30a4\u30ec\u30af\u30c8)"},{"location":"linux_command/#_6","text":"","title":"\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb"},{"location":"linux_command/#echo","text":"1 2 3 # echo abc: \u6587\u5b57\u5217abc\u3092\u51fa\u529b # echo $PATH: \u74b0\u5883\u5909\u6570PATH\u3092\u51fa\u529b # print\u3068\u4e00\u7dd2","title":"echo"},{"location":"linux_command/#env","text":"1 2 # env | less: \u74b0\u5883\u5909\u6570\u3092\u78ba\u8a8d # * env\u3060\u3051\u3067\u3082\u898b\u308c\u308b\u304c\u3001\u74b0\u5883\u5909\u6570\u304c\u591a\u3044\u5834\u5408\u898b\u5207\u308c\u3066\u3057\u307e\u3046\u305f\u3081less\u3067\u78ba\u8a8d","title":"env"},{"location":"linux_command/#which","text":"1 # which cmd: cmd\u306e\u5b9f\u4f53\u304c\u7f6e\u304b\u308c\u3066\u3044\u308b\u5834\u6240\u3092\u8868\u793a","title":"which"},{"location":"linux_command/#source","text":"1 2 3 # source ~/.bashrc: .bashrc\u3092\u518d\u8aad\u307f\u8fbc\u307f # . ~/.bashrc: \u2191\u3068\u540c\u3058(.\u306fsource\u306e\u30a8\u30a4\u30ea\u30a2\u30b9) # * \u30b7\u30a7\u30eb\u306e\u8a2d\u5b9a\u30d5\u30a1\u30a4\u30eb\u3092\u5909\u66f4\u3057\u305f\u5f8c\u306e\u518d\u8aad\u307f\u8fbc\u307f\u3067\u4f7f\u3046\u30b1\u30fc\u30b9\u304c100%","title":"source"},{"location":"linux_command/#chmod","text":"1 2 3 chmod 755 *.sh #sh\u30d5\u30a1\u30a4\u30eb\u306b\u5b9f\u884c\u6a29\u9650\u3092\u4ed8\u4e0e chmod 644 *.js #js\u30d5\u30a1\u30a4\u30eb\u3092\u666e\u901a\u306b\u8aad\u307f\u66f8\u304d\u3067\u304d\u308b\u8a2d\u5b9a\u306b\u3059\u308b chmod ugo+rwx -R /*","title":"chmod"},{"location":"linux_command/#os","text":"","title":"OS \u95a2\u9023"},{"location":"linux_command/#df","text":"1 2 # df -h: \u30c7\u30a3\u30b9\u30af\u306e\u4f7f\u7528\u91cf/\u7a7a\u304d\u5bb9\u91cf\u3092\u5358\u4f4d\u4ed8\u304d\u3067\u8868\u793a(\u7531\u6765: human readable) # df: \u30c7\u30a3\u30b9\u30af\u306e\u4f7f\u7528\u91cf/\u7a7a\u304d\u5bb9\u91cf\u3092\u8868","title":"df"},{"location":"linux_command/#du","text":"1 2 3 4 5 # du -h: \u5404\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u5bb9\u91cf\u3092\u5358\u4f4d\u4ed8\u304d\u3067\u8868\u793a(\u7531\u6765: human readable) # \u30ab\u30ec\u30f3\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u5bb9\u91cf\u3092\u8868\u793a\uff0e\u6df1\u30551 du -h -d1 . du -h -d 1 | sort -h","title":"du"},{"location":"linux_command/#free","text":"1 free -h #\u30e1\u30e2\u30ea\u4f7f\u7528\u72b6\u6cc1\u3092\u5358\u4f4d\u4ed8\u304d\u3067\u8868\u793a(\u7531\u6765: human readable)","title":"free"},{"location":"linux_command/#top-ps-kill","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 top #CPU\u3084\u30e1\u30e2\u30ea\u306e\u4f7f\u7528\u72b6\u6cc1\u3092\u78ba\u8a8d # * \u30c7\u30d5\u30a9\u30eb\u30c8\u3060\u3068CPU\u4f7f\u7528\u7387\u306e\u591a\u3044\u30d7\u30ed\u30bb\u30b9\u304c\u4e0a\u306b\u6765\u308b # * %CPU\u304cCPU\u4f7f\u7528\u7387\u3002\u3069\u306e\u30d7\u30ed\u30bb\u30b9\u304c\u9ad8\u8ca0\u8377\u304b\u3092\u78ba\u8a8d\u3067\u304d\u308b\u3002 ps -ef #\u5168\u3066\u306e\u30d7\u30ed\u30bb\u30b9\u306e\u8a73\u7d30\u306a\u60c5\u5831\u3092\u898b\u308b(\u7531\u6765: every, full) # * \u7528\u90141: \u3042\u308b\u30d7\u30ed\u30bb\u30b9\u304c\u751f\u304d\u3066\u308b\u304b\u3069\u3046\u304b\u30c1\u30a7\u30c3\u30af (web\u30b5\u30fc\u30d0\u8d77\u52d5\u3057\u3066\u308b?) # * \u7528\u90142: \u3042\u308b\u30d7\u30ed\u30bb\u30b9\u306ePID(\u30d7\u30ed\u30bb\u30b9ID)\u3092\u30c1\u30a7\u30c3\u30af -> kill ${PID} ps aux # kill 123: \u30d7\u30ed\u30bb\u30b9ID\u304c123\u306e\u30d7\u30ed\u30bb\u30b9\u3092\u505c\u6b62\u3055\u305b\u308b(SIGTERM\u3092\u9001\u308b) # kill -9 123: \u30d7\u30ed\u30bb\u30b9ID\u304c123\u306e\u30d7\u30ed\u30bb\u30b9\u3092\u554f\u7b54\u7121\u7528\u3067\u6bba\u3059(9\u306fSIGKILL\u306e\u30b7\u30b0\u30ca\u30eb\u756a\u53f7) # kill -KILL 123: -9\u3068\u540c\u3058 kill -9 [ \u756a\u53f7 ] # pkill process_name_prefix: process_name_prefix\u3067\u59cb\u307e\u308b\u30d7\u30ed\u30bb\u30b9\u3059\u3079\u3066\u3092\u7d42\u4e86\u3055\u305b\u308b # pkill -9 process_name_prefix: process_name_prefix\u3067\u59cb\u307e\u308b\u30d7\u30ed\u30bb\u30b9\u3059\u3079\u3066\u3092\u554f\u7b54\u7121\u7528\u3067\u7d42\u4e86\u3055\u305b\u308b","title":"top, ps, kill"},{"location":"linux_command/#_7","text":"1 2 3 4 5 6 7 8 cmd1 #cmd1\u3092\u30d5\u30a9\u30a2\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u5b9f\u884c cmd1 & #cmd1\u3092\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u3067\u5b9f\u884c #\u30d5\u30a9\u30a2\u30b0\u30e9\u30a6\u30f3\u30c9 \u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u306b\u5207\u308a\u66ff\u3048 jobs #job\u756a\u53f7\u3092\u8abf\u3079\u308b fg %1 bg %1 \u306b\u5207\u308a\u66ff\u3048 # * \u91cd\u305f\u3044\u30d0\u30c3\u30c1\u51e6\u7406\u3084\u3001\u4e00\u6642\u7684\u306bweb\u30b5\u30fc\u30d0\u3092\u52d5\u304b\u3057\u305f\u3044\u3068\u304d\u306f\u3001 # \u30b3\u30de\u30f3\u30c9\u3092\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u5b9f\u884c\u3059\u308b\u3068\u4fbf\u5229","title":"\u30d0\u30c3\u30af\u30b0\u30e9\u30a6\u30f3\u30c9\u5b9f\u884c"},{"location":"linux_command/#_8","text":"1 2 3 4 # cmd1 && cmd2: cmd1\u304c\u6210\u529f\u3057\u305f\u3089\u3001cmd2\u3092\u5b9f\u884c(cmd1\u304c\u5931\u6557\u3057\u305f\u3089\u305d\u3053\u3067\u7d42\u308f\u308a) # cmd1 || cmd2: cmd1\u304c\u5931\u6557\u3057\u305f\u3089\u3001cmd2\u3092\u5b9f\u884c(cmd1\u304c\u6210\u529f\u3057\u305f\u3089\u305d\u3053\u3067\u7d42\u308f\u308a) # * \u7528\u90141: \u30ef\u30f3\u30e9\u30a4\u30ca\u30fc\u3067\u3061\u3087\u3063\u3068\u3057\u305f\u9010\u6b21\u51e6\u7406\u3092\u66f8\u304f # * \u7528\u90142: cmd1 || echo \"error message\"","title":"&amp;&amp;, ||"},{"location":"linux_command/#_9","text":"","title":"\u30ea\u30e2\u30fc\u30c8"},{"location":"linux_command/#ssh","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 # -i : \u9375\u30d5\u30a1\u30a4\u30eb # -L: \u30dd\u30fc\u30c8\u30d5\u30a9\u30ef\u30fc\u30c7\u30a3\u30f3\u30b0 ssh -L <host port>:localhost:<remote port> user@remote #https://qiita.com/wnoguchi/items/a72a042bb8159c35d056 # ECDSA521 bit ssh-keygen -t ecdsa -b 521 -C \"wnoguchi-mbp\" # Ed25519 ssh-keygen -t ed25519 -P \"\" -f serial-server.pem ssh-keygen -t ed25519 cat public_key >> ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys","title":"ssh"},{"location":"linux_command/#scp","text":"1 2 # -i : \u9375\u30d5\u30a1\u30a4\u30eb # -r : \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u79fb\u52d5","title":"scp"},{"location":"linux_command/#useful-commands","text":"","title":"useful commands"},{"location":"linux_command/#_10","text":"\u4f7f\u7528\u91cf\u304c\u591a\u3044\u9806\u306b 5 \u4ef6\u3092\u53d6\u5f97\u3059\u308b 1 du -sm ./* | sort -rn | head -5 \u5bb9\u91cf\u3092\u304f\u3063\u3066\u308b\u30d9\u30b9\u30c8 100 1 du -ma | sort -rn | head -100 \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u307f\u3092\u691c\u7d22\u3059\u308b\u5834\u5408 1 du -m | sort -rn | head -100 30 \u65e5\u9593\u7de8\u96c6\u304c\u306a\u3044\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u3092\u30b5\u30a4\u30ba\u9806\u3067\u8868\u793a 1 find ./ -mtime +30 -prune -exec du -sh {} \\;|sort -hr \u30ab\u30ec\u30f3\u30c8\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u5bb9\u91cf\u3092\u8868\u793a\uff0e\u6df1\u3055 1\uff0e 1 du -h -d1 . 100 \u30d5\u30a1\u30a4\u30eb\u3092\u30e9\u30f3\u30c0\u30e0\u306b\u9078\u3093\u3067\u30b3\u30d4\u30fc\uff0e 1 find /some/dir -type f -name \"*.jpg\" | shuf -n 100 | xargs cp -vt /target/dir/ tgt_dir \u4ee5\u4e0b\u306e\u30d5\u30a1\u30a4\u30eb\u540d\u3092\u5229\u7528\u3057\u3066\u3001src_dir \u304b\u3089 dst_fir \u3078\u3068\u30d5\u30a1\u30a4\u30eb\u3092\u79fb\u52d5 1 ls tgt_dir | while read name; do mv src_dir/${name:0:-4}* dst_dir/; done","title":"\u5bb9\u91cf\u306e\u5927\u304d\u3044\u30d5\u30a1\u30a4\u30eb\u306e\u7279\u5b9a"},{"location":"linux_command/#tmux","text":"https://golang.hateblo.jp/entry/2019/10/11/133000 https://qiita.com/nmrmsys/items/03f97f5eabec18a3a18b 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # \u65b0\u898f\u30bb\u30c3\u30b7\u30e7\u30f3\u958b\u59cb tmux # \u540d\u524d\u3092\u3064\u3051\u3066\u65b0\u898f\u30bb\u30c3\u30b7\u30e7\u30f3\u958b\u59cb tmux new -s <\u30bb\u30c3\u30b7\u30e7\u30f3\u540d> # \u30bb\u30c3\u30b7\u30e7\u30f3\u306e\u4e00\u89a7\u8868\u793a tmux ls # \u63a5\u7d9a\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u306e\u4e00\u89a7\u8868\u793a tmux lsc # \u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u518d\u958b \u203b-t <\u5bfe\u8c61\u30bb\u30c3\u30b7\u30e7\u30f3\u540d>\u3067\u30bb\u30c3\u30b7\u30e7\u30f3\u540d\u306e\u6307\u5b9a\u3082\u53ef\u80fd tmux a -t [ session-name ] # \u30bb\u30c3\u30b7\u30e7\u30f3\u3092\u7d42\u4e86 \u203b-t <\u5bfe\u8c61\u30bb\u30c3\u30b7\u30e7\u30f3\u540d>\u3067\u30bb\u30c3\u30b7\u30e7\u30f3\u540d\u306e\u6307\u5b9a\u3082\u53ef\u80fd tmux kill-session -t [ session-name ] # tmux\u5168\u4f53\u3092\u7d42\u4e86 tmux kill-server # \u305d\u306e\u4ed6\u30b3\u30de\u30f3\u30c9\u3092\u5b9f\u884c tmux [ command [ flags ]] ctrl-b c : \u65b0\u3057\u3044\u30a6\u30a4\u30f3\u30c9\u30a6\u3092\u8ffd\u52a0 ctrl-b b : \u30a6\u30a4\u30f3\u30c9\u30a6\u3092\u79fb\u52d5 ctrl-b & : \u30a2\u30af\u30c6\u30a3\u30d6\u306a\u30a6\u30a3\u30f3\u30c9\u30a6\u3092\u524a\u9664 ctrl-b % : \u5de6\u53f3\u306e\u30da\u30a4\u30f3\u306b\u79fb\u52d5 ctrl-b \" : \u4e0a\u4e0b\u306e\u30da\u30a4\u30f3\u306b\u79fb\u52d5 : ctrl-b o or \u30ab\u30fc\u30bd\u30eb\uff1a\u30da\u30a4\u30f3\u9593\u306e\u79fb\u52d5 ctrl-b x : \u30da\u30a4\u30f3\u5206\u5272\u306e\u89e3\u9664 ctrl-b d: detach","title":"tmux"},{"location":"linux_command/#gunicorn-uvicorn","text":"","title":"gunicorn, uvicorn"},{"location":"linux_shell/","text":"Shell arts \u00b6 Basic \u00b6 1 man # \u30b3\u30de\u30f3\u30c9\u3092\u8abf\u3079\u308b sed \u00b6 1 2 3 echo abcdefgabc | sed 's/a/b/' # \u6587\u5b571\u3064\u3060\u3051 echo abcdefgabc | sed 's/a/b/g' #\u6587\u5b57\u5217\u5168\u90e8 echo abcdefgabc | sed 's/ab/&&/' #&\u306f\u691c\u7d22\u5bfe\u8c61\u306e\u6587\u5b57\u5217\u3092\u6307\u3059\u306e\u3067abab\u3068\u540c\u7fa9 awk \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 ## awk, grep, sed \u306a\u3069\u306fbash\u306e\u5909\u6570\u3068\u3057\u3066\u89e3\u91c8\u3055\u308c\u308b\u306e\u3092\u9632\u3050\u305f\u3081\u306b\u30b7\u30f3\u30b0\u30eb\u30af\u30aa\u30fc\u30c8\u3067\u56f2\u3080 # grep '\u6b63\u898f\u8868\u73fe'\u3068\u540c\u7fa9 seq 5 | awk '/[24]/' # $1\u306f\u8aad\u307f\u8fbc\u3093\u3060\u884c\u306e\uff11\u5217\u76ee # \u6587\u5b57\u5217\u306f\u30c0\u30d6\u30eb\u30af\u30aa\u30fc\u30c8\u3067\u56f2\u3080 seq 5 | '$1%2==0' # \u30d1\u30a4\u30d7\u306f\u6a19\u6e96\u5165\u529b\u3068\u3057\u3066\u6e21\u3059\u304c\u3001xargs\u306f\u5f15\u6570\u3068\u3057\u3066\u6e21\u3059 seq 4 | mkdir ls **.sh | xargs less \u4e09\u9805\u6f14\u7b97\u5b50 \u00b6 1 2 3 4 # {}\u306e\u610f\u5473\u3001https://qiita.com/yohm/items/3527d517768402efbcb6 seq 5 | awk '{print $1%2 ? \"odd\":\"even\"}' # -c \u30aa\u30d7\u30b7\u30e7\u30f3\u306f\u540c\u3058\u884c\u304c\u4f55\u500b\u9023\u7d9a\u3057\u3066\u3044\u308b\u304b\u3092\u6570\u3048\u308b seq 5 | awk '{print $1%2 ? \"odd\":\"even\"}' | sort | uniq -c 1 \u5217\u76ee\u306b pl \u3068\u66f8\u304b\u308c\u3066\u3044\u308b\u884c\u306e 2 \u5217\u76ee\u3092\u62bd\u51fa \u00b6 1 cat data.txt | awk '$1==\"pl\"' | awk '{print $2}' \u968e\u6bb5\u578b\u306e\u6a21\u69d8\u3092\u63cf\u304f \u00b6 1 2 seq 5 | awk '{for(i=1;i<$1;i++){printf \" \"};print \"x\"}' | tac seq 5 | awk '{a++;for(i=5;i>a;i--){printf \" \"}' ; print \"x\" } ' \u30ab\u30f3\u30de\u533a\u5207\u308a\u306e 2 \u5217\u76ee\u3092\u53d6\u308a\u51fa\u3059 \u00b6 1 2 echo 'aaa,\"bbb,ccc\",ddd' | \\ gawk -v FPAT = '([^,]+)|(\\\"[^\\\"]+\\\")' '{print $2}' xargs \u00b6 1 2 3 4 5 6 7 8 9 mkdir 1 3 seq 4 | xargs -n2 mv # -n\u500b\u6570 \u500b\u6570\u305a\u3064\u5f15\u6570\u3092\u6e21\u3059 seq 4 | xargs -I@ mkdir dir_@ # @\u306e\u4e2d\u306bxargs\u304c\u53d7\u3051\u53d6\u308b\u5f15\u6570\u3092\uff11\u3064\u305a\u3064\u5165\u308c\u308b seq 4 | awk '{print \"mkdir\" ($1%2 ? \"odd_\" : \"even_\")$1}' | bash even_2 even_4 odd_1 even_4 file manipulation \u00b6 png \u3092 jpg \u306b\u4e00\u62ec\u5909\u63db+\u6642\u9593\u8a08\u6e2c\uff0b\u30d7\u30ed\u30bb\u30c3\u30b5\u6570\u3067\u4e26\u5217\u51e6\u7406 \u00b6 1 2 3 time ls *.png | sed 's/\\.exe$//' | xargs -P $( nproc ) -I@ convert @.png # \\\u306f\u30a8\u30b9\u30b1\u30fc\u30d7\u6587\u5b57.\u4eca\u306f\u62e1\u5f35\u5b50\u3092\u691c\u7d22\u3057\u305f\u3044\u3002$\u306f\u7d42\u7aef\u3092\u8868\u3059\u3002 # \u30d5\u30a1\u30a4\u30eb\u306e\u4e2d\u304b\u3089.exe\u3068\u3044\u3046\u540d\u524d\u306e\u3082\u306e\u3092\u63a2\u3059 \u540d\u524d\u4e00\u62ec\u5909\u66f4+-U \u3067\u30bd\u30fc\u30c8\u77ed\u7e2e \u00b6 1 2 3 time ls -U | xargs -P $( nproc ) rename 's/^/000000/;/0\\*([0-9]{7}/$1/' ) # \u524a\u9664 grep -l '^10$' -R | xargs rm \u5909\u6570\u306e\u6271\u3044 \u00b6 1 2 3 4 5 6 7 8 a = 234 b = 678 c = $a$b ; echo $c #234678 c = ${ a : 1 : 2 } ; echo $c #0\u30b9\u30bf\u30fc\u30c8\u30011\u6587\u5b57\u76ee\u304b\u3089\u6570\u3048\u30662\u3064 #34 for \u6587 \u00b6 1 2 set aa bb cc for x in \" $1 \" \" $2 \" \" $3 \" ; do echo $x ; done if \u6587 \u00b6 1 2 a = 0 if echo $a | grep '[02468]$' ; then echo even ; elif echo $a | grep '[123579]$' then echo odd ; else echo other ; fi","title":"Shell arts"},{"location":"linux_shell/#shell-arts","text":"","title":"Shell arts"},{"location":"linux_shell/#basic","text":"1 man # \u30b3\u30de\u30f3\u30c9\u3092\u8abf\u3079\u308b","title":"Basic"},{"location":"linux_shell/#sed","text":"1 2 3 echo abcdefgabc | sed 's/a/b/' # \u6587\u5b571\u3064\u3060\u3051 echo abcdefgabc | sed 's/a/b/g' #\u6587\u5b57\u5217\u5168\u90e8 echo abcdefgabc | sed 's/ab/&&/' #&\u306f\u691c\u7d22\u5bfe\u8c61\u306e\u6587\u5b57\u5217\u3092\u6307\u3059\u306e\u3067abab\u3068\u540c\u7fa9","title":"sed"},{"location":"linux_shell/#awk","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 ## awk, grep, sed \u306a\u3069\u306fbash\u306e\u5909\u6570\u3068\u3057\u3066\u89e3\u91c8\u3055\u308c\u308b\u306e\u3092\u9632\u3050\u305f\u3081\u306b\u30b7\u30f3\u30b0\u30eb\u30af\u30aa\u30fc\u30c8\u3067\u56f2\u3080 # grep '\u6b63\u898f\u8868\u73fe'\u3068\u540c\u7fa9 seq 5 | awk '/[24]/' # $1\u306f\u8aad\u307f\u8fbc\u3093\u3060\u884c\u306e\uff11\u5217\u76ee # \u6587\u5b57\u5217\u306f\u30c0\u30d6\u30eb\u30af\u30aa\u30fc\u30c8\u3067\u56f2\u3080 seq 5 | '$1%2==0' # \u30d1\u30a4\u30d7\u306f\u6a19\u6e96\u5165\u529b\u3068\u3057\u3066\u6e21\u3059\u304c\u3001xargs\u306f\u5f15\u6570\u3068\u3057\u3066\u6e21\u3059 seq 4 | mkdir ls **.sh | xargs less","title":"awk"},{"location":"linux_shell/#_1","text":"1 2 3 4 # {}\u306e\u610f\u5473\u3001https://qiita.com/yohm/items/3527d517768402efbcb6 seq 5 | awk '{print $1%2 ? \"odd\":\"even\"}' # -c \u30aa\u30d7\u30b7\u30e7\u30f3\u306f\u540c\u3058\u884c\u304c\u4f55\u500b\u9023\u7d9a\u3057\u3066\u3044\u308b\u304b\u3092\u6570\u3048\u308b seq 5 | awk '{print $1%2 ? \"odd\":\"even\"}' | sort | uniq -c","title":"\u4e09\u9805\u6f14\u7b97\u5b50"},{"location":"linux_shell/#1-pl-2","text":"1 cat data.txt | awk '$1==\"pl\"' | awk '{print $2}'","title":"1 \u5217\u76ee\u306b pl \u3068\u66f8\u304b\u308c\u3066\u3044\u308b\u884c\u306e 2 \u5217\u76ee\u3092\u62bd\u51fa"},{"location":"linux_shell/#_2","text":"1 2 seq 5 | awk '{for(i=1;i<$1;i++){printf \" \"};print \"x\"}' | tac seq 5 | awk '{a++;for(i=5;i>a;i--){printf \" \"}' ; print \"x\" } '","title":"\u968e\u6bb5\u578b\u306e\u6a21\u69d8\u3092\u63cf\u304f"},{"location":"linux_shell/#2","text":"1 2 echo 'aaa,\"bbb,ccc\",ddd' | \\ gawk -v FPAT = '([^,]+)|(\\\"[^\\\"]+\\\")' '{print $2}'","title":"\u30ab\u30f3\u30de\u533a\u5207\u308a\u306e 2 \u5217\u76ee\u3092\u53d6\u308a\u51fa\u3059"},{"location":"linux_shell/#xargs","text":"1 2 3 4 5 6 7 8 9 mkdir 1 3 seq 4 | xargs -n2 mv # -n\u500b\u6570 \u500b\u6570\u305a\u3064\u5f15\u6570\u3092\u6e21\u3059 seq 4 | xargs -I@ mkdir dir_@ # @\u306e\u4e2d\u306bxargs\u304c\u53d7\u3051\u53d6\u308b\u5f15\u6570\u3092\uff11\u3064\u305a\u3064\u5165\u308c\u308b seq 4 | awk '{print \"mkdir\" ($1%2 ? \"odd_\" : \"even_\")$1}' | bash even_2 even_4 odd_1 even_4","title":"xargs"},{"location":"linux_shell/#file-manipulation","text":"","title":"file manipulation"},{"location":"linux_shell/#png-jpg","text":"1 2 3 time ls *.png | sed 's/\\.exe$//' | xargs -P $( nproc ) -I@ convert @.png # \\\u306f\u30a8\u30b9\u30b1\u30fc\u30d7\u6587\u5b57.\u4eca\u306f\u62e1\u5f35\u5b50\u3092\u691c\u7d22\u3057\u305f\u3044\u3002$\u306f\u7d42\u7aef\u3092\u8868\u3059\u3002 # \u30d5\u30a1\u30a4\u30eb\u306e\u4e2d\u304b\u3089.exe\u3068\u3044\u3046\u540d\u524d\u306e\u3082\u306e\u3092\u63a2\u3059","title":"png \u3092 jpg \u306b\u4e00\u62ec\u5909\u63db+\u6642\u9593\u8a08\u6e2c\uff0b\u30d7\u30ed\u30bb\u30c3\u30b5\u6570\u3067\u4e26\u5217\u51e6\u7406"},{"location":"linux_shell/#-u","text":"1 2 3 time ls -U | xargs -P $( nproc ) rename 's/^/000000/;/0\\*([0-9]{7}/$1/' ) # \u524a\u9664 grep -l '^10$' -R | xargs rm","title":"\u540d\u524d\u4e00\u62ec\u5909\u66f4+-U \u3067\u30bd\u30fc\u30c8\u77ed\u7e2e"},{"location":"linux_shell/#_3","text":"1 2 3 4 5 6 7 8 a = 234 b = 678 c = $a$b ; echo $c #234678 c = ${ a : 1 : 2 } ; echo $c #0\u30b9\u30bf\u30fc\u30c8\u30011\u6587\u5b57\u76ee\u304b\u3089\u6570\u3048\u30662\u3064 #34","title":"\u5909\u6570\u306e\u6271\u3044"},{"location":"linux_shell/#for","text":"1 2 set aa bb cc for x in \" $1 \" \" $2 \" \" $3 \" ; do echo $x ; done","title":"for \u6587"},{"location":"linux_shell/#if","text":"1 2 a = 0 if echo $a | grep '[02468]$' ; then echo even ; elif echo $a | grep '[123579]$' then echo odd ; else echo other ; fi","title":"if \u6587"},{"location":"util/","text":"python \u6a19\u6e96\u30e9\u30a4\u30d6\u30e9\u30ea \u00b6 https://qiita.com/hiroyuki_mrp/items/8bbd9ab6c16601e87a9c \u30ea\u30f3\u30bf\u30fc \u00b6 \u3010VS Code\u3011Black \u3068 Flake8 \u3092\u4f7f\u3063\u3066\u304d\u308c\u3044\u306a Python \u30b3\u30fc\u30c9\u3092\u66f8\u304f\uff01\uff01 Python \u306e\u30b3\u30fc\u30c9\u3092\u30ad\u30ec\u30a4\u306b\u66f8\u304d\u305f\u3044\uff01(VSCode \u306b flake8 & black \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb) flake8\u3001black\u3001isort\u3001mypy \u3092 VS Code \u4e0a\u3067\u4f7f\u7528\u3059\u308b GCP \u306a\u3069\u306e\u5834\u5408\u306f\u500b\u5225\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff08pip install black\uff09,\u8a2d\u5b9a(ssh \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9)\u304c\u5fc5\u8981\u3001error lense \u306f 500 \u307e\u3067\u306e delay \u304c\u5fc5\u8981 util pyfile templates \u00b6 Pypy, pip \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb Python \u3067\u81ea\u5206\u3060\u3051\u306e\u30af\u30bd\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u4f5c\u308b\u65b9\u6cd5 Python \u3067\u4f5c\u3063\u305f\u30b3\u30de\u30f3\u30c9\u3092 GitHub \u7d4c\u7531\u3067 pip \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u53ef\u80fd\u306b\u3059\u308b \u30c6\u30f3\u30d7\u30ec\u30fc\u30c8 \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import glob import os import time from functools import wraps import argparse from tqdm import tqdm @stop_watch def func ( file_list , output_dir ): return None if __name__ == \"__main__\" : parser = argparse . ArgumentParser () parser . add_argument ( \"--input_dir\" , type = str , required = True , help = \"path for input dir\" , ) parser . add_argument ( \"--output_dir\" , type = str , required = True , help = \"path for output dir\" , ) args = parser . parse_args () check_create_dir ( args . output_dir ) file_list = get_file_list ( args . input_dir ) func ( file_list , args . output_dir ) \u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u78ba\u8a8d\u3068\u4f5c\u6210 \u00b6 1 2 3 4 def check_create_dir ( path ): # check if there is the directory. if not create a new directory. if not os . path . isdir ( path ): os . makedirs ( path ) \u30d5\u30a1\u30a4\u30eb\u30ea\u30b9\u30c8\u306e\u53d6\u5f97 \u00b6 1 2 3 4 5 6 7 8 9 def get_file_list ( input_dir ): # get the list of files in input directory. return sorted ( [ p for p in glob . glob ( os . path . join ( input_dir , \"**\" ), recursive = True ) if os . path . isfile ( p ) ] ) 1 2 3 4 5 6 7 8 9 10 11 ### def stop_watch ( func ) : @wraps ( func ) def wrapper ( * args , ** kargs ) : start = time . time () result = func ( * args , ** kargs ) elapsed_time = time . time () - start print ( f \"total time of { func . __name__ } : { elapsed_time } \" ) return result return wrapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @stop_watch def func ( file_list , output_dir ): return None if __name__ == \"__main__\" : parser = argparse . ArgumentParser () parser . add_argument ( \"--input_dir\" , type = str , required = True , help = \"path for input dir\" , ) parser . add_argument ( \"--output_dir\" , type = str , required = True , help = \"path for output dir\" , ) args = parser . parse_args () check_create_dir ( args . output_dir ) file_list = get_file_list ( args . input_dir ) func ( file_list , args . output_dir ) General util \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def load_pickle ( load_path ): # pd.read_pickle(load_path) with open ( load_path , mode = \"rb\" ) as f : return pickle . load ( f ) def save_pickle ( object , save_path ): # pd.to_pickle(object, save_path) with open ( save_path , mode = \"wb\" ) as f : pickle . dump ( object , f ) def check_create_dir ( path ): if not os . path . isdir ( path ): os . makedirs ( path , exist_ok = True ) def get_file_list ( input_dir ): return [ p for p in glob . glob ( os . path . join ( input_dir , \"**\" ), recursive = True ) if os . path . isfile ( p ) ] def split_list ( l , n ): \"\"\" https://www.python.ambitious-engineer.com/archives/1843 Other: np.array_split(l, 3) \"\"\" for idx in range ( 0 , len ( l ), n ): yield l [ idx : idx + n ] def split_list ( l , n ): return np . array_split ( l , n ) def json2dataframe ( json_data ): return pd . json_normalize ( json_data , record_path = 'data' ) def flatten_dict ( dict ): df = pd . json_normalize ( dict [ \"data\" ][ 0 ], sep = \"_\" ) return df . to_dict ( orient = \"records\" )[ 0 ] def flatten_dict ( d , parent_key = \"\" , sep = \"_\" ): items = [] for k , v in d . items (): new_key = parent_key + sep + k if parent_key else k if isinstance ( v , collections . MutableMapping ): items . extend ( flatten ( v , new_key , sep = sep ) . items ()) else : items . append (( new_key , v )) return dict ( items ) from functools import wraps import time def stop_watch ( func ) : @wraps ( func ) def wrapper ( * args , ** kargs ) : start = time . time () result = func ( * args , ** kargs ) elapsed_time = time . time () - start print ( f \"total time of { func . __name__ } : { elapsed_time } \" ) return result return wrapper def seed_everything ( seed = 2021 ): random . seed ( seed ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) np . random . seed ( seed ) torch . manual_seed ( seed ) torch . cuda . manual_seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False def git_commits ( rand ): def func_decorator ( my_func ): repo = git . Repo ( \"/work\" ) repo . config_writer () . set_value ( \"user\" , \"name\" , \"your_userID\" ) . release () repo . config_writer () . set_value ( \"user\" , \"email\" , \"your_email@gmail.com\" ) . release () repo . git . diff ( \"HEAD\" ) repo . git . add ( \".\" ) repo . index . commit ( f \" { rand } _running\" ) repo . git . push ( \"origin\" , \"HEAD\" ) logger . info ( f \"git pushed to the remote origin\" ) def decorator_wrapper ( * args , ** kwargs ): my_func ( * args , ** kwargs ) repo . git . add ( \".\" ) repo . index . commit ( f \" { rand } _done\" ) repo . git . push ( \"origin\" , \"HEAD\" ) logger . info ( f \"git pushed to the remote origin\" ) return decorator_wrapper return func_decorator def randomname ( n ): return \"\" . join ( random . choices ( string . ascii_letters + string . digits , k = n )) logger \u00b6 \u30ed\u30b0\u51fa\u529b\u306e\u305f\u3081\u306e print \u3068 import logging \u306f\u3084\u3081\u3066\u307b\u3057\u3044 Python \u3067 print \u3092\u5352\u696d\u3057\u3066\u30ed\u30b0\u51fa\u529b\u3092\u3044\u3044\u611f\u3058\u306b\u3059\u308b \u00b6 1 2 3 4 5 6 7 8 9 from logging import getLogger , StreamHandler , DEBUG logger = getLogger ( __name__ ) handler = StreamHandler () handler . setLevel ( DEBUG ) logger . setLevel ( DEBUG ) logger . addHandler ( handler ) logger . propagate = False logger . debug ( 'hello' ) https://qiita.com/shotakaha/items/0fa2db1dc8253c83e2bb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 import logging import logging.handlers def setup_logger ( name , logfile = 'log.log' ): logger = logging . getLogger ( name ) logger . setLevel ( logging . DEBUG ) # create file handler which logs even DEBUG messages fh = logging . handlers . RotatingFileHandler ( logfile , maxBytes = 100000000 , backupCount = 10 ) fh . setLevel ( logging . DEBUG ) fh_formatter = logging . Formatter ( \"[ %(asctime)s ] [ %(levelname)s ] [ %(process)d ] [ %(name)s ] [ %(funcName)s ] [ %(lineno)d ] %(message)s \" ) fh . setFormatter ( fh_formatter ) # create console handler with a INFO log level ch = LoggingHandler () ch . setLevel ( logging . INFO ) ch_formatter = logging . Formatter ( \"[ %(asctime)s ] [ %(levelname)s ] [ %(process)d ] [ %(name)s ] [ %(funcName)s ] [ %(lineno)d ] %(message)s \" ) ch . setFormatter ( ch_formatter ) # add the handlers to the logger logger . addHandler ( fh ) logger . addHandler ( ch ) return logger def setup_logger ( name , logfile = 'log.log' ): logger = logging . getLogger ( name ) logger . setLevel ( logging . DEBUG ) # create file handler which logs even DEBUG messages fh = logging . FileHandler ( logfile ) fh . setLevel ( logging . DEBUG ) fh_formatter = logging . Formatter ( \"[ %(asctime)s ] [ %(levelname)s ] [ %(process)d ] [ %(name)s ] [ %(funcName)s ] [ %(lineno)d ] %(message)s \" ) fh . setFormatter ( fh_formatter ) # create console handler with a INFO log level ch = LoggingHandler () ch . setLevel ( logging . INFO ) ch_formatter = logging . Formatter ( \"[ %(asctime)s ] [ %(levelname)s ] [ %(process)d ] [ %(name)s ] [ %(funcName)s ] [ %(lineno)d ] %(message)s \" ) ch . setFormatter ( ch_formatter ) # add the handlers to the logger logger . addHandler ( fh ) logger . addHandler ( ch ) return logger \u53c2\u8003 https://github.com/tqdm/tqdm#redirecting-writing https://qiita.com/mino-38/items/f09251d18fe3181bfbfd https://waregawa-log.hatenablog.com/entry/2020/01/01/100000 https://stackoverflow.com/questions/384076/how-can-i-color-python-logging-output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 import contextlib import logging import logging.handlers import sys from time import sleep from tqdm import tqdm from tqdm.contrib import DummyTqdmFile class TqdmLoggingHandler ( logging . Handler ): colors = { \"INFO\" : \" \\033 [37m {} \\033 [0m\" } def __init__ ( self , level = logging . NOTSET ): super () . __init__ ( level ) def emit ( self , record ): try : record . msg = TqdmLoggingHandler . colors . get ( record . levelname , \" {} \" ) . format ( record . msg ) msg = self . format ( record ) tqdm . write ( msg , file = sys . stderr ) self . flush () except Exception : self . handleError ( record ) class CustomFormatter ( logging . Formatter ): grey = \" \\x1b [38;20m\" green = \" \\x1b [32;20m\" yellow = \" \\x1b [33;20m\" red = \" \\x1b [31;20m\" bold_red = \" \\x1b [31;1m\" reset = \" \\x1b [0m\" format = \"[ %(asctime)s ] [ %(levelname)s ] [ %(process)d ] [ %(name)s ] [ %(funcName)s ] [ %(lineno)d ] %(message)s \" FORMATS = { logging . DEBUG : grey + format + reset , logging . INFO : green + format + reset , logging . WARNING : yellow + format + reset , logging . ERROR : red + format + reset , logging . CRITICAL : bold_red + format + reset , } def format ( self , record ): log_fmt = self . FORMATS . get ( record . levelno ) formatter = logging . Formatter ( log_fmt ) return formatter . format ( record ) def setup_logger ( name , logfile = \"log.log\" ): logger = logging . getLogger ( name ) logger . setLevel ( logging . DEBUG ) # create file handler which logs even DEBUG messages fh = logging . handlers . RotatingFileHandler ( logfile , maxBytes = 100000000 , backupCount = 10 ) fh . setLevel ( logging . DEBUG ) fh_formatter = logging . Formatter ( \"[ %(asctime)s ] [ %(levelname)s ] [ %(process)d ] [ %(name)s ] [ %(funcName)s ] [ %(lineno)d ] %(message)s \" ) fh . setFormatter ( fh_formatter ) # create console handler with a INFO log level ch = TqdmLoggingHandler () ch . setLevel ( logging . INFO ) ch . setFormatter ( CustomFormatter ()) # add the handlers to the logger logger . addHandler ( fh ) logger . addHandler ( ch ) return logger logger = setup_logger ( __name__ ) @contextlib . contextmanager def std_out_err_redirect_tqdm (): orig_out_err = sys . stdout , sys . stderr try : sys . stdout , sys . stderr = map ( DummyTqdmFile , orig_out_err ) yield orig_out_err [ 0 ] # Relay exceptions except Exception as exc : raise exc # Always restore sys.stdout/err if necessary finally : sys . stdout , sys . stderr = orig_out_err def some_fun ( i ): logger . info ( \"Fee, fi, fo,\" . split ()[ 2 ]) print ( \"Fee, fi, fo,\" . split ()[ 2 ]) # Redirect stdout to tqdm.write() (don't forget the `as save_stdout`) with std_out_err_redirect_tqdm () as orig_stdout : # tqdm needs the original stdout # and dynamic_ncols=True to autodetect console width for i in tqdm ( range ( 3 ), file = orig_stdout , dynamic_ncols = True ): sleep ( 0.5 ) some_fun ( i ) # After the `with`, printing is restored print ( \"Done!\" ) Image \u00b6 png \u753b\u50cf\u3068 jpg \u753b\u50cf\u306e\u53d6\u308a\u6271\u3044\u306e\u6ce8\u610f\u70b9 https://qiita.com/pashango2/items/145d858eff3c505c100a https://note.nkmk.me/python-pillow-basic/ 1 2 3 4 def jpg2png ( file_list , output_dir ): for file_path in tqdm ( file_list ): img = Image . open ( file_path ) . resize (( 256 , 256 )) . convert ( \"RGBA\" ) img . save ( os . path . join ( output_dir , f \" { os . path . basename ( file_path )[: - 4 ] } .png\" )) \u900f\u660e png \u3092\u767d jpg \u306b\u5909\u63db \u00b6 1 2 3 4 5 6 7 def tra_png2white_jpg ( file_list , output_dir ): for file_path in tqdm ( file_list ): img = Image . open ( file_path ) img . load () background = Image . new ( \"RGB\" , img . size , ( 255 , 255 , 255 )) background . paste ( img , mask = img . split ()[ 3 ]) background . save ( os . path . join ( output_dir , f \" { os . path . basename ( file_path )[: - 4 ] } .jpg\" ), \"JPEG\" , quality = 95 ) \u900f\u660e png \u3092\u767d png \u306b\u5909\u63db \u00b6 1 2 3 4 5 6 def tra_png2white_jpg ( file_list , output_dir ): for file_path in tqdm ( file_list ): img = cv2 . imread ( file_path ) index = np . where ( img [:, :, 3 ] == 0 ) img [ index ] = [ 255 , 255 , 255 , 255 ] cv2 . imwrite ( os . path . join ( output_dir , f \" { os . path . basename ( file_path )[: - 4 ] } .png\" ), img ) \u65e9\u304f\u77e5\u3063\u3066\u304a\u304d\u305f\u304b\u3063\u305f matplotlib \u306e\u57fa\u790e\u77e5\u8b58\u3001\u3042\u308b\u3044\u306f\u898b\u305f\u76ee\u306e\u8abf\u6574\u304c\u6357\u308b Artist \u306e\u8a71 \u753b\u50cf\u3092 Grid \u4e0a\u306b\u8868\u793a \u00b6 \u753b\u50cf\u3092\u305f\u3060\u4e26\u3079\u305f\u3044\u3068\u304d\u306b\u4f7f\u3048\u308b TorchVision PIL to CV \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def cv2pil ( image ): ''' OpenCV\u578b -> PIL\u578b ''' new_image = image . copy () if new_image . ndim == 2 : # \u30e2\u30ce\u30af\u30ed pass elif new_image . shape [ 2 ] == 3 : # \u30ab\u30e9\u30fc new_image = cv2 . cvtColor ( new_image , cv2 . COLOR_BGR2RGB ) elif new_image . shape [ 2 ] == 4 : # \u900f\u904e new_image = cv2 . cvtColor ( new_image , cv2 . COLOR_BGRA2RGBA ) new_image = Image . fromarray ( new_image ) return new_image def pil2cv ( image ): ''' PIL\u578b -> OpenCV\u578b ''' new_image = np . array ( image , dtype = np . uint8 ) if new_image . ndim == 2 : # \u30e2\u30ce\u30af\u30ed pass elif new_image . shape [ 2 ] == 3 : # \u30ab\u30e9\u30fc new_image = cv2 . cvtColor ( new_image , cv2 . COLOR_RGB2BGR ) elif new_image . shape [ 2 ] == 4 : # \u900f\u904e new_image = cv2 . cvtColor ( new_image , cv2 . COLOR_RGBA2BGRA ) return new_image torch \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def get_file_list ( input_dir ): return sorted ( [ p for p in glob . glob ( os . path . join ( input_dir , \"**\" ), recursive = True ) if os . path . isfile ( p ) ] ) def create_image_array ( image_folder_path , number_of_images = 100 , size = 256 ): file_list = sorted ( get_file_list ( image_folder_path )) random . seed ( 0 ) # random_images = random.sample(file_list, number_of_images) random_images = file_list [: 100 ] image_array = np . zeros (( number_of_images , size , size , 3 ), np . uint8 ) for i , image_path in enumerate ( random_images ): im = Image . open ( image_path ) . resize (( size , size )) img = np . asarray ( im ) image_array [ i ] = img return image_array def torchvision_save ( image_array , save_path , nrows = 10 , padding = 2 ): # \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f images = image_array # save_image\u3067255\u639b\u3051\u308b\u305f\u3081[0,1]\u30b9\u30b1\u30fc\u30eb\u306b\u3057\u3066\u304a\u304f images = ( images / 255.0 ) . astype ( np . float32 ) # 1\u679a\u306b\u7d50\u5408 images = np . transpose ( images , [ 0 , 3 , 1 , 2 ]) images_tensor = torch . as_tensor ( images ) torchvision . utils . save_image ( images_tensor , save_path , nrow = nrows , padding = padding ) 1 2 3 4 5 6 7 8 9 10 11 12 13 import seaborn as sns import matplotlib.pyplot as plt num_rows , num_cols = 10 , 10 f , axes = plt . subplots ( nrows = num_rows , ncols = num_cols , figsize = ( 14 , 14 )) #f.suptitle('Distribution of Features', fontsize=16) for index , ( key , ( a1 , a2 )) in enumerate ( dic_male_five . items ()): i , j = ( index // num_cols , index % num_cols ) axes [ i , j ] . tick_params ( labelbottom = False , labelleft = False , labelright = False , labeltop = False ) sns . histplot ( a1 , bins = 5 , ax = axes [ i , j ]) 1 2 3 4 5 6 7 8 9 10 def tra_png2white_jpg1 ( file_path , output_dir ): img = Image . open ( file_path ) img . load () background = Image . new ( \"RGB\" , img . size , ( 255 , 255 , 255 )) background . paste ( img , mask = img . split ()[ 3 ]) background . save ( os . path . join ( output_dir , f \" { os . path . basename ( file_path )[: - 4 ] } .jpg\" ), \"JPEG\" , quality = 95 , ) \u753b\u50cf\u51e6\u7406\u3001\u30de\u30b9\u30af \u00b6 Python, OpenCV, NumPy \u3067\u753b\u50cf\u306e\u30a2\u30eb\u30d5\u30a1\u30d6\u30ec\u30f3\u30c9\u3068\u30de\u30b9\u30af\u51e6\u7406 \u753b\u50cf\u51e6\u7406\u5165\u9580\u8b1b\u5ea7 : OpenCV \u3068 Python \u3067\u59cb\u3081\u308b\u753b\u50cf\u51e6\u7406 Plot util \u00b6 1 2 3 4 5 def plot_pie ( data , labels ): plt . figure ( figsize = ( 12 , 8 )) plt . rcParams [ 'font.size' ] = 16.0 plt . pie ( data , labels = labels , counterclock = True , autopct = \" %1.1f%% \" ) pandas \u00b6 [Python3 / pandas] dataframe \u306b\u8f9e\u66f8\u578b\u30c7\u30fc\u30bf\u3092 1 \u884c\u305a\u3064\u8ffd\u52a0\u3057\u3066\u3044\u304d\u305f\u3044\u3068\u304d\uff08\u901f\u5ea6\u6bd4\u8f03\uff09 pandas.DataFrame \u306b\uff11\u884c\u305a\u3064\u66f8\u304d\u8db3\u3059\u65e9\u3044\u65b9\u6cd5\u3092\u8abf\u3079\u305f 1 2 3 4 5 6 7 def from_dict_method (): some_df = pd . DataFrame ([], columns = some_dict . keys ()) dict_array = [] for i in range ( 3000 ): dict_array . append ( some_dict ) some_df = pd . concat ([ some_df , pd . DataFrame . from_dict ( dict_array )]) return some_df vectorize \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 def func_1 ( energy_kwh_0 , energy_kwh_1 , energy_kwh_2 ): if energy_kwh_0 > energy_kwh_1 : return 'a' elif energy_kwh_0 > energy_kwh_2 : return 'b' else : return 'c' df [ 'pattern_np_vectorize' ] = np . vectorize ( func_1 )( df [ \"energy_kwh_0\" ], df [ \"energy_kwh_1\" ], df [ \"energy_kwh_2\" ] ) argparse \u00b6 Python \u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u89e3\u6790\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u6bd4\u8f03(argparse, click, fire) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 parser = argparse . ArgumentParser ( description = \"Image Annotation\" ) parser . add_argument ( \"--input_dir\" , type = str , default = \"./images\" , help = \"path for input data\" , ) parser . add_argument ( \"--output_dir\" , type = str , default = \"./ntt\" , help = \"path for output csv file\" , ) args = parser . parse_args () parallel, asyncronized \u00b6 subprocess \u00b6 1 2 3 4 5 6 7 8 def subprocess_popen ( max_process , loop_number , cmd ): for i in range ( loop_num ): proc_list = [] proc = subprocess . Popen ( cmd ) proc_list . append ( proc ) if ( i + 1 ) % max_process == 0 or ( i + 1 ) == loop_num : for subproc in proc_list : subproc . wait () joblib \u00b6 1 2 3 4 from joblib import Parallel , delayed def task ( file ): return None Parallel ( n_jobs =- 1 )( delayed ( task )( i ) for i in tqdm ( data )) mpire \u00b6 1 2 3 4 5 6 7 from mpire import WorkerPool def task ( file ): return None with WorkerPool ( n_jobs = 5 ) as pool : results = pool . map ( task , data , progress_bar = True ) multithread, multiprocess \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 def task ( file ): return None def main (): with ThreadPoolExecutor () as executor : results = list ( executor . map ( task , files , ** kwargs ), total = len ( my_iter )) return list ( results ) def main (): with ProcessPoolExecutor () as executor : results = list ( executor . map ( task , files ), total = len ( my_iter )) # tqdm\u3092\u4f7f\u3046 # https://stackoverflow.com/questions/51601756/use-tqdm-with-concurrent-futures asyncio & multiprocess \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import asyncio import time import random import concurrent.futures def task ( one_task ): return None async def multi_process ( loop , task_list ): executor = concurrent . futures . ProcessPoolExecutor () queue = asyncio . Queue () [ queue . put_nowait ( x ) for x in task_list ] async def p ( q ): while not q . empty (): one_task = await q . get () future = loop . run_in_executor ( executor , task , one_task ) await future # 8\u30d7\u30ed\u30bb\u30b9\u3067\u51e6\u7406 tasks = [ asyncio . create_task ( p ( queue )) for i in range ( 8 )] return await asyncio . wait ( tasks ) def main ( task_list ): loop = asyncio . get_event_loop () loop . run_until_complete ( multi_process ( loop , task_list )) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import asyncio from concurrent.futures import ProcessPoolExecutor , ThreadPoolExecutor async def with_processing (): with ProcessPoolExecutor () as executor : tasks = [ ... ] for task in asyncio . as_completed ( tasks ): result = await task ... async def with_threading (): with ThreadPoolExecutor () as executor : tasks = [ ... ] for task in asyncio . as_completed ( tasks ): result = await task ... async def main (): await asyncio . gather ( with_processing (), with_threading ()) asyncio . run ( main ()) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 from concurrent.futures import ProcessPoolExecutor import asyncio import time async def mygen ( u : int = 2 ): i = 0 while i < u : yield i i += 1 def blocking ( delay ): time . sleep ( delay + 1 ) return ( 'EXECUTOR: Completed blocking task number ' + str ( delay + 1 )) async def run_blocking ( executor , task_no , delay ): print ( 'MASTER: Sending to executor blocking task number ' + str ( task_no )) result = await loop . run_in_executor ( executor , blocking , delay ) print ( result ) print ( 'MASTER: Well done executor - you seem to have completed ' 'blocking task number ' + str ( task_no )) async def non_blocking ( loop ): tasks = [] with ProcessPoolExecutor ( max_workers = 2 ) as executor : async for i in mygen (): # spawn the task and let it run in the background tasks . append ( asyncio . create_task ( run_blocking ( executor , i + 1 , i ))) # if there was an exception, retrieve it now await asyncio . gather ( * tasks ) loop = asyncio . get_event_loop () loop . run_until_complete ( non_blocking ( loop )) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def task (): futures = [] def main (): with concurrent . futures . ProcessPoolExecutor ( NUM_CORES ) as executor : run = asyncio . run ( task ( num_pages , output_file )) for i in range ( NUM_CORES - 1 ): new_future = executor . submit ( start_scraping , num_pages = PAGES_PER_CORE , output_file = OUTPUT_FILE , i = i ) futures . append ( new_future ) concurrent . futures . wait ( futures ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 async def task (): await do_something () await do_something2 () async def batch_task ( task_batch ): task_list = [ task ( f ) for f in task_batch ] results = await asyncio . gather ( * task_batch ) return results def do_batch_task_async ( task_batch ): loop = asyncio . get_event_loop () results = loop . run_until_complete ( do_batch_task_async ( task_batch )) loop . close () # asyncio.run(do_batch_task_async(task_batch)) if __name__ == \"__main__\" : task_divided = [[], [], []] # task \u3092cpu\u306e\u6570\u306bdivide\u3057\u305f\u3082\u306e with concurrent . futures . ProcessPoolExecutor () as executor : results = list ( tqdm ( executor . map ( do_batch_task_async , task_divided ), total = len ( my_iter ))) asyncio & aiohttp \u00b6 python \u3067\u975e\u540c\u671f\u30ea\u30af\u30a8\u30b9\u30c8\u3059\u308b\u306a\u3089\u5927\u4eba\u3057\u304f aiohttp \u3092\u4f7f\u3044\u307e\u3057\u3087\u3046\u3068\u3044\u3046\u8a71 aiohttp \u3068 asyncio \u3092\u4f7f\u7528\u3057\u305f Python \u306e\u975e\u540c\u671f HTTP \u30ea\u30af\u30a8\u30b9\u30c8 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import aiohttp import asyncio import time async def get_data ( session ): async with session . post ( url = url , params = params , headers = headers , data = open ( file_path , \"rb\" ) . read (), timeout = 10 , ) as resp : data = await resp . json () return data async def main ( total_number ): async with aiohttp . ClientSession () as session : tasks = [] tasks . append ( asyncio . ensure_future ( get_data ( session ))) all_data = await asyncio . gather ( * tasks ) \u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0 \u00b6 https://chusotsu-program.com/arimurakasumi-scraping/ https://itstudio.co/2018/12/28/8664/ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 from bs4 import BeautifulSoup import urllib.request , urllib.error , urllib.parse keyword = '\u30ac\u30c3\u30ad\u30fc' max_page = 3 # \u30da\u30fc\u30b8\u6570\uff0820\u679a/\u30da\u30fc\u30b8\uff09 dst_path = './img-kasumi/' headers = { \"User-Agent\" : \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\" , } cnt = 1 for i in range ( max_page ): cnt += 20 url = 'https://search.yahoo.co.jp/image/search?p= {} &ei=UTF-8&b= {} ' . format ( urllib . parse . quote ( keyword ), cnt ) req = urllib . request . Request ( url = url , headers = headers ) res = urllib . request . urlopen ( req ) soup = BeautifulSoup ( res ) div = soup . find ( 'div' , id = 'gridlist' ) imgs = div . find_all ( 'img' ) for j in range ( len ( imgs )): img = imgs [ j ][ 'src' ] tmp = urllib . request . urlopen ( img ) data = tmp . read () file_name = dst_path + 'page' + str ( i + 1 ) + '_img' + str ( j + 1 ) + '.jpg' with open ( file_name , 'wb' ) as save_img : save_img . write ( data ) subprocess \u00b6 \u51fa\u529b\u3092\u8a18\u9332\u3059\u308b \u00b6 1 2 3 4 5 6 7 proc = subprocess . run ([ \"ls\" ], stdout = subprocess . PIPE , stderr = subprocess . PIPE ) print ( proc . stdout . decode ( \"utf8\" )) # \u51fa\u529b\u3092\u8a18\u9332 p = subprocess . Popen ( mycmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) for line in iter ( p . stdout . readline , b '' ): print ( line . rstrip () . decode ( \"utf8\" )) gokart, luigi \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 import logging import time import luigi import gokart class TaskA ( gokart . TaskOnKart ): param = luigi . Parameter () def run ( self ): output = \"Hi {} \" . format ( self . param ) time . sleep ( 10.0 ) self . dump ( output ) class TaskB ( gokart . TaskOnKart ): param = luigi . Parameter () def requires ( self ): return dict ( a = TaskA ( param = \"called by TaskB\" ), b = TaskA ( param = \"aaaaaa\" + self . param ) ) # return dict(a=TaskA(serialized_task_definition_check=True), b=TaskA()) def run ( self ): res = self . load ( \"a\" ) time . sleep ( 5.0 ) print ( \"I am waited\" ) # res = self.load('caaa') self . dump ( res ) class TaskC ( gokart . TaskOnKart ): param = luigi . Parameter () task = gokart . TaskInstanceParameter def requires ( self ): self . task = TaskB ( param = self . param ) return self . task def run ( self ): summary = gokart . tree . task_info . make_task_info_as_table ( self . task , []) show_columns = [ \"name\" , \"processing_time\" , \"is_complete\" ] print ( summary . columns ) print ( summary [ show_columns ]) string = \"aeeee\" task = TaskC ( param = string ) gokart . build ( TaskC ( param = string ), log_level = logging . DEBUG , return_value = False ) tqdm \u00b6 print \u3092\u4f7f\u3044\u3064\u3064\u3001tqdm \u3092\u30bf\u30fc\u30df\u30ca\u30eb\u306e\u5e45\u306b\u5408\u308f\u305b\u3066\u5909\u5316 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import contextlib import sys from time import sleep from tqdm import tqdm from tqdm.contrib import DummyTqdmFile @contextlib . contextmanager def std_out_err_redirect_tqdm (): orig_out_err = sys . stdout , sys . stderr try : sys . stdout , sys . stderr = map ( DummyTqdmFile , orig_out_err ) yield orig_out_err [ 0 ] # Relay exceptions except Exception as exc : raise exc # Always restore sys.stdout/err if necessary finally : sys . stdout , sys . stderr = orig_out_err def some_fun ( i ): print ( \"Fee, fi, fo,\" . split ()[ 2 ]) # Redirect stdout to tqdm.write() (don't forget the `as save_stdout`) with std_out_err_redirect_tqdm () as orig_stdout : # tqdm needs the original stdout # and dynamic_ncols=True to autodetect console width for i in tqdm ( range ( 3 ), file = orig_stdout , dynamic_ncols = True ): sleep ( 0.5 ) some_fun ( i ) \u540d\u524d\u53d6\u5f97 \u00b6 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def get_parameters_of_func ( offset = None ): \"\"\"Get a dictionary of paramteres of the function. Parameters ---------- offset : int default value is None Return ------ dictionary The dictionary includes pairs of paremeter's name and the corresponding values. References ---------- [1] https://tottoto.net/python3-get-args-of-current-function/ \"\"\" parent_frame = inspect . currentframe () . f_back info = inspect . getargvalues ( parent_frame ) return { key : info . locals [ key ] for key in info . args [ offset :]} 1 function_name = inspect . currentframe () . f_code . co_name","title":"Python util"},{"location":"util/#python","text":"https://qiita.com/hiroyuki_mrp/items/8bbd9ab6c16601e87a9c","title":"python \u6a19\u6e96\u30e9\u30a4\u30d6\u30e9\u30ea"},{"location":"util/#_1","text":"\u3010VS Code\u3011Black \u3068 Flake8 \u3092\u4f7f\u3063\u3066\u304d\u308c\u3044\u306a Python \u30b3\u30fc\u30c9\u3092\u66f8\u304f\uff01\uff01 Python \u306e\u30b3\u30fc\u30c9\u3092\u30ad\u30ec\u30a4\u306b\u66f8\u304d\u305f\u3044\uff01(VSCode \u306b flake8 & black \u3092\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb) flake8\u3001black\u3001isort\u3001mypy \u3092 VS Code \u4e0a\u3067\u4f7f\u7528\u3059\u308b GCP \u306a\u3069\u306e\u5834\u5408\u306f\u500b\u5225\u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\uff08pip install black\uff09,\u8a2d\u5b9a(ssh \u30ef\u30fc\u30af\u30b9\u30da\u30fc\u30b9)\u304c\u5fc5\u8981\u3001error lense \u306f 500 \u307e\u3067\u306e delay \u304c\u5fc5\u8981","title":"\u30ea\u30f3\u30bf\u30fc"},{"location":"util/#util-pyfile-templates","text":"Pypy, pip \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb Python \u3067\u81ea\u5206\u3060\u3051\u306e\u30af\u30bd\u30e9\u30a4\u30d6\u30e9\u30ea\u3092\u4f5c\u308b\u65b9\u6cd5 Python \u3067\u4f5c\u3063\u305f\u30b3\u30de\u30f3\u30c9\u3092 GitHub \u7d4c\u7531\u3067 pip \u30a4\u30f3\u30b9\u30c8\u30fc\u30eb\u53ef\u80fd\u306b\u3059\u308b","title":"util pyfile templates"},{"location":"util/#_2","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 import glob import os import time from functools import wraps import argparse from tqdm import tqdm @stop_watch def func ( file_list , output_dir ): return None if __name__ == \"__main__\" : parser = argparse . ArgumentParser () parser . add_argument ( \"--input_dir\" , type = str , required = True , help = \"path for input dir\" , ) parser . add_argument ( \"--output_dir\" , type = str , required = True , help = \"path for output dir\" , ) args = parser . parse_args () check_create_dir ( args . output_dir ) file_list = get_file_list ( args . input_dir ) func ( file_list , args . output_dir )","title":"\u30c6\u30f3\u30d7\u30ec\u30fc\u30c8"},{"location":"util/#_3","text":"1 2 3 4 def check_create_dir ( path ): # check if there is the directory. if not create a new directory. if not os . path . isdir ( path ): os . makedirs ( path )","title":"\u30c7\u30a3\u30ec\u30af\u30c8\u30ea\u306e\u78ba\u8a8d\u3068\u4f5c\u6210"},{"location":"util/#_4","text":"1 2 3 4 5 6 7 8 9 def get_file_list ( input_dir ): # get the list of files in input directory. return sorted ( [ p for p in glob . glob ( os . path . join ( input_dir , \"**\" ), recursive = True ) if os . path . isfile ( p ) ] ) 1 2 3 4 5 6 7 8 9 10 11 ### def stop_watch ( func ) : @wraps ( func ) def wrapper ( * args , ** kargs ) : start = time . time () result = func ( * args , ** kargs ) elapsed_time = time . time () - start print ( f \"total time of { func . __name__ } : { elapsed_time } \" ) return result return wrapper 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @stop_watch def func ( file_list , output_dir ): return None if __name__ == \"__main__\" : parser = argparse . ArgumentParser () parser . add_argument ( \"--input_dir\" , type = str , required = True , help = \"path for input dir\" , ) parser . add_argument ( \"--output_dir\" , type = str , required = True , help = \"path for output dir\" , ) args = parser . parse_args () check_create_dir ( args . output_dir ) file_list = get_file_list ( args . input_dir ) func ( file_list , args . output_dir )","title":"\u30d5\u30a1\u30a4\u30eb\u30ea\u30b9\u30c8\u306e\u53d6\u5f97"},{"location":"util/#general-util","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 def load_pickle ( load_path ): # pd.read_pickle(load_path) with open ( load_path , mode = \"rb\" ) as f : return pickle . load ( f ) def save_pickle ( object , save_path ): # pd.to_pickle(object, save_path) with open ( save_path , mode = \"wb\" ) as f : pickle . dump ( object , f ) def check_create_dir ( path ): if not os . path . isdir ( path ): os . makedirs ( path , exist_ok = True ) def get_file_list ( input_dir ): return [ p for p in glob . glob ( os . path . join ( input_dir , \"**\" ), recursive = True ) if os . path . isfile ( p ) ] def split_list ( l , n ): \"\"\" https://www.python.ambitious-engineer.com/archives/1843 Other: np.array_split(l, 3) \"\"\" for idx in range ( 0 , len ( l ), n ): yield l [ idx : idx + n ] def split_list ( l , n ): return np . array_split ( l , n ) def json2dataframe ( json_data ): return pd . json_normalize ( json_data , record_path = 'data' ) def flatten_dict ( dict ): df = pd . json_normalize ( dict [ \"data\" ][ 0 ], sep = \"_\" ) return df . to_dict ( orient = \"records\" )[ 0 ] def flatten_dict ( d , parent_key = \"\" , sep = \"_\" ): items = [] for k , v in d . items (): new_key = parent_key + sep + k if parent_key else k if isinstance ( v , collections . MutableMapping ): items . extend ( flatten ( v , new_key , sep = sep ) . items ()) else : items . append (( new_key , v )) return dict ( items ) from functools import wraps import time def stop_watch ( func ) : @wraps ( func ) def wrapper ( * args , ** kargs ) : start = time . time () result = func ( * args , ** kargs ) elapsed_time = time . time () - start print ( f \"total time of { func . __name__ } : { elapsed_time } \" ) return result return wrapper def seed_everything ( seed = 2021 ): random . seed ( seed ) os . environ [ \"PYTHONHASHSEED\" ] = str ( seed ) np . random . seed ( seed ) torch . manual_seed ( seed ) torch . cuda . manual_seed ( seed ) torch . backends . cudnn . deterministic = True torch . backends . cudnn . benchmark = False def git_commits ( rand ): def func_decorator ( my_func ): repo = git . Repo ( \"/work\" ) repo . config_writer () . set_value ( \"user\" , \"name\" , \"your_userID\" ) . release () repo . config_writer () . set_value ( \"user\" , \"email\" , \"your_email@gmail.com\" ) . release () repo . git . diff ( \"HEAD\" ) repo . git . add ( \".\" ) repo . index . commit ( f \" { rand } _running\" ) repo . git . push ( \"origin\" , \"HEAD\" ) logger . info ( f \"git pushed to the remote origin\" ) def decorator_wrapper ( * args , ** kwargs ): my_func ( * args , ** kwargs ) repo . git . add ( \".\" ) repo . index . commit ( f \" { rand } _done\" ) repo . git . push ( \"origin\" , \"HEAD\" ) logger . info ( f \"git pushed to the remote origin\" ) return decorator_wrapper return func_decorator def randomname ( n ): return \"\" . join ( random . choices ( string . ascii_letters + string . digits , k = n ))","title":"General util"},{"location":"util/#logger","text":"\u30ed\u30b0\u51fa\u529b\u306e\u305f\u3081\u306e print \u3068 import logging \u306f\u3084\u3081\u3066\u307b\u3057\u3044","title":"logger"},{"location":"util/#python-print","text":"1 2 3 4 5 6 7 8 9 from logging import getLogger , StreamHandler , DEBUG logger = getLogger ( __name__ ) handler = StreamHandler () handler . setLevel ( DEBUG ) logger . setLevel ( DEBUG ) logger . addHandler ( handler ) logger . propagate = False logger . debug ( 'hello' ) https://qiita.com/shotakaha/items/0fa2db1dc8253c83e2bb 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 import logging import logging.handlers def setup_logger ( name , logfile = 'log.log' ): logger = logging . getLogger ( name ) logger . setLevel ( logging . DEBUG ) # create file handler which logs even DEBUG messages fh = logging . handlers . RotatingFileHandler ( logfile , maxBytes = 100000000 , backupCount = 10 ) fh . setLevel ( logging . DEBUG ) fh_formatter = logging . Formatter ( \"[ %(asctime)s ] [ %(levelname)s ] [ %(process)d ] [ %(name)s ] [ %(funcName)s ] [ %(lineno)d ] %(message)s \" ) fh . setFormatter ( fh_formatter ) # create console handler with a INFO log level ch = LoggingHandler () ch . setLevel ( logging . INFO ) ch_formatter = logging . Formatter ( \"[ %(asctime)s ] [ %(levelname)s ] [ %(process)d ] [ %(name)s ] [ %(funcName)s ] [ %(lineno)d ] %(message)s \" ) ch . setFormatter ( ch_formatter ) # add the handlers to the logger logger . addHandler ( fh ) logger . addHandler ( ch ) return logger def setup_logger ( name , logfile = 'log.log' ): logger = logging . getLogger ( name ) logger . setLevel ( logging . DEBUG ) # create file handler which logs even DEBUG messages fh = logging . FileHandler ( logfile ) fh . setLevel ( logging . DEBUG ) fh_formatter = logging . Formatter ( \"[ %(asctime)s ] [ %(levelname)s ] [ %(process)d ] [ %(name)s ] [ %(funcName)s ] [ %(lineno)d ] %(message)s \" ) fh . setFormatter ( fh_formatter ) # create console handler with a INFO log level ch = LoggingHandler () ch . setLevel ( logging . INFO ) ch_formatter = logging . Formatter ( \"[ %(asctime)s ] [ %(levelname)s ] [ %(process)d ] [ %(name)s ] [ %(funcName)s ] [ %(lineno)d ] %(message)s \" ) ch . setFormatter ( ch_formatter ) # add the handlers to the logger logger . addHandler ( fh ) logger . addHandler ( ch ) return logger \u53c2\u8003 https://github.com/tqdm/tqdm#redirecting-writing https://qiita.com/mino-38/items/f09251d18fe3181bfbfd https://waregawa-log.hatenablog.com/entry/2020/01/01/100000 https://stackoverflow.com/questions/384076/how-can-i-color-python-logging-output 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 import contextlib import logging import logging.handlers import sys from time import sleep from tqdm import tqdm from tqdm.contrib import DummyTqdmFile class TqdmLoggingHandler ( logging . Handler ): colors = { \"INFO\" : \" \\033 [37m {} \\033 [0m\" } def __init__ ( self , level = logging . NOTSET ): super () . __init__ ( level ) def emit ( self , record ): try : record . msg = TqdmLoggingHandler . colors . get ( record . levelname , \" {} \" ) . format ( record . msg ) msg = self . format ( record ) tqdm . write ( msg , file = sys . stderr ) self . flush () except Exception : self . handleError ( record ) class CustomFormatter ( logging . Formatter ): grey = \" \\x1b [38;20m\" green = \" \\x1b [32;20m\" yellow = \" \\x1b [33;20m\" red = \" \\x1b [31;20m\" bold_red = \" \\x1b [31;1m\" reset = \" \\x1b [0m\" format = \"[ %(asctime)s ] [ %(levelname)s ] [ %(process)d ] [ %(name)s ] [ %(funcName)s ] [ %(lineno)d ] %(message)s \" FORMATS = { logging . DEBUG : grey + format + reset , logging . INFO : green + format + reset , logging . WARNING : yellow + format + reset , logging . ERROR : red + format + reset , logging . CRITICAL : bold_red + format + reset , } def format ( self , record ): log_fmt = self . FORMATS . get ( record . levelno ) formatter = logging . Formatter ( log_fmt ) return formatter . format ( record ) def setup_logger ( name , logfile = \"log.log\" ): logger = logging . getLogger ( name ) logger . setLevel ( logging . DEBUG ) # create file handler which logs even DEBUG messages fh = logging . handlers . RotatingFileHandler ( logfile , maxBytes = 100000000 , backupCount = 10 ) fh . setLevel ( logging . DEBUG ) fh_formatter = logging . Formatter ( \"[ %(asctime)s ] [ %(levelname)s ] [ %(process)d ] [ %(name)s ] [ %(funcName)s ] [ %(lineno)d ] %(message)s \" ) fh . setFormatter ( fh_formatter ) # create console handler with a INFO log level ch = TqdmLoggingHandler () ch . setLevel ( logging . INFO ) ch . setFormatter ( CustomFormatter ()) # add the handlers to the logger logger . addHandler ( fh ) logger . addHandler ( ch ) return logger logger = setup_logger ( __name__ ) @contextlib . contextmanager def std_out_err_redirect_tqdm (): orig_out_err = sys . stdout , sys . stderr try : sys . stdout , sys . stderr = map ( DummyTqdmFile , orig_out_err ) yield orig_out_err [ 0 ] # Relay exceptions except Exception as exc : raise exc # Always restore sys.stdout/err if necessary finally : sys . stdout , sys . stderr = orig_out_err def some_fun ( i ): logger . info ( \"Fee, fi, fo,\" . split ()[ 2 ]) print ( \"Fee, fi, fo,\" . split ()[ 2 ]) # Redirect stdout to tqdm.write() (don't forget the `as save_stdout`) with std_out_err_redirect_tqdm () as orig_stdout : # tqdm needs the original stdout # and dynamic_ncols=True to autodetect console width for i in tqdm ( range ( 3 ), file = orig_stdout , dynamic_ncols = True ): sleep ( 0.5 ) some_fun ( i ) # After the `with`, printing is restored print ( \"Done!\" )","title":"Python \u3067 print \u3092\u5352\u696d\u3057\u3066\u30ed\u30b0\u51fa\u529b\u3092\u3044\u3044\u611f\u3058\u306b\u3059\u308b"},{"location":"util/#image","text":"png \u753b\u50cf\u3068 jpg \u753b\u50cf\u306e\u53d6\u308a\u6271\u3044\u306e\u6ce8\u610f\u70b9 https://qiita.com/pashango2/items/145d858eff3c505c100a https://note.nkmk.me/python-pillow-basic/ 1 2 3 4 def jpg2png ( file_list , output_dir ): for file_path in tqdm ( file_list ): img = Image . open ( file_path ) . resize (( 256 , 256 )) . convert ( \"RGBA\" ) img . save ( os . path . join ( output_dir , f \" { os . path . basename ( file_path )[: - 4 ] } .png\" ))","title":"Image"},{"location":"util/#png-jpg","text":"1 2 3 4 5 6 7 def tra_png2white_jpg ( file_list , output_dir ): for file_path in tqdm ( file_list ): img = Image . open ( file_path ) img . load () background = Image . new ( \"RGB\" , img . size , ( 255 , 255 , 255 )) background . paste ( img , mask = img . split ()[ 3 ]) background . save ( os . path . join ( output_dir , f \" { os . path . basename ( file_path )[: - 4 ] } .jpg\" ), \"JPEG\" , quality = 95 )","title":"\u900f\u660e png \u3092\u767d jpg \u306b\u5909\u63db"},{"location":"util/#png-png","text":"1 2 3 4 5 6 def tra_png2white_jpg ( file_list , output_dir ): for file_path in tqdm ( file_list ): img = cv2 . imread ( file_path ) index = np . where ( img [:, :, 3 ] == 0 ) img [ index ] = [ 255 , 255 , 255 , 255 ] cv2 . imwrite ( os . path . join ( output_dir , f \" { os . path . basename ( file_path )[: - 4 ] } .png\" ), img ) \u65e9\u304f\u77e5\u3063\u3066\u304a\u304d\u305f\u304b\u3063\u305f matplotlib \u306e\u57fa\u790e\u77e5\u8b58\u3001\u3042\u308b\u3044\u306f\u898b\u305f\u76ee\u306e\u8abf\u6574\u304c\u6357\u308b Artist \u306e\u8a71","title":"\u900f\u660e png \u3092\u767d png \u306b\u5909\u63db"},{"location":"util/#grid","text":"\u753b\u50cf\u3092\u305f\u3060\u4e26\u3079\u305f\u3044\u3068\u304d\u306b\u4f7f\u3048\u308b TorchVision","title":"\u753b\u50cf\u3092 Grid \u4e0a\u306b\u8868\u793a"},{"location":"util/#pil-to-cv","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 def cv2pil ( image ): ''' OpenCV\u578b -> PIL\u578b ''' new_image = image . copy () if new_image . ndim == 2 : # \u30e2\u30ce\u30af\u30ed pass elif new_image . shape [ 2 ] == 3 : # \u30ab\u30e9\u30fc new_image = cv2 . cvtColor ( new_image , cv2 . COLOR_BGR2RGB ) elif new_image . shape [ 2 ] == 4 : # \u900f\u904e new_image = cv2 . cvtColor ( new_image , cv2 . COLOR_BGRA2RGBA ) new_image = Image . fromarray ( new_image ) return new_image def pil2cv ( image ): ''' PIL\u578b -> OpenCV\u578b ''' new_image = np . array ( image , dtype = np . uint8 ) if new_image . ndim == 2 : # \u30e2\u30ce\u30af\u30ed pass elif new_image . shape [ 2 ] == 3 : # \u30ab\u30e9\u30fc new_image = cv2 . cvtColor ( new_image , cv2 . COLOR_RGB2BGR ) elif new_image . shape [ 2 ] == 4 : # \u900f\u904e new_image = cv2 . cvtColor ( new_image , cv2 . COLOR_RGBA2BGRA ) return new_image","title":"PIL to CV"},{"location":"util/#torch","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 def get_file_list ( input_dir ): return sorted ( [ p for p in glob . glob ( os . path . join ( input_dir , \"**\" ), recursive = True ) if os . path . isfile ( p ) ] ) def create_image_array ( image_folder_path , number_of_images = 100 , size = 256 ): file_list = sorted ( get_file_list ( image_folder_path )) random . seed ( 0 ) # random_images = random.sample(file_list, number_of_images) random_images = file_list [: 100 ] image_array = np . zeros (( number_of_images , size , size , 3 ), np . uint8 ) for i , image_path in enumerate ( random_images ): im = Image . open ( image_path ) . resize (( size , size )) img = np . asarray ( im ) image_array [ i ] = img return image_array def torchvision_save ( image_array , save_path , nrows = 10 , padding = 2 ): # \u30c7\u30fc\u30bf\u306e\u8aad\u307f\u8fbc\u307f images = image_array # save_image\u3067255\u639b\u3051\u308b\u305f\u3081[0,1]\u30b9\u30b1\u30fc\u30eb\u306b\u3057\u3066\u304a\u304f images = ( images / 255.0 ) . astype ( np . float32 ) # 1\u679a\u306b\u7d50\u5408 images = np . transpose ( images , [ 0 , 3 , 1 , 2 ]) images_tensor = torch . as_tensor ( images ) torchvision . utils . save_image ( images_tensor , save_path , nrow = nrows , padding = padding ) 1 2 3 4 5 6 7 8 9 10 11 12 13 import seaborn as sns import matplotlib.pyplot as plt num_rows , num_cols = 10 , 10 f , axes = plt . subplots ( nrows = num_rows , ncols = num_cols , figsize = ( 14 , 14 )) #f.suptitle('Distribution of Features', fontsize=16) for index , ( key , ( a1 , a2 )) in enumerate ( dic_male_five . items ()): i , j = ( index // num_cols , index % num_cols ) axes [ i , j ] . tick_params ( labelbottom = False , labelleft = False , labelright = False , labeltop = False ) sns . histplot ( a1 , bins = 5 , ax = axes [ i , j ]) 1 2 3 4 5 6 7 8 9 10 def tra_png2white_jpg1 ( file_path , output_dir ): img = Image . open ( file_path ) img . load () background = Image . new ( \"RGB\" , img . size , ( 255 , 255 , 255 )) background . paste ( img , mask = img . split ()[ 3 ]) background . save ( os . path . join ( output_dir , f \" { os . path . basename ( file_path )[: - 4 ] } .jpg\" ), \"JPEG\" , quality = 95 , )","title":"torch"},{"location":"util/#_5","text":"Python, OpenCV, NumPy \u3067\u753b\u50cf\u306e\u30a2\u30eb\u30d5\u30a1\u30d6\u30ec\u30f3\u30c9\u3068\u30de\u30b9\u30af\u51e6\u7406 \u753b\u50cf\u51e6\u7406\u5165\u9580\u8b1b\u5ea7 : OpenCV \u3068 Python \u3067\u59cb\u3081\u308b\u753b\u50cf\u51e6\u7406","title":"\u753b\u50cf\u51e6\u7406\u3001\u30de\u30b9\u30af"},{"location":"util/#plot-util","text":"1 2 3 4 5 def plot_pie ( data , labels ): plt . figure ( figsize = ( 12 , 8 )) plt . rcParams [ 'font.size' ] = 16.0 plt . pie ( data , labels = labels , counterclock = True , autopct = \" %1.1f%% \" )","title":"Plot util"},{"location":"util/#pandas","text":"[Python3 / pandas] dataframe \u306b\u8f9e\u66f8\u578b\u30c7\u30fc\u30bf\u3092 1 \u884c\u305a\u3064\u8ffd\u52a0\u3057\u3066\u3044\u304d\u305f\u3044\u3068\u304d\uff08\u901f\u5ea6\u6bd4\u8f03\uff09 pandas.DataFrame \u306b\uff11\u884c\u305a\u3064\u66f8\u304d\u8db3\u3059\u65e9\u3044\u65b9\u6cd5\u3092\u8abf\u3079\u305f 1 2 3 4 5 6 7 def from_dict_method (): some_df = pd . DataFrame ([], columns = some_dict . keys ()) dict_array = [] for i in range ( 3000 ): dict_array . append ( some_dict ) some_df = pd . concat ([ some_df , pd . DataFrame . from_dict ( dict_array )]) return some_df","title":"pandas"},{"location":"util/#vectorize","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 def func_1 ( energy_kwh_0 , energy_kwh_1 , energy_kwh_2 ): if energy_kwh_0 > energy_kwh_1 : return 'a' elif energy_kwh_0 > energy_kwh_2 : return 'b' else : return 'c' df [ 'pattern_np_vectorize' ] = np . vectorize ( func_1 )( df [ \"energy_kwh_0\" ], df [ \"energy_kwh_1\" ], df [ \"energy_kwh_2\" ] )","title":"vectorize"},{"location":"util/#argparse","text":"Python \u30b3\u30de\u30f3\u30c9\u30e9\u30a4\u30f3\u89e3\u6790\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u6bd4\u8f03(argparse, click, fire) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 parser = argparse . ArgumentParser ( description = \"Image Annotation\" ) parser . add_argument ( \"--input_dir\" , type = str , default = \"./images\" , help = \"path for input data\" , ) parser . add_argument ( \"--output_dir\" , type = str , default = \"./ntt\" , help = \"path for output csv file\" , ) args = parser . parse_args ()","title":"argparse"},{"location":"util/#parallel-asyncronized","text":"","title":"parallel, asyncronized"},{"location":"util/#subprocess","text":"1 2 3 4 5 6 7 8 def subprocess_popen ( max_process , loop_number , cmd ): for i in range ( loop_num ): proc_list = [] proc = subprocess . Popen ( cmd ) proc_list . append ( proc ) if ( i + 1 ) % max_process == 0 or ( i + 1 ) == loop_num : for subproc in proc_list : subproc . wait ()","title":"subprocess"},{"location":"util/#joblib","text":"1 2 3 4 from joblib import Parallel , delayed def task ( file ): return None Parallel ( n_jobs =- 1 )( delayed ( task )( i ) for i in tqdm ( data ))","title":"joblib"},{"location":"util/#mpire","text":"1 2 3 4 5 6 7 from mpire import WorkerPool def task ( file ): return None with WorkerPool ( n_jobs = 5 ) as pool : results = pool . map ( task , data , progress_bar = True )","title":"mpire"},{"location":"util/#multithread-multiprocess","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 def task ( file ): return None def main (): with ThreadPoolExecutor () as executor : results = list ( executor . map ( task , files , ** kwargs ), total = len ( my_iter )) return list ( results ) def main (): with ProcessPoolExecutor () as executor : results = list ( executor . map ( task , files ), total = len ( my_iter )) # tqdm\u3092\u4f7f\u3046 # https://stackoverflow.com/questions/51601756/use-tqdm-with-concurrent-futures","title":"multithread, multiprocess"},{"location":"util/#asyncio-multiprocess","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 import asyncio import time import random import concurrent.futures def task ( one_task ): return None async def multi_process ( loop , task_list ): executor = concurrent . futures . ProcessPoolExecutor () queue = asyncio . Queue () [ queue . put_nowait ( x ) for x in task_list ] async def p ( q ): while not q . empty (): one_task = await q . get () future = loop . run_in_executor ( executor , task , one_task ) await future # 8\u30d7\u30ed\u30bb\u30b9\u3067\u51e6\u7406 tasks = [ asyncio . create_task ( p ( queue )) for i in range ( 8 )] return await asyncio . wait ( tasks ) def main ( task_list ): loop = asyncio . get_event_loop () loop . run_until_complete ( multi_process ( loop , task_list )) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import asyncio from concurrent.futures import ProcessPoolExecutor , ThreadPoolExecutor async def with_processing (): with ProcessPoolExecutor () as executor : tasks = [ ... ] for task in asyncio . as_completed ( tasks ): result = await task ... async def with_threading (): with ThreadPoolExecutor () as executor : tasks = [ ... ] for task in asyncio . as_completed ( tasks ): result = await task ... async def main (): await asyncio . gather ( with_processing (), with_threading ()) asyncio . run ( main ()) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 from concurrent.futures import ProcessPoolExecutor import asyncio import time async def mygen ( u : int = 2 ): i = 0 while i < u : yield i i += 1 def blocking ( delay ): time . sleep ( delay + 1 ) return ( 'EXECUTOR: Completed blocking task number ' + str ( delay + 1 )) async def run_blocking ( executor , task_no , delay ): print ( 'MASTER: Sending to executor blocking task number ' + str ( task_no )) result = await loop . run_in_executor ( executor , blocking , delay ) print ( result ) print ( 'MASTER: Well done executor - you seem to have completed ' 'blocking task number ' + str ( task_no )) async def non_blocking ( loop ): tasks = [] with ProcessPoolExecutor ( max_workers = 2 ) as executor : async for i in mygen (): # spawn the task and let it run in the background tasks . append ( asyncio . create_task ( run_blocking ( executor , i + 1 , i ))) # if there was an exception, retrieve it now await asyncio . gather ( * tasks ) loop = asyncio . get_event_loop () loop . run_until_complete ( non_blocking ( loop )) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def task (): futures = [] def main (): with concurrent . futures . ProcessPoolExecutor ( NUM_CORES ) as executor : run = asyncio . run ( task ( num_pages , output_file )) for i in range ( NUM_CORES - 1 ): new_future = executor . submit ( start_scraping , num_pages = PAGES_PER_CORE , output_file = OUTPUT_FILE , i = i ) futures . append ( new_future ) concurrent . futures . wait ( futures ) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 async def task (): await do_something () await do_something2 () async def batch_task ( task_batch ): task_list = [ task ( f ) for f in task_batch ] results = await asyncio . gather ( * task_batch ) return results def do_batch_task_async ( task_batch ): loop = asyncio . get_event_loop () results = loop . run_until_complete ( do_batch_task_async ( task_batch )) loop . close () # asyncio.run(do_batch_task_async(task_batch)) if __name__ == \"__main__\" : task_divided = [[], [], []] # task \u3092cpu\u306e\u6570\u306bdivide\u3057\u305f\u3082\u306e with concurrent . futures . ProcessPoolExecutor () as executor : results = list ( tqdm ( executor . map ( do_batch_task_async , task_divided ), total = len ( my_iter )))","title":"asyncio &amp; multiprocess"},{"location":"util/#asyncio-aiohttp","text":"python \u3067\u975e\u540c\u671f\u30ea\u30af\u30a8\u30b9\u30c8\u3059\u308b\u306a\u3089\u5927\u4eba\u3057\u304f aiohttp \u3092\u4f7f\u3044\u307e\u3057\u3087\u3046\u3068\u3044\u3046\u8a71 aiohttp \u3068 asyncio \u3092\u4f7f\u7528\u3057\u305f Python \u306e\u975e\u540c\u671f HTTP \u30ea\u30af\u30a8\u30b9\u30c8 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 import aiohttp import asyncio import time async def get_data ( session ): async with session . post ( url = url , params = params , headers = headers , data = open ( file_path , \"rb\" ) . read (), timeout = 10 , ) as resp : data = await resp . json () return data async def main ( total_number ): async with aiohttp . ClientSession () as session : tasks = [] tasks . append ( asyncio . ensure_future ( get_data ( session ))) all_data = await asyncio . gather ( * tasks )","title":"asyncio &amp; aiohttp"},{"location":"util/#_6","text":"https://chusotsu-program.com/arimurakasumi-scraping/ https://itstudio.co/2018/12/28/8664/ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 from bs4 import BeautifulSoup import urllib.request , urllib.error , urllib.parse keyword = '\u30ac\u30c3\u30ad\u30fc' max_page = 3 # \u30da\u30fc\u30b8\u6570\uff0820\u679a/\u30da\u30fc\u30b8\uff09 dst_path = './img-kasumi/' headers = { \"User-Agent\" : \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:47.0) Gecko/20100101 Firefox/47.0\" , } cnt = 1 for i in range ( max_page ): cnt += 20 url = 'https://search.yahoo.co.jp/image/search?p= {} &ei=UTF-8&b= {} ' . format ( urllib . parse . quote ( keyword ), cnt ) req = urllib . request . Request ( url = url , headers = headers ) res = urllib . request . urlopen ( req ) soup = BeautifulSoup ( res ) div = soup . find ( 'div' , id = 'gridlist' ) imgs = div . find_all ( 'img' ) for j in range ( len ( imgs )): img = imgs [ j ][ 'src' ] tmp = urllib . request . urlopen ( img ) data = tmp . read () file_name = dst_path + 'page' + str ( i + 1 ) + '_img' + str ( j + 1 ) + '.jpg' with open ( file_name , 'wb' ) as save_img : save_img . write ( data )","title":"\u30b9\u30af\u30ec\u30a4\u30d4\u30f3\u30b0"},{"location":"util/#subprocess_1","text":"","title":"subprocess"},{"location":"util/#_7","text":"1 2 3 4 5 6 7 proc = subprocess . run ([ \"ls\" ], stdout = subprocess . PIPE , stderr = subprocess . PIPE ) print ( proc . stdout . decode ( \"utf8\" )) # \u51fa\u529b\u3092\u8a18\u9332 p = subprocess . Popen ( mycmd , stdout = subprocess . PIPE , stderr = subprocess . STDOUT ) for line in iter ( p . stdout . readline , b '' ): print ( line . rstrip () . decode ( \"utf8\" ))","title":"\u51fa\u529b\u3092\u8a18\u9332\u3059\u308b"},{"location":"util/#gokart-luigi","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 import logging import time import luigi import gokart class TaskA ( gokart . TaskOnKart ): param = luigi . Parameter () def run ( self ): output = \"Hi {} \" . format ( self . param ) time . sleep ( 10.0 ) self . dump ( output ) class TaskB ( gokart . TaskOnKart ): param = luigi . Parameter () def requires ( self ): return dict ( a = TaskA ( param = \"called by TaskB\" ), b = TaskA ( param = \"aaaaaa\" + self . param ) ) # return dict(a=TaskA(serialized_task_definition_check=True), b=TaskA()) def run ( self ): res = self . load ( \"a\" ) time . sleep ( 5.0 ) print ( \"I am waited\" ) # res = self.load('caaa') self . dump ( res ) class TaskC ( gokart . TaskOnKart ): param = luigi . Parameter () task = gokart . TaskInstanceParameter def requires ( self ): self . task = TaskB ( param = self . param ) return self . task def run ( self ): summary = gokart . tree . task_info . make_task_info_as_table ( self . task , []) show_columns = [ \"name\" , \"processing_time\" , \"is_complete\" ] print ( summary . columns ) print ( summary [ show_columns ]) string = \"aeeee\" task = TaskC ( param = string ) gokart . build ( TaskC ( param = string ), log_level = logging . DEBUG , return_value = False )","title":"gokart, luigi"},{"location":"util/#tqdm","text":"print \u3092\u4f7f\u3044\u3064\u3064\u3001tqdm \u3092\u30bf\u30fc\u30df\u30ca\u30eb\u306e\u5e45\u306b\u5408\u308f\u305b\u3066\u5909\u5316 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 import contextlib import sys from time import sleep from tqdm import tqdm from tqdm.contrib import DummyTqdmFile @contextlib . contextmanager def std_out_err_redirect_tqdm (): orig_out_err = sys . stdout , sys . stderr try : sys . stdout , sys . stderr = map ( DummyTqdmFile , orig_out_err ) yield orig_out_err [ 0 ] # Relay exceptions except Exception as exc : raise exc # Always restore sys.stdout/err if necessary finally : sys . stdout , sys . stderr = orig_out_err def some_fun ( i ): print ( \"Fee, fi, fo,\" . split ()[ 2 ]) # Redirect stdout to tqdm.write() (don't forget the `as save_stdout`) with std_out_err_redirect_tqdm () as orig_stdout : # tqdm needs the original stdout # and dynamic_ncols=True to autodetect console width for i in tqdm ( range ( 3 ), file = orig_stdout , dynamic_ncols = True ): sleep ( 0.5 ) some_fun ( i )","title":"tqdm"},{"location":"util/#_8","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def get_parameters_of_func ( offset = None ): \"\"\"Get a dictionary of paramteres of the function. Parameters ---------- offset : int default value is None Return ------ dictionary The dictionary includes pairs of paremeter's name and the corresponding values. References ---------- [1] https://tottoto.net/python3-get-args-of-current-function/ \"\"\" parent_frame = inspect . currentframe () . f_back info = inspect . getargvalues ( parent_frame ) return { key : info . locals [ key ] for key in info . args [ offset :]} 1 function_name = inspect . currentframe () . f_code . co_name","title":"\u540d\u524d\u53d6\u5f97"}]}